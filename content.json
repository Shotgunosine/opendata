{"pages":[{"title":"About OpenData","text":"OpenData is a database of publicly available behavioral datasets. To browse the database, click on the links above or use the search bar at the top-right of this page. What is the goal of OpenData? The goal of this project is simply to make it easier for researchers to find and use publicly available behavioral data as part of research. There's already so much out there that can be used to: Test new hypotheses or models Calculate effect sizes for power analysis Estimate meta-analytic effects across studies What is the scope of OpenData? The scope of this project is to catalogue any and all open datasets involving experimental or cognitive tasks (e.g., Stroop, delay discounting, 2-arm bandits). Datasets involving more naturalistic behaviors are also welcomed. The only firm requirement is that trial-level data must be available. Who maintains OpenData? This project is maintained by Sam Zorowitz with help from other members of the Niv Lab. How can I add a dataset? Please see the contributing page. How can I report an issue? Please open an issue on our Github or directly contact the maintainer.","link":"/opendata/about/index.html"},{"title":"Contributing to OpenData","text":"Contributions to OpenData are welcome! All of the code is managed through the GitHub repository. How to submit a dataset There are three main ways you can submit a dataset for entry to OpenData, which are described in turn below. Note that they are ranked in order of preference, from most preferred to least preferred, by the maintainers of Open Data. 1. Fill out the Google form Have a dataset to submit? Fill out this form: https://forms.gle/N87Dqhs73vbfoPec8 2. Submit a pull request To directly add a dataset yourself, you can open a pull request on Github. First you should fork the OpenData library via GitHub and make modifications on your fork. The OpenData database is written in markdown using a standardized, easy-to-copy template. Once your modification is complete, submit a pull request to merge your changes into the docs branch of OpenData. Pull requests will be reviewed by the maintainers. 3. Open an issue To advertise a dataset for entry into the database, you can open a new issue via GitHub. Please provide a link to a repository for the data and, if available, a link to a corresponding manuscript describing the data.","link":"/opendata/contribute/index.html"}],"posts":[{"title":"Bein et al. (2021)","text":"When our experience violates our predictions, it is adaptive to update our knowledge to promote a more accurate representation of the world and facilitate future predictions. Theoretical models propose that these mnemonic prediction errors should be encoded into a distinct memory trace to prevent interference with previous, conflicting memories. We investigated this proposal by repeatedly exposing participants to pairs of sequentially presented objects (A → B), thus evoking expectations. Then, we violated participants expectations by replacing the second object in the pairs with a novel object (A → C). The following item memory test required participants to discriminate between identical old items and similar lures, thus testing detailed and distinctive item memory representations. In two experiments, mnemonic prediction errors enhanced item memory: Participants correctly identified more old items as old when those items violated expectations during learning, compared with items that did not violate expectations. This memory enhancement for C items was only observed when participants later showed intact memory for the related A → B pairs, suggesting that strong predictions are required to facilitate memory for violations. Following up on this, a third experiment reduced prediction strength prior to violation and subsequently eliminated the memory advantage of violations. Interestingly, mnemonic prediction errors did not increase gist-based mistakes of identifying old items as similar lures or identifying similar lures as old. Enhanced item memory in the absence of gist-based mistakes suggests that violations enhanced memory for items details, which could be mediated via distinct memory traces. Together, these results advance our knowledge of how mnemonic prediction errors promote memory formation.","link":"/opendata/bein-et-al-2021/"},{"title":"Abir et al. (2023)","text":"The purpose of exploration is to reduce goal-relevant uncertainty. This can be achieved by choosing to explore the parts of the environment one is most uncertain about. Humans, however, often choose to avoid uncertainty. How do humans balance approaching and avoiding uncertainty during exploration? To answer this question, we developed a task requiring participants to explore a simulated environment towards a clear goal. We compared human choices to the predictions of the optimal exploration policy and a hierarchy of simpler strategies. We found that participants generally explored the object they were more uncertain about. However, when overall uncertainty about choice options was high, participants avoided objects they were more uncertain about, learning instead about better known objects. We examined reaction times and individual differences to understand the costs and benefits of this strategy. We conclude that balancing approaching and avoiding uncertainty ameliorates the costs of exploration in a resource-rational manner.","link":"/opendata/abir-et-al-2023/"},{"title":"Albrecht et al. (2016)","text":"The negative symptoms of schizophrenia (SZ) are associated with a pattern of reinforcement learning (RL) deficits likely related to degraded representations of reward values. However, the RL tasks used to date have required active responses to both reward and punishing stimuli. Pavlovian biases have been shown to affect performance on these tasks through invigoration of action to reward and inhibition of action to punishment, and may be partially responsible for the effects found in patients. Forty-five patients with schizophrenia and 30 demographically-matched controls completed a four-stimulus reinforcement learning task that crossed action (Go or NoGo) and the valence of the optimal outcome (reward or punishment-avoidance), such that all combinations of action and outcome valence were tested. Behaviour was modelled using a six-parameter RL model and EEG was simultaneously recorded. Patients demonstrated a reduction in Pavlovian performance bias that was evident in a reduced Go bias across the full group. In a subset of patients administered clozapine, the reduction in Pavlovian bias was enhanced. The reduction in Pavlovian bias in SZ patients was accompanied by feedback processing differences at the time of the P3a component. The reduced Pavlovian bias in patients is suggested to be due to reduced fidelity in the communication between striatal regions and frontal cortex. It may also partially account for previous findings of poorer Go-learning in schizophrenia where Go responses or Pavlovian consistent responses are required for optimal performance. An attenuated P3a component dynamic in patients is consistent with a view that deficits in operant learning are due to impairments in adaptively using feedback to update representations of stimulus value.","link":"/opendata/albrecht-et-al-2016/"},{"title":"Algermissen et al. (2021)","text":"Action selection is biased by the valence of anticipated outcomes. To assess mechanisms by which these motivational biases are expressed and controlled, we measured simultaneous EEG-fMRI during a motivational Go/NoGo learning task (N = 36), leveraging the temporal resolution of EEG and subcortical access of fMRI. VmPFC BOLD encoded cue valence, importantly predicting trial-by-trial valence-driven response speed differences and EEG theta power around cue onset. In contrast, striatal BOLD encoded selection of active Go responses and correlated with theta power around response time. Within trials, theta power ramped in the fashion of an evidence accumulation signal for the value of making a Go response, capturing the faster responding to reward cues. Our findings reveal a dual nature of midfrontal theta power, with early components reflecting the vmPFC contribution to motivational biases, and late components reflecting their striatal translation into behavior, in line with influential recent value of work theories of striatal processing.","link":"/opendata/algermissen-et-al-2021/"},{"title":"Alister et al. (2022)","text":"The gaze cueing effect is the tendency for people to respond faster to targets appearing at locations gazed at by others compared to locations gazed away from by others. The effect is robust, widely studied, and is an influential finding within social cognition. However, much is still unknown about the cognitive processes that drive this effect. Formal evidence accumulation models provide the dominant theoretical account of the cognitive processes underlying speeded decision making but have never been applied to gaze cueing research and rarely to the study of social cognition more broadly. In this study, using a combination of individual-level and hierarchical computational modelling techniques, we applied Evidence Accumulation Models to gaze and arrow cueing data (four data sets total, n = 171, 139,001 trials) for the first time to 1) identify which cognitive mechanisms underlie the gaze cueing effect, and 2) see whether these processes could be considered the same as those that underlie arrow cueing effects. At the group level, people were best described by an attentional orienting mechanism rather than higher-order decision bias or information processing mechanisms. However, we found evidence for individual differences such that not everyone was best described by an attentional orienting mechanism. Further, the same people who were best described by an attentional orienting mechanism for gaze cues tended not to be best described by that same mechanism for arrow cues, suggesting these cueing effects may induce different responses within the same people – although we interpret this finding with caution.","link":"/opendata/alister-et-al-2022/"},{"title":"Almeras et al. (2022)","text":"Exploring novel environments through sequential sampling is essential for efficient decision-making under uncertainty. In the laboratory, human exploration has been studied in situations where exploration is traded against reward maximisation. By design, these ‘explore-exploit’ dilemmas confound the behavioural characteristics of exploration with those of the trade-off itself. Here we designed a sequential sampling task where exploration can be studied and compared in the presence and absence of trade-off with exploitation. Detailed model-based analyses of choice behaviour revealed specific exploration patterns arising in situations where information seeking is not traded against reward seeking. Human choices are directed toward the most uncertain option available, but only after an initial sampling phase consisting of choice streaks from each novel option. These findings outline competing cognitive pressures on information seeking: the repeated sampling of the current option (for hypothesis testing), and the directed sampling of the most uncertain option available (for structure mapping).","link":"/opendata/almeras-et-al-2022/"},{"title":"Amir et al. (2022)","text":"People have limited computational resources, yet they make complex strategic decisions over enormous spaces of possibilities. How do people efficiently search spaces with combinatorially branching paths? Here, we study players’ search strategies for a winning move in a “k-in-a-row” game. We find that players use scoring strategies to prune the search space and augment this pruning by a “shutter” heuristic that focuses the search on the paths emanating from their previous move. This strong pruning has its costs-both computational simulations and behavioral data indicate that the shutter size is correlated with players’ blindness to their opponent’s winning moves. However, simulations of the search while varying the shutter size, complexity levels, noise levels, branching factor, and computational limitations indicate that despite its costs, a narrow shutter strategy is the dominant strategy for most of the parameter space. Finally, we show that in the presence of computational limitations, the shutter heuristic enhances the performance of deep learning networks in these end-game scenarios. Together, our findings suggest a novel adaptive heuristic that benefits search in a vast space of possibilities of a strategic game.","link":"/opendata/amir-et-al-2022/"},{"title":"Antony et al. (2022)","text":"Two fundamental issues in memory research concern when later experiences strengthen or weaken initial memories and when the two memories become linked or remain independent. A promising candidate for explaining these issues is semantic relatedness. Here, across five paired-associate learning experiments (N=1000), we systematically varied the semantic relatedness between initial and later cues, initial and later targets, or both. We found that learning retroactively benefited long-term memory performance for semantically related words (vs. unshown control words), and these benefits increased as a function of relatedness. Critically, memory dependence between initial and later pairs also increased with relatedness, suggesting that pre-existing semantic relationships promote interdependence for memories formed across episodes. We also found that modest retroactive benefits, but not interdependencies, emerged when subjects learned via studying rather than practice testing. These findings demonstrate that semantic relatedness during new learning retroactively strengthens old associations while scaffolding new ones into well-fortified memory traces.","link":"/opendata/antony-et-al-2022/"},{"title":"Appelhoff et al. (2022)","text":"When judging the average value of sample stimuli (e.g., numbers) people tend to either over- or underweight extreme sample values, depending on task context. In a context of overweighting, recent work has shown that extreme sample values were overly represented also in neural signals, in terms of an anti-compressed geometry of number samples in multivariate electroencephalography (EEG) patterns. Here, we asked whether neural representational geometries may also reflect a relative underweighting of extreme values (i.e., compression) which has been observed behaviorally in a great variety of tasks. We used a simple experimental manipulation (instructions to average a single-stream or to compare dual-streams of samples) to induce compression or anti-compression in behavior when participants judged rapid number sequences. Model-based representational similarity analysis (RSA) replicated the previous finding of neural anti-compression in the dual-stream task, but failed to provide evidence for neural compression in the single-stream task, despite the evidence for compression in behavior. Instead, the results indicated enhanced neural processing of extreme values in either task, regardless of whether extremes were over- or underweighted in subsequent behavioral choice. We further observed more general differences in the neural representation of the sample information between the two tasks. Together, our results indicate a mismatch between sample-level EEG geometries and behavior, which raises new questions about the origin of common psychometric distortions, such as diminishing sensitivity for larger values.","link":"/opendata/appelhoff-et-al-2022/"},{"title":"Arbuzova et al. (2022)","text":"It is still debated whether metacognition, or the ability to monitor our own mental states, relies on processes that are domain-general (a single set of processes can account for the monitoring of any mental process) or domain-specific (metacognition is accomplished by a collection of multiple monitoring modules, one for each cognitive domain). It has been speculated that two broad categories of metacognitive processes may exist: those that monitor primarily externally generated versus those that monitor primarily internally generated information. To test this proposed division, we measured metacognitive performance (using m-ratio, a signal detection theoretical measure) in four tasks that could be ranked along an internal-external axis of the source of information, namely memory, motor, visuomotor, and visual tasks. We found correlations between m-ratios in visuomotor and motor tasks, but no correlations between m-ratios in visual and visuomotor tasks, or between motor and memory tasks. While we found no correlation in metacognitive ability between visual and memory tasks, and a positive correlation between visuomotor and motor tasks, we found no evidence for a correlation between motor and memory tasks. This pattern of correlations does not support the grouping of domains based on whether the source of information is primarily internal or external. We suggest that other groupings could be more reflective of the nature of metacognition and discuss the need to consider other non-domain task-features when using correlations as a way to test the underlying shared processes between domains.","link":"/opendata/arbuzova-et-al-2022/"},{"title":"Armstrong et al. (2022)","text":"Attentional bias for threat is an adaptive feature of human psychology, but may become maladaptive in anxiety-related disorders, causing distress, distraction, and distorted perception of danger. Reaction time measures have revealed automatic, covert attention biases to threat, whereas eye tracking has revealed voluntary biases over a larger timescale, with monitoring or avoidance depending on context. Recently, attentional bias for threat has been studied as a conditioned fear response, providing new insight into how attentional biases are acquired and inhibited through learning experiences. However, very few studies have examined voluntary gaze biases during fear learning. In a novel eye tracking paradigm, we examine the overt components of attentional bias to threat and safety cues. We found that threat cues, but not safety cues, elicited an initial orienting bias, as well as sustained monitoring bias across 10-second trials. This collective “vigilance” response to threat cues was insensitive to extinction, whereas condition fear responding revealed by pupil size and self-report ratings showed marked extinction. Vigilance may be less prone to extinction, compared to autonomic arousal, because eye movements require less energy than preparing the body for defensive behavior. Implications for understanding vigilance in PTSD are considered.","link":"/opendata/armstrong-et-al-2022/"},{"title":"Ashinoff et al. (2022)","text":"Base-rate neglect is a pervasive bias in judgment that is conceptualized as underweighting of prior information and can have serious consequences in real-world scenarios. This bias is thought to reflect variability in inferential processes but empirical support for a cohesive theory of base-rate neglect with sufficient explanatory power to account for longer-term and real-world beliefs is lacking. A Bayesian formalization of base-rate neglect in the context of sequential belief updating predicts that belief trajectories should exhibit dynamic patterns of dependence on the order in which evidence is presented and its consistency with prior beliefs. To test this, we developed a novel ‘urn-and-beads’ task that systematically manipulated the order of colored bead sequences and elicited beliefs via an incentive-compatible procedure. Our results in two independent online studies confirmed the predictions of the sequential base-rate neglect model: people exhibited beliefs that are more influenced by recent evidence and by evidence inconsistent with prior beliefs. We further found support for a noisy-sampling inference model whereby base-rate neglect results from rational discounting of noisy internal representations of prior beliefs. Finally, we found that model-derived indices of base-rate neglect-including noisier prior representation-correlated with propensity for unusual beliefs outside the laboratory. Our work supports the relevance of Bayesian accounts of sequential base-rate neglect to real-world beliefs and hints at strategies to minimize deleterious consequences of this pervasive bias.","link":"/opendata/ashinoff-et-al-2022/"},{"title":"Aydoğan et al. (2023)","text":"Interval timing refers to the ability to perceive and remember intervals in the seconds to minutes range. Our contemporary understanding of interval timing is derived from relatively small-scale, isolated studies that investigate a limited range of intervals with a small sample size, usually based on a single task. Consequently, the conclusions drawn from individual studies are not readily generalizable to other tasks, conditions, and task parameters. The current paper presents a live database that presents raw data from interval timing studies (currently composed of 68 datasets from eight different tasks incorporating various interval and temporal order judgments) with an online graphical user interface to easily select, compile, and download the data organized in a standard format. The Timing Database aims to promote and cultivate key and novel analyses of our timing ability by making published and future datasets accessible as open-source resources for the entire research community. In the current paper, we showcase the use of the database by testing various core ideas based on data compiled across studies (i.e., temporal accuracy, scalar property, location of the point of subjective equality, malleability of timing precision). The Timing Database will serve as the repository for interval timing studies through the submission of new datasets.","link":"/opendata/aydogan-et-al-2023/"},{"title":"Aylward et al. (2019)","text":"Anxiety is characterized by altered responses under uncertain conditions, but the precise mechanism by which uncertainty changes the behaviour of anxious individuals is unclear. Here we probe the computational basis of learning under uncertainty in healthy individuals and individuals suffering from a mix of mood and anxiety disorders. Participants were asked to choose between four competing slot machines with fluctuating reward and punishment outcomes during safety and stress. We predicted that anxious individuals under stress would learn faster about punishments and exhibit choices that were more affected by those punishments, thus formalizing our predictions as parameters in reinforcement learning accounts of behaviour. Overall, the data suggest that anxious individuals are quicker to update their behaviour in response to negative outcomes (increased punishment learning rates). When treating anxiety, it may therefore be more fruitful to encourage anxious individuals to integrate information over longer horizons when bad things happen, rather than try to blunt their responses to negative outcomes.","link":"/opendata/aylward-et-al-2019/"},{"title":"Bach (2015)","text":"Behavioural inhibition is a key anxiety-like behaviour in rodents and humans, distinct from avoidance of danger, and reduced by anxiolytic drugs. In some situations, it is not clear how behavioural inhibition minimises harm or maximises benefit for the agent, and can even appear counterproductive. Extant explanations of this phenomenon make use of descriptive models but do not provide a formal assessment of its adaptive value. This hampers a better understanding of the neural computations underlying anxiety behaviour. Here, we analyse a standard rodent anxiety model, the operant conflict test. We harvest Bayesian Decision Theory to show that behavioural inhibition normatively arises as cost-minimising strategy in temporally correlated environments. Importantly, only if behavioural inhibition is aimed at minimising cost, it depends on probability and magnitude of threat. Harnessing a virtual computer game, we test model predictions in four experiments with human participants. Humans exhibit behavioural inhibition with a strong linear dependence on threat probability and magnitude. Strikingly, inhibition occurs before motor execution and depends on the virtual environment, thus likely resulting from a neural optimisation process rather than a pre-programmed mechanism. Individual trait anxiety scores predict behavioural inhibition, underlining the validity of this anxiety model. These findings put anxiety behaviour into the context of cost-minimisation and optimal inference, and may ultimately pave the way towards a mechanistic understanding of the neural computations gone awry in human anxiety disorder.","link":"/opendata/bach-2015/"},{"title":"Bach et al. (2020)","text":"During adolescence and early adulthood, learning when to avoid threats and when to pursue rewards becomes crucial. Using a risky foraging task, we investigated individual differences in this dynamic across 781 individuals aged 14-24 years who were split into a hypothesis-generating discovery sample and a hold-out confirmation sample. Sex was the most important predictor of cautious behaviour and performance. Males earned one standard deviation (or 20%) more reward than females, collected more reward when there was little to lose and reduced foraging to the same level as females when potential losses became high. Other independent predictors of cautiousness and performance were self-reported daringness, IQ and self-reported cognitive complexity. We found no evidence for an impact of age or maturation. Thus, maleness, a high IQ or self-reported cognitive complexity, and self-reported daringness predicted greater success in risky foraging, possibly due to better exploitation of low-risk opportunities in high-risk environments.","link":"/opendata/bach-et-al-2020/"},{"title":"Bae & Luck (2019)","text":"Recent experiences influence the processing of new information even when those experiences are irrelevant to the current task. Does this reflect the indirect effects of a passively maintained representation of the previous experience, or is this representation reactivated when a new event occurs? To answer this question, we attempted to decode the orientation of the stimulus on the previous trial from the electroencephalogram on the current trial in a working memory task. Behavioral data confirmed that the previous-trial stimulus orientation influenced the reported orientation on the current trial, even though the previous-trial orientation was now task irrelevant. In two independent experiments, we found that the previous-trial orientation could be decoded from the current-trial electroencephalogram, indicating that the current-trial stimulus reactivated or boosted the representation of the previous-trial orientation. These results suggest that the effects of recent experiences on behavior are driven, in part, by a reactivation of those experiences and not solely by the indirect effects of passive memory traces.","link":"/opendata/bae-luck-2019/"},{"title":"Bahrami & Navajas (2020)","text":"The dataset includes 975 participants, who completed an online version of the4-arm bandit task in 2014. All participants gave their consent to carry the experiment. The experiment was approved by UCLResearch Ethics Committee(project 4223/001). The dataset is anonymised, and does not include information about the participants identity. The task followed the 4-arm bandit paradigm described in Daw et al. 2006. In this task the participants were asked to choose between four options on multiple trials. On each trial they had to choose an option and were then given information about the reward obtained by their choice. The rewards of each option drifted over time, in a manner also known as restless bandit, forcing the participants to constantly explore the different options to obtain the maximum reward. The rewards followed one of three drift schedules which were predefined, see below.The experiment lasted 150 trials. Participants failing to response within 4 seconds missed the trial and moved to the next one with no reward.","link":"/opendata/bahrami-navajas-2020/"},{"title":"Balasubramani et al. (2021)","text":"Choice selection strategies and decision making are typically investigated using multiple-choice gambling paradigms that require participants to maximize reward payoff. However, research shows that performance in such paradigms suffers from individual biases towards the frequency of gains to choose smaller local gains over larger longer term gain, also referred to as melioration. Here, we developed a simple two-choice reward task, implemented in 186 healthy human adult subjects across the adult lifespan to understand the behavioral, computational, and neural bases of payoff maximization versus melioration. The observed reward choice behavior on this task was best explained by a reinforcement learning model of differential future reward prediction. Simultaneously recorded and source-localized electroencephalography (EEG) showed that diminished theta-band activations in the right rostral anterior cingulate cortex (rACC) correspond to greater reward payoff maximization, specifically during the presentation of cumulative reward information at the end of each task trial. Notably, these activations (greater rACC theta) predicted depressed mood symptoms, thereby showcasing a reward processing marker of potential clinical utility. This study presents cognitive, computational and neural (EEG-based) analyses of a rapid reward-based decision-making task. The research has the following three highlights. 1) It teases apart two core aspects of reward processing, i.e. long term expected value maximization versus immediate gain frequency melioration based choice behavior. 2) It models reinforcement learning based behavioral differences between individuals showing that observed performance is best explained by differential extents of reward prediction. 3) It investigates neural correlates in 186 healthy human subjects across the adult lifespan, revealing specific theta band cortical source activations in right rostral anterior cingulate as correlates for maximization that further predict depressed mood across subjects.","link":"/opendata/balasubramani-et-al-2021/"},{"title":"Ballard et al. (2019a)","text":"Animals rely on learned associations to make decisions. Associations can be based on relationships between object features (e.g., the three leaflets of poison ivy leaves) and outcomes (e.g., rash). More often, outcomes are linked to multidimensional states (e.g., poison ivy is green in summer but red in spring). Feature-based reinforcement learning fails when the values of individual features depend on the other features present. One solution is to assign value to multi-featural conjunctive representations. Here, we test if the hippocampus forms separable conjunctive representations that enables the learning of response contingencies for stimuli of the form: AB+, B-, AC-, C+. Pattern analyses on functional MRI data show the hippocampus forms conjunctive representations that are dissociable from feature components and that these representations, along with those of cortex, influence striatal prediction errors. Our results establish a novel role for hippocampal pattern separation and conjunctive representation in reinforcement learning.","link":"/opendata/ballard-et-al-2019a/"},{"title":"Ballard et al. (2019b)","text":"Much is known about the effects of reward and punishment on behavior, yet little research has considered how these incentives influence the information-processing dynamics that underlie decision making. We fitted the linear ballistic accumulator to data from a perceptual-judgment task to examine the impacts of reward- and punishment-based incentives on three distinct components of information processing: the quality of the information processed, the quantity of that information, and the decision threshold. The threat of punishment lowered the average quality and quantity of information processed, compared with the prospect of reward or no performance incentive at all. The threat of punishment also induced less cautious decision making by lowering people’s decision thresholds relative to the prospect of reward. These findings suggest that information-processing dynamics are determined not only by objective properties of the decision environment but also by the higher order goals of the system.","link":"/opendata/ballard-et-al-2019b/"},{"title":"Balter & Raymond (2022)","text":"Transfer of learning refers to successful application of previously acquired knowledge or skills to novel settings. Although working memory (WM) is thought to play a role in transfer learning, direct evidence of the effect of limitations in WM on transfer learning is lacking. To investigate, we used an acquired equivalence paradigm that included tests of association and transfer learning. The effects of imposing an acute WM limitation on young adults was tested (within-subjects design: N = 27 adults; Mage = 24 years) by conducting learning transfer tests concurrent with a secondary task that required carrying a spatial WM load when performing the learned/transfer trial (Load condition) to acutely limit WM resources or no WM load (No-Load condition; WM was unloaded prior to performing the learned/transfer trial). Analysis using mixed effects models showed that although success on the transfer trials was high in the No-Load condition, performance dropped significantly to chance in the Load condition. Performance on tests of learned associations remained high in both conditions. These results indicate that transfer of learning depends on access to WM resources and suggests that even healthy young individuals may be affected in their ability to cross-utilize when cognitive resources become scarce, such as when engaging in two tasks simultaneously (e.g., using satellite navigation while driving).","link":"/opendata/balter-raymond-2022/"},{"title":"Balzus et al. (2022)","text":"Overactive performance monitoring, as reflected by enhanced neural responses to errors (the error-related negativity, ERN), is considered a biomarker for obsessive-compulsive disorder (OCD) and may be a promising target for novel treatment approaches. Prior research suggests that non-invasive brain stimulation with transcranial direct current stimulation (tDCS) may reduce the ERN in healthy individuals, yet no study has investigated its efficacy in attenuating the ERN in OCD. In this preregistered, randomized, sham-controlled, crossover study, we investigated effects of tDCS on performance monitoring in patients with OCD (n = 28) and healthy individuals (n = 28). Cathodal and sham tDCS was applied over the presupplementary motor area (pre-SMA) in two sessions, each followed by electroencephalogram recording during a flanker task. Cathodal tDCS reduced the ERN amplitude compared to sham tDCS, albeit this effect was only marginally significant (p = .052; mean difference: 0.86 μV). Additionally, cathodal tDCS reduced the correct-response negativity and increased the error positivity. These neural modulations were not accompanied by behavioral changes. Moreover, we found no evidence that the tDCS effect was more pronounced in the patient group. In summary, our findings indicate that tDCS over the pre-SMA modulates neural correlates of performance monitoring across groups. Therefore, this study represents a valuable starting point for future research to determine whether repeated tDCS application induces a more pronounced ERN attenuation and normalizes aberrant performance monitoring in the long term, thereby potentially alleviating obsessive-compulsive symptoms and providing a psychophysiological intervention strategy for individuals who do not benefit sufficiently from existing interventions.","link":"/opendata/balzus-et-al-2022/"},{"title":"Bang et al. (2022)","text":"Computing confidence in ones own and others decisions is critical for social success. While there has been substantial progress in our understanding of confidence estimates about oneself, little is known about how people form confidence estimates about others. Here, we address this question by asking participants undergoing fMRI to place bets on perceptual decisions made by themselves or one of three other players of varying ability. We show that participants compute confidence in another players decisions by combining distinct estimates of player ability and decision difficulty - allowing them to predict that a good player may get a difficult decision wrong and that a bad player may get an easy decision right. We find that this computation is associated with an interaction between brain systems implicated in decision-making (LIP) and theory of mind (TPJ and dmPFC). These results reveal an interplay between self- and other-related processes during a social confidence computation.","link":"/opendata/bang-et-al-2022/"},{"title":"Barnby et al. (2022a)","text":"Theoretical accounts suggest heightened uncertainty about the state of the world underpins aberrant belief updates, which in turn increase the risk of developing a persecutory delusion. However, this raises the question as to how an agent’s uncertainty may relate to the precise phenomenology of paranoia, as opposed to other qualitatively different forms of belief. We tested whether the same population (n=693) responded similarly to non-social and social contingency changes in a probabilistic reversal learning task and a modified repeated reversal Dictator game, and the impact of paranoia on both. We fitted computational models that included closely related parameters that quantified the rigidity across contingency reversals and the uncertainty about the environment/partner. Consistent with prior work we show that paranoia was associated with uncertainty around a partner’s behavioural policy and rigidity in harmful intent attributions in the social task. In the non-social task we found that pre-existing paranoia was associated with larger decision temperatures and commitment to suboptimal cards. We show relationships between decision temperature in the non-social task and priors over harmful intent attributions and uncertainty over beliefs about partners in the social task. Our results converge across both classes of model, suggesting paranoia is associated with a general uncertainty over the state of the world (and agents within it) that takes longer to resolve, although we demonstrate that this uncertainty is expressed asymmetrically in social contexts. Our model and data allow the representation of sociocognitive mechanisms that explain persecutory delusions and provide testable, phenomenologically relevant predictions for causal experiments.","link":"/opendata/barnby-et-al-2022a/"},{"title":"Barnby et al. (2022b)","text":"To benefit from social interactions, people need to predict how their social partners will behave. Such predictions arise through integrating prior expectations with evidence from observations, but where the priors come from and whether they influence the integration into beliefs about a social partner is not clear. Furthermore, this process can be affected by factors such as paranoia, in which the tendency to form biased impressions of others is common. Using a modified social value orientation (SVO) task in a large online sample (n = 697), we showed that participants used a Bayesian inference process to learn about partners, with priors that were based on their own preferences. Paranoia was associated with preferences for earning more than a partner and less flexible beliefs regarding a partner’s social preferences. Alignment between the preferences of participants and their partners was associated with better predictions and with reduced attributions of harmful intent to partners. Together, our data and model expand upon theories of interpersonal relationships by demonstrating how dyadic similarity mechanistically influences social interaction by generating more accurate predictions and less threatening impressions.","link":"/opendata/barnby-et-al-2022b/"},{"title":"Bavard et al. (2018)","text":"In economics and perceptual decision-making contextual effects are well documented, where decision weights are adjusted as a function of the distribution of stimuli. Yet, in reinforcement learning literature whether and how contextual information pertaining to decision states is integrated in learning algorithms has received comparably little attention. Here, we investigate reinforcement learning behavior and its computational substrates in a task where we orthogonally manipulate outcome valence and magnitude, resulting in systematic variations in state-values. Model comparison indicates that subjects behavior is best accounted for by an algorithm which includes both reference point-dependence and range-adaptation-two crucial features of state-dependent valuation. In addition, we find that state-dependent outcome valuation progressively emerges, is favored by increasing outcome information and correlated with explicit understanding of the task structure. Finally, our data clearly show that, while being locally adaptive (for instance in negative valence and small magnitude contexts), state-dependent valuation comes at the cost of seemingly irrational choices, when options are extrapolated out from their original contexts.","link":"/opendata/bavard-et-al-2018/"},{"title":"Bavard et al. (2021)","text":"Evidence suggests that economic values are rescaled as a function of the range of the available options. Although locally adaptive, range adaptation has been shown to lead to suboptimal choices, particularly notable in reinforcement learning (RL) situations when options are extrapolated from their original context to a new one. Range adaptation can be seen as the result of an adaptive coding process aiming at increasing the signal-to-noise ratio. However, this hypothesis leads to a counterintuitive prediction: Decreasing task difficulty should increase range adaptation and, consequently, extrapolation errors. Here, we tested the paradoxical relation between range adaptation and performance in a large sample of participants performing variants of an RL task, where we manipulated task difficulty. Results confirmed that range adaptation induces systematic extrapolation errors and is stronger when decreasing task difficulty. Last, we propose a range-adapting model and show that it is able to parsimoniously capture all the behavioral results.","link":"/opendata/bavard-et-al-2021/"},{"title":"Bejjani et al. (2022)","text":"Cognitive control is guided by learning, as people adjust control to meet changing task demands. The two best-studied instances of control-learning are the enhancement of attentional task focus in response to increased frequencies of incongruent distracter stimuli, reflected in the list-wide proportion congruent (LWPC) effect, and the enhancement of switch-readiness in response to increased frequencies of task switches, reflected in the list-wide proportion switch (LWPS) effect. However, the latent architecture underpinning these adaptations in cognitive stability and flexibility - specifically, whether there is a single, domain-general, or multiple, domain-specific learners - is currently not known. To reveal the underlying structure of control-learning, we had a large sample of participants (N = 950) perform LWPC and LWPS paradigms, and afterwards assessed their explicit awareness of the task manipulations, as well as general cognitive ability and motivation. Structural equation modeling was used to evaluate several preregistered models representing different plausible hypotheses concerning the latent structure of control-learning. Task performance replicated standard LWPC and LWPS effects. Crucially, the model that best fit the data had correlated domain- and context-specific latent factors. Thus, peoples ability to adapt their on-task focus and between-task switch-readiness to changing levels of demand was mediated by distinct (though correlated) underlying factors. Model fit remained good when accounting for speed-accuracy trade-offs, variance in individual cognitive ability and self-reported motivation, as well as self-reported explicit awareness of manipulations and the order in which different levels of demand were experienced. Implications of these results for the cognitive architecture of dynamic cognitive control are discussed.","link":"/opendata/bejjani-et-al-2022/"},{"title":"Bellana et al. (2022)","text":"Some experiences linger in mind, spontaneously returning to our thoughts for minutes after their conclusion. Other experiences fall out of mind immediately. It remains unclear why. We hypothesize that an input is more likely to persist in our thoughts when it has been deeply processed: when we have extracted its situational meaning rather than its physical properties or low-level semantics. Here, participants read sequences of words with different levels of coherence (word-, sentence-, or narrative-level). We probe participants spontaneous thoughts via free word association, before and after reading. By measuring lingering subjectively (via self-report) and objectively (via changes in free association content), we find that information lingers when it is coherent at the narrative level. Furthermore, and an individuals feeling of transportation into reading material predicts lingering better than the materials objective coherence. Thus, our thoughts in the present moment echo prior experiences that have been incorporated into deeper, narrative forms of thinking.","link":"/opendata/bellana-et-al-2022/"},{"title":"Beltzer et al. (2019)","text":"Adaptive social behavior requires learning probabilities of social reward and punishment, and updating these probabilities when they change. Given prior research on aberrant reinforcement learning in affective disorders, this study examines how social anxiety affects probabilistic social reinforcement learning and dynamic updating of learned probabilities in a volatile environment. N=222 online participants completed questionnaires and a computerized ball-catching game with changing probabilities of reward and punishment. Dynamic learning rates were estimated to assess the relative importance ascribed to new information in response to volatility. Mixed-effects regression was used to analyze throw patterns as a function of social anxiety symptoms. Higher social anxiety predicted fewer throws to the previously punishing avatar and different learning rates after certain role changes, suggesting that social anxiety may be characterized by difficulty updating learned social probabilities. Socially anxious individuals may miss the chance to learn that a once-punishing situation no longer poses a threat.","link":"/opendata/beltzer-et-al-2019/"},{"title":"Ben Artzi & Shahar (2021)","text":"178 prolific workers completed an online experiment in return for monetary compensation. Participants completed a Reinforcement Learning task of four cards and two reward conditions. On each trial of the task, two cards of the four were offered by the computer, and participants were asked to pick one. Each card could lead to a reward on an independent drifting probability across trials. The difference between conditions was in whether participants won extra points or avoided the loss of points. All participants completed the OCI-R, and a partial sample also completed BDI, STAI, and SPQ.","link":"/opendata/ben-artzi-shahar-2021/"},{"title":"Ben Artzi et al. (2022a)","text":"To establish accurate action-outcome associations in the environment, individuals must refrain from assigning value to outcome-irrelevant features. However, reinforcement learning studies have largely ignored the role of attentional control processes on credit assignment (the process of assigning value to one’s actions). In the current study, we examined the extent to which working memory – a system that can filter and block the processing of irrelevant information in one’s mind – predicted credit assignment to outcome-irrelevant task features. One hundred and seventy-four individuals completed working memory capacity and outcome-irrelevant learning estimates. Outcome-irrelevant learning was estimated in a reinforcement learning task where only stimulus’ visual features predicted reward, but not the response keys used to indicate one’s selection. As expected, we found a consistent tendency to assign value to the tasks’ response keys, reflecting outcome-irrelevant learning at the group level. However, we also found substantial individual differences, such that only 55% of participants demonstrated this effect. Importantly, working memory capacity significantly moderated individual differences in outcome-irrelevant learning; individuals with higher capacity were less likely to assign credit to the outcome-irrelevant feature (i.e., response key). We discuss the influence of working memory on outcome-irrelevant learning through the perspective of cognitive control failure.","link":"/opendata/ben-artzi-et-al-2022a/"},{"title":"Ben Artzi et al. (2022b)","text":"Current studies suggest that individuals estimate the value of their choices based on observed feedback. Here, we ask whether individuals update the value of their unchosen actions, even when the associated feedback remains unknown. Two hundred and three individuals completed a multi-armed bandit task, making choices to gain rewards. We found robust evidence suggesting inverse value updating for unchosen actions based on the chosen action’s outcome. Computational modeling results suggested that this effect is mainly explained by a value updating mechanism whereby individuals integrate the outcome history for choosing an option with that of avoiding the alternative. Properties of the deliberation (i.e., duration/difficulty) did not moderate the latent value updating of unchosen actions, suggesting that memory traces generated during deliberation take a smaller role in this phenomenon than previously thought. We discuss the mechanisms facilitating credit assignment to unchosen actions and their implications for human decision-making.","link":"/opendata/ben-artzi-et-al-2022b/"},{"title":"Bennett et al. (2021)","text":"Aversion to uncertainty about the future has been proposed as a transdiagnostic trait underlying psychiatric diagnoses including obsessive-compulsive disorder and generalized anxiety. This association might explain the frequency of pathological information-seeking behaviors such as compulsive checking and reassurance-seeking in these disorders. Here we tested the behavioral predictions of this model using a noninstrumental information-seeking task that measured preferences for unusable information about future outcomes in different payout domains (gain, loss, and mixed gain/loss). We administered this task, along with a targeted battery of self-report questionnaires, to a general-population sample of 146 adult participants. Using computational cognitive modeling of choices to test competing theories of information valuation, we found evidence for a model in which preferences for costless and costly information about future outcomes were independent, and in which information preference was modulated by both outcome mean and outcome variance. Critically, we also found positive associations between a model parameter controlling preference for costly information and individual differences in latent traits of both anxiety and obsessive-compulsion. These associations were invariant across different payout domains, providing evidence that individuals high in obsessive-compulsive and anxious traits show a generalized increase in willingness-to-pay for unusable information about uncertain future outcomes, even though this behavior reduces their expected future reward.","link":"/opendata/bennett-et-al-2021/"},{"title":"Bennett, Radulescu et al. (2021)","text":"Positive and negative affective states are respectively associated with optimistic and pessimistic expectations regarding future reward. One mechanism that might underlie these affect-related expectation biases is attention to positive- versus negative-valence stimulus features (e.g., attending to the positive reviews of a restaurant versus its expensive price). Here we tested the effects of experimentally induced positive and negative affect on feature-based attention in 120 participants completing a compound-generalization task with eye-tracking. We found that participants reward expectations for novel compound stimuli were modulated by the affect induction in an affect-congruent way: positive affect increased reward expectations for compounds, whereas negative affect decreased reward expectations. Computational modelling and eye-tracking analyses each revealed that these effects were driven by affect-congruent changes in participants allocation of attention to high- versus low-value features of compound stimuli. These results provide mechanistic insight into a process by which affect produces biases in generalized reward expectations.","link":"/opendata/bennett-radulescu-et-al-2021/"},{"title":"Benwell et al. (2022)","text":"Human behaviours are guided by how confident we feel in our abilities. When confidence does not reflect objective performance, this can impact critical adaptive functions and impair life quality. Distorted decision-making and confidence have been associated with mental health problems. Here, utilising advances in computational and transdiagnostic psychiatry, we sought to map relationships between psychopathology and both decision-making and confidence in the general population across two online studies (N’s = 344 and 473, respectively). The results revealed dissociable decision-making and confidence signatures related to distinct symptom dimensions. A dimension characterised by compulsivity and intrusive thoughts was found to be associated with reduced objective accuracy but, paradoxically, increased absolute confidence, whereas a dimension characterized by anxiety and depression was associated with systematically low confidence in the absence of impairments in objective accuracy. These relationships replicated across both studies and distinct cognitive domains (perception and general knowledge), suggesting that they are reliable and domain general. Additionally, whereas Big-5 personality traits also predicted objective task performance, only symptom dimensions related to subjective confidence. Domain-general signatures of decision-making and metacognition characterise distinct psychological dispositions and psychopathology in the general population and implicate confidence as a central component of mental health.","link":"/opendata/benwell-et-al-2022/"},{"title":"Bertram et al. (2021)","text":"Information about risks and probabilities is ubiquitous in our environment, forming the basis for decisions in an uncertain world. Emotions are known to modulate subjective probability assessments when probabilistic information is emotionally valenced. Yet little is known about the role of emotions in subjective probability assessment of affectively neutral events. We investigated this in one correlational study (Study 1, N = 162) and one experimental study (Study 2, N = 119). As predicted, we found that emotional dominance modulated the degree of conservatism in respondents’ neutral probability estimates. Remarkably, this pattern also transferred to realistic risk assessments. Furthermore, respondents’ tendency to use the representativeness heuristic as a proxy for probability was increased in high dominance individuals. Our findings highlight the importance of considering emotions, particularly the little-understood emotion dimension dominance, in research on probabilistic cognition.","link":"/opendata/bertram-et-al-2021/"},{"title":"Bioud et al. (2022)","text":"To decide whether a course of action is worth pursuing, individuals typically weigh its expected costs and benefits. Optimal decision-making relies upon accurate effort cost anticipation, which is generally assumed to be performed independently from goal valuation. In two experiments (n = 46), we challenged this independence principle of standard decision theory. We presented participants with a series of treadmill routes randomly associated to monetary rewards and collected both accept versus decline decisions and subjective estimates of energetic cost. Behavioural results show that higher monetary prospects led participants to provide higher cost estimates, although reward was independent from effort in our design. Among candidate cognitive explanations, they support a model in which prospective cost assessment is biased by the output of an automatic computation adjusting effort expenditure to goal value. This decision bias might lead people to abandon the pursuit of valuable goals that are in fact not so costly to achieve.","link":"/opendata/bioud-et-al-2022/"},{"title":"Bisschop (2021)","text":"Database of cognitive control task data (e.g., Stroop, Flanker tasks).","link":"/opendata/bisschop-2021/"},{"title":"Blain & Rutledge (2020)","text":"Subjective well-being or happiness is often associated with wealth. Recent studies suggest that momentary happiness is associated with reward prediction error, the difference between experienced and predicted reward, a key component of adaptive behaviour. We tested subjects in a reinforcement learning task in which reward size and probability were uncorrelated, allowing us to dissociate between the contributions of reward and learning to happiness. Using computational modelling, we found convergent evidence across stable and volatile learning tasks that happiness, like behaviour, is sensitive to learning-relevant variables (i.e. probability prediction error). Unlike behaviour, happiness is not sensitive to learning-irrelevant variables (i.e. reward prediction error). Increasing volatility reduces how many past trials influence behaviour but not happiness. Finally, depressive symptoms reduce happiness more in volatile than stable environments. Our results suggest that how we learn about our world may be more important for how we feel than the rewards we actually receive.","link":"/opendata/blain-rutledge-2020/"},{"title":"Bogdanov et al. (2021)","text":"Adverse effects following acute stress are traditionally thought to reflect functional impairments of central executive-dependent cognitive-control processes. However, recent evidence demonstrates that cognitive-control application is perceived as effortful and aversive, indicating that stress-related decrements in cognitive performance could denote decreased motivation to expend effort instead. To investigate this hypothesis, we tested 40 young, healthy individuals (20 female, 20 male) under both stress and control conditions in a 2-day study that had a within-subjects design. Cognitive-effort avoidance was assessed using the demand-selection task, in which participants chose between performing low-demand and high-demand variants of a task-switching paradigm. We found that acute stress indeed increased participants preference for less demanding behavior, whereas task-switching performance remained intact. Additional Bayesian and multiverse analyses confirmed the robustness of this effect. Our findings provide novel insights into how stressful experiences shape behavior by modulating our motivation to employ cognitive control.","link":"/opendata/bogdanov-et-al-2021/"},{"title":"Bolenz et al. (2019)","text":"Humans employ different strategies when making decisions. Previous research has reported reduced reliance on model-based strategies with aging, but it remains unclear whether this is due to cognitive or motivational factors. Moreover, it is not clear how aging affects the metacontrol of decision making, that is the dynamic adaptation of decision-making strategies to varying situational demands. In this cross-sectional study, we tested younger and older adults in a sequential decision-making task that dissociates model-free and model-based strategies. In contrast to previous research, model-based strategies led to higher payoffs. Moreover, we manipulated the costs and benefits of model-based strategies by varying reward magnitude and the stability of the task structure. Compared to younger adults, older adults showed reduced model-based decision making and less adaptation of decision-making strategies. Our findings suggest that aging affects the metacontrol of decision-making strategies and that reduced model-based strategies in older adults are due to limited cognitive abilities.","link":"/opendata/bolenz-et-al-2019/"},{"title":"Bolenz & Eppinger (2021)","text":"The development of metacontrol of decision making and its susceptibility to framing effects were investigated in a sample of 201 adolescents and adults in Germany (12-25 years, 111 female, ethnicity not recorded). In a task that dissociates model-free and model-based decision making, outcome magnitude and outcome valence were manipulated. Both adolescents and adults showed metacontrol and metacontrol tended to increase across adolescence. Furthermore, model-based decision making was more pronounced for loss compared to gain frames but there was no evidence that this framing effect differed with age. Thus, the strategic adaptation of decision making continues to develop into young adulthood and for both adolescents and adults, losses increase the motivation to invest cognitive resources into an effortful decision-making strategy.","link":"/opendata/bolenz-eppinger-2021/"},{"title":"Bolenz et al. (2022)","text":"Humans show metacontrol of decision making, that is they adapt their reliance on decision-making strategies toward situational differences such as differences in reward magnitude. Specifically, when higher rewards are at stake, individuals increase reliance on a more accurate but cognitively effortful strategy. We investigated whether the personality trait Need for Cognition (NFC) explains individual differences in metacontrol. Based on findings of cognitive effort expenditure in executive functions, we expected more metacontrol in individuals low in NFC. In two independent studies, metacontrol was assessed by means of a decision-making task that dissociates different reinforcement-learning strategies and in which reward magnitude was manipulated across trials. In contrast to our expectations, NFC did not account for individual differences in metacontrol of decision making. In fact, a Bayesian analysis provided moderate to strong evidence against a relationship between NFC and metacontrol. Beyond this, there was no consistent evidence for relationship between NFC and overall model-based decision making. These findings show that the effect of rewards on the engagement of effortful decision-making strategies is largely independent of the intrinsic motivation for engaging in cognitively effortful tasks and suggest a differential role of NFC for the regulation of cognitive effort in decision making and executive functions.","link":"/opendata/bolenz-et-al-2022/"},{"title":"Bond et al. (2021)","text":"In uncertain or unstable environments, sometimes the best decision is to change your mind. To shed light on this flexibility, we evaluated how the underlying decision policy adapts when the most rewarding action changes. Human participants performed a dynamic two-armed bandit task that manipulated the certainty in relative reward (conflict) and the reliability of action-outcomes (volatility). Continuous estimates of conflict and volatility contributed to shifts in exploratory states by changing both the rate of evidence accumulation (drift rate) and the amount of evidence needed to make a decision (boundary height), respectively. At the trialwise level, following a switch in the optimal choice, the drift rate plummets and the boundary height weakly spikes, leading to a slow exploratory state. We find that the drift rate drives most of this response, with an unreliable contribution of boundary height across experiments. Surprisingly, we find no evidence that pupillary responses associated with decision policy changes. We conclude that humans show a stereotypical shift in their decision policies in response to environmental changes.","link":"/opendata/bond-et-al-2021/"},{"title":"Boschet et al. (2022)","text":"Conflicts between avoiding feared stimuli versus approaching them for competing rewards are essential for functional behavior and anxious psychopathology. Yet, little is known about the underlying decision process. We examined approach-avoidance decisions and their temporal dynamics when avoiding Pavlovian fear stimuli conflicted with gaining rewards. First, a formerly neutral stimulus (CS+) was repeatedly paired with an aversive stimulus (US) to establish Pavlovian fear. Another stimulus (CS-) was never paired with the US. A control group received neutral tones instead of aversive USs. Next, in each of 324 trials, participants chose between a CS-/low reward and a CS+/high reward option. For the latter, probability of CS+ presentation (Pavlovian fear information) and reward magnitude (reward information) varied. Computer mouse movements were tracked to capture the decision dynamics. Although no more USs occurred, pronounced and persistent costly avoidance of the Pavlovian fear CS+ was found. Time-continuous multiple regression of movement trajectories revealed a stronger and faster impact of Pavlovian fear compared to reward information during decision-making. The impact of fear information, but not reward information, modestly decreased across trials. These findings suggest a persistently stronger weighting of fear compared to reward information during approach-avoidance decisions, which may facilitate the development of pathological avoidance.","link":"/opendata/boschet-et-al-2022/"},{"title":"Bradshaw & McGettigan (2021)","text":"Recent research suggests that reinforcement learning may underlie trait formation in social interactions with faces. The current study investigated whether the same learning mechanisms could be engaged for trait learning from voices. On each trial of a training phase, participants (N = 192) chose from pairs of human or slot machine targets that varied in the (1) reward value and (2) generosity of their payouts. Targets were either auditory (voices or tones; Experiment 1) or visual (faces or icons; Experiment 2) and were presented sequentially before payout feedback. A test phase measured participant choice behaviour, and a post-test recorded their target preference ratings. For auditory targets, we found a significant effect of reward only on target choices, but saw higher preference ratings for more generous humans and slot machines. For visual targets, findings from previous studies were replicated: participants learned about both generosity and reward, but generosity was prioritised in the human condition. These findings provide one of the first demonstrations of reinforcement learning of reward with auditory stimuli in a social learning task, but suggest that the use of auditory targets does alter learning in this paradigm. Conversely, reinforcement learning of reward and trait information with visual stimuli remains intact even when sequential presentation introduces a delay in feedback.","link":"/opendata/bradshaw-mcgettigan-2021/"},{"title":"Braun et al. (2018)","text":"Many decisions are based on an internal model of the world. Yet, how such a model is constructed from experience and represented in memory remains unknown. We test the hypothesis that reward shapes memory for sequences of events by retroactively prioritizing memory for objects as a function of their distance from reward. Human participants encountered neutral objects while exploring a series of mazes for reward. Across six data sets, we find that reward systematically modulates memory for neutral objects, retroactively prioritizing memory for objects closest to the reward. This effect of reward on memory emerges only after a 24-hour delay and is stronger for mazes followed by a longer rest interval, suggesting a role for post-reward replay and overnight consolidation, as predicted by neurobiological data in animals. These findings demonstrate that reward retroactively prioritizes memory along a sequential gradient, consistent with the role of memory in supporting adaptive decision-making.","link":"/opendata/braun-et-al-2018/"},{"title":"Breslav et al. (2022)","text":"As children age, they can learn increasingly complex features of environmental structure-a key prerequisite for adaptive decision-making. Yet when we tested children (N = 304, 4-13 years old) in the Children’s Gambling Task, an age-appropriate variant of the Iowa Gambling Task, we found that age was negatively associated with performance. However, this paradoxical effect of age was found only in children who exhibited a maladaptive deplete-replenish bias, a tendency to shift choices after positive outcomes and repeat choices after negative outcomes. We found that this bias results from sensitivity to incidental nonrandom structure in the canonical, deterministic forms of these tasks-and that it would actually lead to optimal outcomes if the tasks were not deterministic. Our results illustrate that changes in decision-making across early childhood reflect, in part, increasing sensitivity to environmental structure.","link":"/opendata/breslav-et-al-2022/"},{"title":"Brown et al. (2022)","text":"When navigating uncertain worlds, humans must balance exploring new options versus exploiting known rewards. Longer horizons and spatially structured option values encourage humans to explore, but the impact of real-world cognitive constraints such as environment size and memory demands on explore-exploit decisions is unclear. In the present study, humans chose between options varying in uncertainty during a multi-armed bandit task with varying environment size and memory demands. Regression and cognitive computational models of choice behavior showed that with a lower cognitive load, humans are more exploratory than a simulated value-maximizing learner, but under cognitive constraints, they adaptively scale down exploration to maintain exploitation. Thus, while humans are curious, cognitive constraints force people to decrease their strategic exploration in a resource-rational-like manner to focus on harvesting known rewards.","link":"/opendata/brown-et-al-2022/"},{"title":"Bruder et al. (2021a)","text":"In recent years the emergence of high-performance virtual reality (VR) technology has opened up new possibilities for the examination of context effects in psychological studies. The opportunity to create ecologically valid stimulation in a highly controlled lab environment is especially relevant for studies of psychiatric disorders, where it can be problematic to confront participants with certain stimuli in real life. However, before VR can be confidently applied widely it is important to establish that commonly used behavioral tasks generate reliable data within a VR surrounding. One field of research that could benefit greatly from VR-applications are studies assessing the reactivity to addiction related cues (cue-reactivity) in participants suffering from gambling disorder. Here we tested the reliability of a commonly used temporal discounting task in a novel VR set-up designed for the concurrent assessment of behavioral and psychophysiological cue-reactivity in gambling disorder. On 2 days, thirty-four healthy non-gambling participants explored two rich and navigable VR-environments (neutral: café vs. gambling-related: casino and sports-betting facility), while their electrodermal activity was measured using remote sensors. In addition, participants completed the temporal discounting task implemented in each VR environment. On a third day, participants performed the task in a standard lab testing context. We then used comprehensive computational modeling using both standard softmax and drift diffusion model (DDM) choice rules to assess the reliability of discounting model parameters assessed in VR. Test-retest reliability estimates were good to excellent for the discount rate log(k), whereas they were poor to moderate for additional DDM parameters. Differences in model parameters between standard lab testing and VR, reflecting reactivity to the different environments, were mostly numerically small and of inconclusive directionality. Finally, while exposure to VR generally increased tonic skin conductance, this effect was not modulated by the neutral versus gambling-related VR-environment. Taken together this proof-of-concept study in non-gambling participants demonstrates that temporal discounting measures obtained in VR are reliable, suggesting that VR is a promising tool for applications in computational psychiatry, including studies on cue-reactivity in addiction.","link":"/opendata/bruder-et-al-2021a/"},{"title":"Bruder et al. (2021b)","text":"High-performance virtual reality (VR) technology has opened new possibilities for the examination of the reactivity towards addiction-related cues (cue-reactivity) in addiction. In this preregistered study (https://osf.io/4mrta), we investigated the subjective, physiological, and behavioral effects of gambling-related VR environment exposure in participants reporting frequent or pathological gambling (n=31) as well as non-gambling controls (n=29). On two separate days, participants explored two rich and navigable VR-environments (neutral: café vs. gambling-related: casino/sports-betting facility), while electrodermal activity and heart rate were continuously measured using remote sensors. Within VR, participants performed a temporal discounting task and a sequential decision-making task designed to assess model-based and model-free contributions to behavior. Replicating previous findings, we found strong evidence for increased temporal discounting and reduced model-based control in participants reporting frequent or pathological gambling. Although VR gambling environment exposure increased subjective craving, there was if anything inconclusive evidence for further behavioral or physiological effects. Instead, VR exposure substantially increased physiological arousal (electrodermal activity), across groups and conditions. VR is a promising tool for the investigation of context effects in addiction, but some caution is warranted since effects of real gambling environments might not generally replicate in VR. Future studies should delineate how factors such as cognitive load and ecological validity could be balanced to create a more naturalistic VR experience.","link":"/opendata/bruder-et-al-2021b/"},{"title":"Burleigh et al. (2022)","text":"Many symptoms of anxiety and posttraumatic stress disorder are elicited by fearful mental imagery. Yet little is known about how visual imagery of conditioned stimuli (CSs) affects the acquisition of differential fear conditioning. Across three experiments with younger human adults (Experiment 1: n = 33, Experiment 2: n = 27, Experiment 3: n = 26), we observed that participants acquired differential fear conditioning to both viewed and imagined percepts serving as the CSs, as measured via self-reported fear and skin conductance responses. Additionally, this differential conditioning generalized across CS-percept modalities such that differential conditioning acquired in response to visual percepts generalized to the corresponding imagined percepts and vice versa. This is novel evidence that perceived and imagined stimuli engage learning processes in very similar ways and is consistent with the theory that mental imagery is depictive and recruits neural resources shared with visual perception. Our findings also provide new insight into the mechanisms of anxiety and related disorders.","link":"/opendata/burleigh-et-al-2022/"},{"title":"Byrne et al. (2020a)","text":"Previous research suggests that depressive symptoms are associated with altered sensitivity to reward and punishment in various decision-making contexts. Building on this work, this study investigated whether depressed-affect symptoms influenced risky decision making under time pressure. The effect of depressed affect on risky choice was assessed in a reward (Experiments 1A and 1B) and loss (Experiment 2) context under low- and high-pressure conditions. Decisions involved learning to choose between a “sure” option and a “risky” option with identical expected values. In Experiment 1A, depressed affect predicted increased risky decision making under time pressure but did not affect decision making under low pressure. Experiment 1B replicated this effect. In contrast, in Experiment 2, depressed affect led to reduced risk taking in low-pressure condition but did not affect decision making under high pressure. These results suggest that the pattern of risky decision making among those experiencing symptoms of depressed affect depends on performance pressure demands.","link":"/opendata/byrne-et-al-2020a/"},{"title":"Byrne et al. (2020b)","text":"Acute stress has been shown to influence reward sensitivity, feedback learning, and risk-taking during decision-making, primarily through activation of the hypothalamic pituitary axis (HPA). However, it is unclear how acute stress affects decision-making among choices that vary in their degree of uncertainty. To address this question, we conducted two experiments in which participants repeatedly chose between two options-a high-uncertainty option that offered highly variable rewards but was advantageous in the long-term, and a low-uncertainty option that offered smaller yet more consistent rewards. The Socially Evaluated Cold Pressor Task (SECPT) was utilized to induce acute stress. Participants in Experiment 1 (N = 114) were exposed to either the SECPT or a warm-water control condition and then completed the decision-making under uncertainty task. Compared to the control condition, those exposed to the acute stress manipulation chose the high-uncertainty option that provided highly variable but larger rewards over the option that provided stable, smaller rewards. Experiment 2 (N = 95) incorporated a salivary cortisol measure. Results replicated the behavioral findings in Experiment 1 and demonstrated that the acute stress manipulation increased salivary cortisol. This work suggests that moderate acute stress is associated with tolerance of outcome variability in contexts that depend on learning to maximize rewards.","link":"/opendata/byrne-et-al-2020b/"},{"title":"Cao & Tsetsos (2022)","text":"Decisions between two economic goods can be swayed by a third unavailable ‘decoy’ alternative, which does not compete for choice, notoriously violating the principles of rational choice theory. Although decoy effects typically depend on the decoy’s position in a multiattribute choice space, recent studies using risky prospects (i.e., varying in reward and probability) reported a novel ‘positive’ decoy effect operating on a single value dimension: the higher the ‘expected value’ (EV) of an unavailable (distractor) prospect was, the easier the discrimination between two available target prospects became, especially when their expected-value difference was small. Here, we show that this unidimensional distractor effect affords alternative interpretations: it occurred because the distractor’s EV covaried positively with the subjective utility difference between the two targets. Looking beyond this covariation, we report a modest ‘negative’ distractor effect operating on subjective utility, as well as classic multiattribute decoy effects. A normatively meaningful model (selective integration), in which subjective utilities are shaped by intra-attribute information distortion, reproduces the multiattribute decoy effects, and as an epiphenomenon, the negative unidimensional distractor effect. These findings clarify the modulatory role of an unavailable distracting option, shedding fresh light on the mechanisms that govern multiattribute decisions.","link":"/opendata/cao-tsetsos-2022/"},{"title":"Caron et al. (2020)","text":"Rosenbaum, Mama, and Algom (2017) reported that participants who completed the Stroop task (i.e., name the hue of a color word when the hue and word meaning are congruent or incongruent) showed a smaller Stroop effect (i.e., the difference in response times between congruent and incongruent trials) when they performed the task standing than when sitting. We report five attempted replications (analyzed sample sizes: N = 108, N = 108, N = 98, N = 78, and N = 51, respectively) of Rosenbaum et al.’s findings, which were conducted in two institutions. All experiments yielded the standard Stroop effect, but we failed to detect any consistent effect of posture (sitting vs. standing) on the magnitude of the Stroop effect. Taken together, the results suggest that posture does not influence the magnitude of the Stroop effect to the extent that was previously suggested.","link":"/opendata/caron-et-al-2020/"},{"title":"Castro-Rodrigues et al. (2022)","text":"Explicit information obtained through instruction profoundly shapes human choice behaviour. However, this has been studied in computationally simple tasks, and it is unknown how model-based and model-free systems, respectively generating goal-directed and habitual actions, are affected by the absence or presence of instructions. We assessed behaviour in a variant of a computationally more complex decision-making task, before and after providing information about task structure, both in healthy volunteers and in individuals suffering from obsessive-compulsive or other disorders. Initial behaviour was model-free, with rewards directly reinforcing preceding actions. Model-based control, employing predictions of states resulting from each action, emerged with experience in a minority of participants, and less in those with obsessive-compulsive disorder. Providing task structure information strongly increased model-based control, similarly across all groups. Thus, in humans, explicit task structural knowledge is a primary determinant of model-based reinforcement learning and is most readily acquired from instruction rather than experience.","link":"/opendata/castro-rodrigues-et-al-2022/"},{"title":"Cataldo et al. (2022)","text":"Healthy adults show better memory for low-arousal positive versus negative stimuli, but depression compromises this positive memory advantage. Existing studies are limited by small samples or analyses that provide limited insight into underlying mechanisms. Our study addresses these concerns by using a multistaged analysis, including diffusion modeling, to identify precise psychological processes underlying the positive memory advantage and its disruption by depression in a large sample. A total of 1,358 participants completed the BDI-II (Beck et al., 1996) and an emotional memory task. At encoding, participants judged whether positive and negative words were positive or self-descriptive. After a free recall test, participants viewed an equal mix of studied and unstudied words and judged whether each was old or new; if judged old, they indicated whether the study source was a valence or self-reference judgment. We replicate the positive memory advantage and its decrease in depression in recall, recognition, and source accuracy. The hierarchical drift diffusion model (HDDM; Wiecki et al., 2013) revealed that higher BDI-II scores are associated with more efficient evidence accumulation for negative words in the recognition and source memory tasks. By contrast, evidence accumulation for positive words is unaffected by BDI-II during the recognition task but becomes less efficient with increased BDI-II during the source memory task. In conclusion, in a well-controlled design with a large sample, we find that depression reduces the positive memory advantage. HDDM analyses suggest that this reflects differential effects of depression on the speed of evidence accumulation during the retrieval of positive versus negative memories.","link":"/opendata/cataldo-et-al-2022/"},{"title":"Caulfield et al. (2022)","text":"Worry is a repetitive, negative thought process that is widely experienced as difficult to control. Despite the adverse effects of uncontrollable worry on academic and other role functioning, the mechanisms by which worry becomes uncontrollable remain poorly understood. Previous experimental work has historically emphasized valence (negative versus positive or neutral). However, contemporary cognitive neuroscience also distinguishes between internally-directed attention (e.g., to thoughts) and externally-directed attention (e.g., to perceptual stimuli). To date, no studies have experimentally examined potential dissociable contributions of valence versus attentional direction to impaired disengagement from worry. In a 2 (negative or neutral valence) x 2 (internal or external attention) between-subjects, experimental and prospective design (https://osf.io/vdyfn/), participants (N = 200) completed alternating blocks of a randomly-assigned attention manipulation and validated sustained attention task. Participants also rated trait worry and distress during the experimental session (T1) and a naturalistic stressor (the week before finals; T2). There was a main effect, such that internally-directed attention impaired sustained attention (increased commission errors). Worry (internal x negative) also impaired sustained attention (faster and less accurate responding) in planned group contrasts. Trait worry did not moderate these effects. Sustained attention at T1 did not predict distress or worry during the T2 stressor. These findings augment the literature on the attentional consequences of worry and replicate and extend previous findings of altered speed-accuracy tradeoffs following experimentally-induced worry. We also find evidence for impaired disengagement from internally-directed (versus externally-directed) attention, which may help to explain impaired disengagement from related forms of perseverative thought (e.g., rumination).","link":"/opendata/caulfield-et-al-2022/"},{"title":"Cavallaro & Hawkins (2022)","text":"We investigated whether cognitive process models commonly studied in experimentalpsychology provide a deeper explanation of preferential choicesthan the descriptive random utility models commonly studied in the appliedchoice literature, with a specific focus on choices made under time pressure.In two preferential choice scenarios we used two standard manipulations oftime pressure to assess whether changes in decision time affect subjective valuationsof the features of preferential options, and whether the answer to thisquestion depends on the theoretical lens used to understand the data. Acrossfour experiments, we found that choices between preferential options and thetime taken to make them varied as a function of time pressure, reinforcingand generalising findings from lower-level perceptual decisions to higherlevelapplied choices. Critically, theoretical analyses from the two traditionsled to different psychological conclusions about how people adapted to timepressure. The random utility analyses suggested that time-pressure inducedchanges to choices were the result of changes in subjective valuations for thefeatures of preferential options. However, the cognitive process analyses attributedtime-pressure induced changes to choices to differential informationaccumulation; subjective valuations remained stable across contexts, againreinforcing decades of findings from the perceptual decision literature. Weargue that cognitive process models provide mechanistic explanations of theprocesses underlying decisions for preferential options. Furthermore, conventionaldescriptive models of choice in the applied literature may misattributevariability in choices to the incorrect latent cause, which has implications forout-of-sample prediction in the marketplace.","link":"/opendata/cavallaro-hawkins-2022/"},{"title":"Cavanagh et al. (2019)","text":"In this report, we provide the first evidence that mood and anxiety dimensions are associated with unique aspects of EEG responses to reward and punishment, respectively. We reanalyzed data from our prior publication of a categorical depiction of depression to address more sophisticated dimensional hypotheses. Highly symptomatic depressed individuals (N = 46) completed a probabilistic learning task with concurrent EEG. Measures of anxiety and depression symptomatology were significantly correlated with each other; however, only anxiety predicted better avoidance learning due to a tighter coupling of negative prediction error signaling with punishment-specific EEG features. In contrast, depression predicted a smaller reward-related EEG feature, but this did not affect prediction error coupling or the ability to learn from reward. We suggest that this reward-related alteration reflects motivational or hedonic aspects of reward and not a diminishment in the ability to represent the information content of reinforcements. These findings compel further research into the domain-specific neural systems underlying dimensional aspects of psychiatric disease.","link":"/opendata/cavanagh-et-al-2019/"},{"title":"Cavanagh (2021)","text":"Healthy control college students. 23 subjects completed the 3-armed bandit task with oscillating probabilities. For example, the ‘blue’ stim would slowly move from 20% reinforcing to 90% then back to 20 over many trials. The other ‘red’ and ‘green’ stims would move similarly, but in different phase. See Fig 1 of the paper. This makes the task great for investigating reward processing &amp; reward prediction error in the service of novel task set generation.","link":"/opendata/cavanagh-2021/"},{"title":"Cavanaugh et al. (2017)","text":"Individual differences in dopaminergic tone underlie tendencies to learn from reward versus punishment. These effects are well documented in Parkinsons patients, who vacillate between low and high tonic dopaminergic states as a function of medication. Yet very few studies have investigated the influence of higher-level cognitive states known to affect downstream dopaminergic learning in Parkinsons patients. A dopamine-dependent cognitive influence over learning would provide a candidate mechanism for declining cognitive integrity and motivation in Parkinsons patients. In this report we tested the influence of two high-level cognitive states (cost of conflict and value of volition) that have recently been shown to cause predictable learning biases in healthy young adults as a function of dopamine receptor subtype and dopaminergic challenge. It was hypothesized that Parkinsons patients OFF medication would have an enhanced cost of conflict and a decreased value of volition, and that these effects would be remediated or reversed ON medication. Participants included N = 28 Parkinsons disease patients who were each tested ON and OFF dopaminergic medication and 28 age- and sex-matched controls. The expected cost of conflict effect was observed in Parkinsons patients OFF versus ON medication, but only in those that were more recently diagnosed (&lt;5 years). We found an unexpected effect in the value of volition task: medication compromised the ability to learn from difficult a-volitional (instructed) choices. This novel finding was also enhanced in recently diagnosed patients. The difference in learning biases ON versus OFF medication between these two tasks was strongly correlated, bolstering the idea that they tapped into a common underlying imbalance in dopaminergic tone that is particularly variable in earlier stage Parkinsonism. The finding that these decision biases are specific to earlier but not later stage disease may offer a chance for future studies to quantify phenotypic expressions of idiosyncratic disease progression.","link":"/opendata/cavanaugh-et-al-2017/"},{"title":"Chambon et al. (2020)","text":"The valence of new information influences learning rates in humans: good news tends to receive more weight than bad news. We investigated this learning bias in four experiments, by systematically manipulating the source of required action (free versus forced choices), outcome contingencies (low versus high reward) and motor requirements (go versus no-go choices). Analysis of model-estimated learning rates showed that the confirmation bias in learning rates was specific to free choices, but was independent of outcome contingencies. The bias was also unaffected by the motor requirements, thus suggesting that it operates in the representational space of decisions, rather than motoric actions. Finally, model simulations revealed that learning rates estimated from the choice-confirmation model had the effect of maximizing performance across low- and high-reward environments. We therefore suggest that choice-confirmation bias may be adaptive for efficient learning of action-outcome contingencies, above and beyond fostering person-level dispositions such as self-esteem.","link":"/opendata/chambon-et-al-2020/"},{"title":"Charpentier et al. (2022)","text":"Seeking information when anxious may help reduce the aversive feeling of uncertainty and guide decision-making. If information is negative or confusing, however, this may increase anxiety further. Information gathered under anxiety can thus be beneficial and/or damaging. Here, we examine whether anxiety leads to a general increase in information-seeking, or rather to changes in the type of information and/or situations in which it is sought. In two controlled laboratory studies, we show that both trait anxiety and induced anxiety lead to a selective alteration in information-seeking. In particular, anxiety did not enhance the general tendency to seek information, nor did it alter the valence of the information gathered. Rather, anxiety amplified the tendency to seek information more in response to large changes in the environment. This was true even when the cause of the anxiety was not directly related to the information sought. As anxious individuals have been shown to have problems learning in changing environments, greater information-seeking in such environments may be an adaptive compensatory mechanism.","link":"/opendata/charpentier-et-al-2022/"},{"title":"Ciranka et al. (2022a)","text":"Humans and other animals are capable of inferring never-experienced relations (for example, A &gt; C) from other relational observations (for example, A &gt; B and B &gt; C). The processes behind such transitive inference are subject to intense research. Here we demonstrate a new aspect of relational learning, building on previous evidence that transitive inference can be accomplished through simple reinforcement learning mechanisms. We show in simulations that inference of novel relations benefits from an asymmetric learning policy, where observers update only their belief about the winner (or loser) in a pair. Across four experiments (n = 145), we find substantial empirical support for such asymmetries in inferential learning. The learning policy favoured by our simulations and experiments gives rise to a compression of values that is routinely observed in psychophysics and behavioural economics. In other words, a seemingly biased learning strategy that yields well-known cognitive distortions can be beneficial for transitive inferential judgements.","link":"/opendata/ciranka-et-al-2022a/"},{"title":"Ciranka & van den Bos (2022)","text":"Adolescents are known for their propensity to take risks, which may be especially strong in social contexts. People are known to use social information more when uncertain of how to decide. How feelings of uncertainty relate to the development of social susceptibility and risky choice across adolescence is unknown. To understand the effects of uncertainty on social influence, we introduce a novel task that measures risky choice under different levels of uncertainty, either with or without observing someone elses advice. Testing 161 adolescents and young adults (10-26 years of age), we show that risky-choice, social information use and subjective uncertainty decrease across development. We also fit a model wherein social information is used to reduce uncertainty to participants’ choices according to Bayesian principles. This model revealed that age-related changes in uncertainty fully accounted for age-related changes in social information use. Our results imply that uncertainty is a key mechanism in adolescents’ social susceptibility in risky behaviour.","link":"/opendata/ciranka-van-den-bos-2022/"},{"title":"Clay et al. (2022)","text":"Current models of mental effort in psychology, behavioral economics, and cognitive neuroscience typically suggest that exerting cognitive effort is aversive, and people avoid it whenever possible. The aim of this research was to challenge this view and show that people can learn to value and seek effort intrinsically. Our experiments tested the hypothesis that effort-contingent reward in a working-memory task will induce a preference for more demanding math tasks in a transfer phase, even though participants were aware that they would no longer receive any reward for task performance. In laboratory Experiment 1 (n = 121), we made reward directly contingent on mobilized cognitive effort as assessed via cardiovascular measures (β-adrenergic sympathetic activity) during the training task. Experiments 2a to 2e (n = 1,457) were conducted online to examine whether the effects of effort-contingent reward on subsequent demand seeking replicate and generalize to community samples. Taken together, the studies yielded reliable evidence that effort-contingent reward increased participants demand seeking and preference for the exertion of cognitive effort on the transfer task. Our findings provide evidence that people can learn to assign positive value to mental effort. The results challenge currently dominant theories of mental effort and provide evidence and an explanation for the positive effects of environments appreciating effort and individual growth on peoples evaluation of effort and their willingness to mobilize effort and approach challenging tasks.","link":"/opendata/clay-et-al-2022/"},{"title":"Cohen et al. (2020)","text":"Beliefs about the controllability of positive or negative events in the environment can shape learning throughout the lifespan. Previous research has shown that adults learning is modulated by beliefs about the causal structure of the environment such that they update their value estimates to a lesser extent when the outcomes can be attributed to hidden causes. This study examined whether external causes similarly influenced outcome attributions and learning across development. Ninety participants, ages 7 to 25 years, completed a reinforcement learning task in which they chose between two options with fixed reward probabilities. Choices were made in three distinct environments in which different hidden agents occasionally intervened to generate positive, negative, or random outcomes. Participants beliefs about hidden-agent intervention aligned with the true probabilities of the positive, negative, or random outcome manipulation in each of the three environments. Computational modeling of the learning data revealed that while the choices made by both adults (ages 18-25) and adolescents (ages 13-17) were best fit by Bayesian reinforcement learning models that incorporate beliefs about hidden-agent intervention, those of children (ages 7-12) were best fit by a one learning rate model that updates value estimates based on choice outcomes alone. Together, these results suggest that while children demonstrate explicit awareness of the causal structure of the task environment, they do not implicitly use beliefs about the causal structure of the environment to guide reinforcement learning in the same manner as adolescents and adults.","link":"/opendata/cohen-et-al-2020/"},{"title":"Collins (2018)","text":"Learning to make rewarding choices in response to stimuli depends on a slow but steady process, reinforcement learning, and a fast and flexible, but capacity-limited process, working memory. Using both systems in parallel, with their contributions weighted based on performance, should allow us to leverage the best of each system: rapid early learning, supplemented by long-term robust acquisition. However, this assumes that using one process does not interfere with the other. We use computational modeling to investigate the interactions between the two processes in a behavioral experiment and show that working memory interferes with reinforcement learning. Previous research showed that neural representations of reward prediction errors, a key marker of reinforcement learning, were blunted when working memory was used for learning. We thus predicted that arbitrating in favor of working memory to learn faster in simple problems would weaken the reinforcement learning process. We tested this by measuring performance in a delayed testing phase where the use of working memory was impossible, and thus participant choices depended on reinforcement learning. Counterintuitively, but confirming our predictions, we observed that associations learned most easily were retained worse than associations learned slower: Using working memory to learn quickly came at the cost of long-term retention. Computational modeling confirmed that this could only be accounted for by working memory interference in reinforcement learning computations. These results further our understanding of how multiple systems contribute in parallel to human learning and may have important applications for education and computational psychiatry.","link":"/opendata/collins-2018/"},{"title":"Conway et al. (2020)","text":"A large and consistent research literature demonstrates the superiority of dimensional models of mental disorder. Factor analytic research has mapped the latent dimensions underlying separate sets of mental disorders (e.g., emotional disorders), but a common framework-unencumbered by arbitrary historical boundaries between disorder groups-requires additional research. Using empirically derived measures of three key domains of psychopathological variation, the overarching goal of the current study was to explicate dimensions connecting internalizing, externalizing, and personality disorders. Participants included 1,144 racially diverse undergraduates. Exploratory structural equation modeling analyses revealed seven latent dimensions: core internalizing, core externalizing, antagonism, impulsivity, dutifulness, detachment, and suspiciousness. This meta-structure reflects a more comprehensive model of the architecture of mental disorders than accounts derived from less inclusive assessment batteries. Future empirical work is needed to evaluate the utility of this structural model in etiological research, assessment, and treatment arenas.","link":"/opendata/conway-et-al-2020/"},{"title":"Correa et al. (2018)","text":"The extent to which subjective awareness influences reward processing, and thereby affects future decisions, is currently largely unknown. In the present report, we investigated this question in a reinforcement learning framework, combining perceptual masking, computational modeling, and electroencephalographic recordings (human male and female participants). Our results indicate that degrading the visibility of the reward decreased, without completely obliterating, the ability of participants to learn from outcomes, but concurrently increased their tendency to repeat previous choices. We dissociated electrophysiological signatures evoked by the reward-based learning processes from those elicited by the reward-independent repetition of previous choices and showed that these neural activities were significantly modulated by reward visibility. Overall, this report sheds new light on the neural computations underlying reward-based learning and decision-making and highlights that awareness is beneficial for the trial-by-trial adjustment of decision-making strategies.","link":"/opendata/correa-et-al-2018/"},{"title":"Cortese et al. (2021)","text":"The human brain excels at constructing and using abstractions, such as rules, or concepts. Here, in two fMRI experiments, we demonstrate a mechanism of abstraction built upon the valuation of sensory features. Human volunteers learned novel association rules based on simple visual features. Reinforcement-learning algorithms revealed that, with learning, high-value abstract representations increasingly guided participant behaviour, resulting in better choices and higher subjective confidence. We also found that the brain area computing value signals - the ventromedial prefrontal cortex - prioritised and selected latent task elements during abstraction, both locally and through its connection to the visual cortex. Such a coding scheme predicts a causal role for valuation. Hence, in a second experiment, we used multivoxel neural reinforcement to test for the causality of feature valuation in the sensory cortex, as a mechanism of abstraction. Tagging the neural representation of a task feature with rewards evoked abstraction-based decisions. Together, these findings provide a novel interpretation of value as a goal-dependent, key factor in forging abstract representations.","link":"/opendata/cortese-et-al-2021/"},{"title":"Crawford et al. (2022)","text":"The study investigated whether cognitive effort decision-making measured via a neuroeconomic paradigm that manipulated framing (gain vs. loss outcomes), could predict daily life engagement in mentally demanding activities in both younger and older adults.Method: Younger and older adult participants (N=310) completed the Cognitive Effort Discounting paradigm (Cog-ED), under both gain and loss conditions, to provide an experimental index of cognitive effort costs for each participant in each framing condition. A subset of participants (N=230) also completed a seven-day Ecological Momentary Assessment (EMA) protocol measuring engagement in mentally demanding daily life activities. In a large, online sample, we replicated a robust increase in cognitive effort costs among older, relative to younger, adults. Additionally, costs were found to be reduced in the loss relative to gain frame, although these effects were only reliable at high levels of task difficulty and were not moderated by age. Critically, participants who had lower effort costs in the gain frame tended to report engaging in more mentally demanding daily life activities, but the opposite pattern was observed in the loss frame. Further exploratory analysis demonstrated that older adults reported overall lower levels of engagement in daily-life mentally demanding activities, and these age differences were statistically mediated by gain and loss effort costs. Together, these results suggest that cognitive effort costs, as measured through behavioral choice patterns in a neuroeconomic decision-making task, can be used to predict and explain engagement in mentally demanding activities during daily life among both older and younger adults.","link":"/opendata/crawford-et-al-2022/"},{"title":"Csifcsak et al. (2020)","text":"The ability to control the occurrence of rewarding and punishing events is crucial for our well-being. Two ways to optimize performance are to follow heuristics like Pavlovian biases to approach reward and avoid loss or to rely more on slowly accumulated stimulus-action associations. Although reduced control over outcomes has been linked to suboptimal decision-making in clinical conditions associated with learned helplessness, it is unclear how uncontrollability of the environment is related to the arbitration between different response strategies. This study directly tested whether a behavioral manipulation designed to induce learned helplessness in healthy adults (intermittent loss of control over feedback in a reinforcement learning task; yoking) would modulate the magnitude of Pavlovian bias and the neurophysiological signature of cognitive control (frontal midline theta power) in healthy adults. Using statistical analysis and computational modeling of behavioral data and electroencephalographic signals, we found stronger Pavlovian influences and alterations in frontal theta activity in the yoked group. However, these effects were not accompanied by reduced performance in experimental blocks with regained control, indicating that our behavioral manipulation was not potent enough for inducing helplessness and impaired coping ability with task demands. We conclude that the level of contingency between instrumental choices and rewards/punishments modulates Pavlovian bias during value-based decision-making, probably via interfering with the implementation of cognitive control. These findings might have implications for understanding the mechanisms underlying helplessness in various psychiatric conditions.","link":"/opendata/csifcsak-et-al-2020/"},{"title":"Csifcsak et al. (2021)","text":"Recent studies suggest that choice behavior in reinforcement learning tasks is shaped by the level of outcome controllability. In particular, Pavlovian bias (PB) seems to be enhanced under low levels of control, manifesting in approach tendencies toward rewards and response inhibition when facing potential losses. The medial prefrontal cortex (mPFC) has been implicated both in evaluating outcome controllability and in the recruitment of cognitive control (CC) to suppress maladaptive PB during reinforcement learning. The current study tested whether high-definition transcranial direct current stimulation (HD-tDCS) above the mPFC of healthy humans can influence PB, and counteract the previously documented, deleterious behavioral effects of low outcome controllability on decision-making. In a preregistered, between-group, double-blind study (N = 103 adults, both sexes), we tested the interaction between controllability and HD-tDCS on parameters of choice behavior in a Go/NoGo task. Relative to sham stimulation, HD-tDCS resulted in more robust performance improvement following reduced control, an effect that was more pronounced in appetitive trials. In addition, we found evidence for weaker PB when HD-tDCS was administered during low controllability over outcomes. Computational modeling revealed that parameter estimates of learning rate and choice randomness were modulated by controllability, HD-tDCS and their interaction. Overall, these results highlight the potential of our HD-tDCS protocol for interfering with choice arbitration under low levels of control, resulting in more adaptive behavior.","link":"/opendata/csifcsak-et-al-2021/"},{"title":"Dai et al. (2019)","text":"Uncertainty about the waiting time before obtaining an outcome is integral to intertemporal choice. Here, we showed that people express different time preferences depending on how they learn about this temporal uncertainty. In two studies, people chose between pairs of options: one with a single, sure delay and the other involving multiple, probabilistic delays (a lottery). The probability of each delay occurring either was explicitly described (timing risk) or could be learned through experiential sampling (timing uncertainty; the delay itself was not experienced). When the shorter delay was rare, people preferred the lottery more often when it was described than when it was experienced. When the longer delay was rare, this pattern was reversed. Modeling analyses suggested that underexperiencing rare delays and different patterns of probability weighting contribute to this description-experience gap. Our results challenge traditional models of intertemporal choice with temporal uncertainty as well as the generality of inverse-S-shaped probability weighting in such choice.","link":"/opendata/dai-et-al-2019/"},{"title":"da Silva & Hare (2020)","text":"Distinct model-free and model-based learning processes are thought to drive both typical and dysfunctional behaviours. Data from two-stage decision tasks have seemingly shown that human behaviour is driven by both processes operating in parallel. However, in this study, we show that more detailed task instructions lead participants to make primarily model-based choices that have little, if any, simple model-free influence. We also demonstrate that behaviour in the two-stage task may falsely appear to be driven by a combination of simple model-free and model-based learning if purely model-based agents form inaccurate models of the task because of misconceptions. Furthermore, we report evidence that many participants do misconceive the task in important ways. Overall, we argue that humans formulate a wide variety of learning models. Consequently, the simple dichotomy of model-free versus model-based learning is inadequate to explain behaviour in the two-stage task and connections between reward learning, habit formation and compulsivity.","link":"/opendata/da-silva-hare-2020/"},{"title":"Decker et al. (2016)","text":"Theoretical models distinguish two decision-making strategies that have been formalized in reinforcement-learning theory. A model-based strategy leverages a cognitive model of potential actions and their consequences to make goal-directed choices, whereas a model-free strategy evaluates actions based solely on their reward history. Research in adults has begun to elucidate the psychological mechanisms and neural substrates underlying these learning processes and factors that influence their relative recruitment. However, the developmental trajectory of these evaluative strategies has not been well characterized. In this study, children, adolescents, and adults performed a sequential reinforcement-learning task that enabled estimation of model-based and model-free contributions to choice. Whereas a model-free strategy was apparent in choice behavior across all age groups, a model-based strategy was absent in children, became evident in adolescents, and strengthened in adults. These results suggest that recruitment of model-based valuation systems represents a critical cognitive component underlying the gradual maturation of goal-directed behavior.","link":"/opendata/decker-et-al-2016/"},{"title":"Decker, Dubois et al. (2022)","text":"Attentional lapses have been found to impair everything from basic perception to learning and memory. Yet, despite the well documented costs of lapses on cognition, recent work suggests that lapses might unexpectedly confer some benefits. One potential benefit is that lapses broaden our learning to integrate seemingly irrelevant content that could later prove useful–a benefit that prior research focusing only on goal relevant memory would miss. Here, we measure how fluctuations in sustained attention influence the learning of seemingly goal-irrelevant content that competes for attention with target content. Participants completed a correlated flanker task in which they categorized central targets (letters or numbers) while ignoring peripheral flanking symbols that shared hidden probabilistic relationships with the targets. We found that across participants, higher rates of attentional lapses correlated with greater learning of the target-flanker relationships. Moreover, within participants, learning was more evident during attentional lapses. These findings address long-standing theoretical debates and reveal a benefit of attentional lapses: they expand the scope of learning and decisions beyond the strictly relevant.","link":"/opendata/decker-dubois-et-al-2022/"},{"title":"Dercon et al. (2022)","text":"Cognitive distancing is a therapeutic technique commonly used in psychological treatment of various mental health disorders, but its computational mechanisms remain unknown. To determine the effects of cognitive distancing on computational learning mechanisms, we use an online reward decision-making task, combined with reinforcement learning modelling in 935 participants, 49.1% of whom were trained to regulate their emotional response to task performance feedback. Those participants practicing cognitive distancing showed heightened learning from negative events as well as an increased integration of previous choice values. These differences seemed to represent an evolving shift in strategy by the distancing participants during the task, from exploiting optimal choices earlier in the task (as indicated by greater inverse temperature parameters), to a late-stage increase in learning from negative outcomes (represented as higher loss learning rates). Our findings suggest adaptive changes in computational learning mechanisms underpin the clinical utility of cognitive distancing in psychological therapy.","link":"/opendata/dercon-et-al-2022/"},{"title":"Dev et al. (2022)","text":"The theory of depressive realism holds that depressed individuals are less prone to optimistic bias, and are thus more realistic, in assessing their control or performance. Since the theory was proposed 40 years ago, many innovations have been validated for testing cognitive accuracy, including improved measures of bias in perceived control and performance. We incorporate several of those innovations in a well-powered, pre-registered study designed to identify depressive realism. Amazon MTurk workers (N = 246) and undergraduate students (N = 134) completed a classic contingency task, an overconfidence task, and measures of mental health constructs, including depression and anxiety. We measured perceived control throughout the contingency task, allowing us to compare control estimates at the trial-level to estimates assessed at task conclusion. We found no evidence that depressive symptoms relate to illusory control or to overconfidence. Our results suggest that despite its popular acceptance, depressive realism is not replicable.","link":"/opendata/dev-et-al-2022/"},{"title":"Devine & Otto (2022)","text":"People tend to avoid engaging in cognitively demanding tasks unless it is worth our while-that is, if the benefits outweigh the costs of effortful action. Yet, we seemingly partake in a variety of effortful mental activities (e.g. playing chess, completing Sudoku puzzles) because they impart a sense of progress. Here, we examine the possibility that information about progress-specifically, the number of trials completed of a demanding cognitive control task, relative to the total number of trials to be completed-reduces individuals aversion to cognitively effort activity, across four experiments. In Experiment 1, we provide an initial demonstration that presenting progress information reduces individuals avoidance of cognitively demanding activity avoidance using a variant of the well-characterized Demand Selection Task (DST). The subsequent experiments buttress this finding using a more sophisticated within-subjects versions of the DST, independently manipulating progress information and demand level to further demonstrate that, 1) people prefer receiving information about temporal progress in a task, and 2) all else being equal, individuals will choose to engage in tasks that require greater levels of cognitive effort when the more demanding option confers information about their progress in a task. Together, these results suggest that progress information can motivate cognitive effort expenditure and, in some cases, override individuals default bias towards demand avoidance.","link":"/opendata/devine-otto-2022/"},{"title":"Dezfouli et al. (2019)","text":"Popular computational models of decision-making make specific assumptions about learning processes that may cause them to underfit observed behaviours. Here we suggest an alternative method using recurrent neural networks (RNNs) to generate a flexible family of models that have sufficient capacity to represent the complex learning and decision- making strategies used by humans. In this approach, an RNN is trained to predict the next action that a subject will take in a decision-making task and, in this way, learns to imitate the processes underlying subjects choices and their learning abilities. We demonstrate the benefits of this approach using a new dataset drawn from patients with either unipolar (n = 34) or bipolar (n = 33) depression and matched healthy controls (n = 34) making decisions on a two-armed bandit task. The results indicate that this new approach is better than baseline reinforcement-learning methods in terms of overall performance and its capacity to predict subjects choices. We show that the model can be interpreted using off-policy simulations and thereby provides a novel clustering of subjects learning processes-something that often eludes traditional approaches to modelling and behavioural analysis.","link":"/opendata/dezfouli-et-al-2019/"},{"title":"Dillon et al. (2021)","text":"Choices and response times in two-alternative decision-making tasks can be modeled by assuming that individuals steadily accrue evidence in favor of each alternative until a response boundary for one of them is crossed, at which point that alternative is chosen. Prior studies have reported that evidence accumulation during decision-making tasks takes longer in adults with psychopathology than in healthy controls, indicating that slow evidence accumulation may be transdiagnostic. However, few studies have examined perceptual decision making in anxiety disorders, where hypervigilance might enhance performance. Therefore, this study used the Hierarchical Drift Diffusion model to investigate evidence accumulation in adults with social anxiety disorder (SAD) and healthy controls as they performed a probabilistic reward task (PRT), in which social rewards were delivered for correct perceptual judgments. Adults with SAD completed the PRT before and after gaze-contingent music reward therapy (GCMRT), which trains attention allocation and has shown efficacy for SAD. Healthy controls also completed the PRT twice. Results revealed excellent performance in adults with SAD, especially after GCMRT: relative to controls, they showed faster evidence accumulation, better discriminability, and earned more rewards. These data highlight a positive effect of attention training on performance in anxious adults and show how a behavioral trait that is typically problematic-hypervigilance in SAD-can nevertheless confer advantages in certain contexts. The data also indicate that, in contrast to other forms of psychopathology, SAD is not characterized by slow evidence accumulation, at least in the context of the social PRT.","link":"/opendata/dillon-et-al-2021/"},{"title":"Dombrovski et al. (2019)","text":"Suicidal behavior is associated with impaired decision making in contexts of uncertainty. Existing studies, however, do not definitively address whether suicide attempers have 1) impairment in learning from experience or 2) impairment in choice based on comparison of estimated option values. Our reinforcement learning model-based behavioral study tested these hypotheses directly in middle-aged and older suicide attempters representative of those who die by suicide. Two samples (sample 1, n = 135; sample 2, n = 125) of suicide attempters with depression (nattempters = 54 and 39, respectively), suicide ideators, nonsuicidal patients with depression, and healthy control participants completed a probabilistic three-choice decision-making task. A second experiment in sample 2 experimentally dissociated long-term learned value from reward magnitude. Analyses combined computational reinforcement learning and mixed-effects models of decision times and choices. With regard to learning, suicide attempters (vs. all comparison groups) were less sensitive to one-back reinforcement, as indicated by a reduced effect on both choices and decision times. Learning deficits scaled with attempt lethality and were partially explained by poor cognitive control. With regard to value-based choice, suicide attempters (vs. all comparison groups) displayed abnormally long decision times when choosing between similarly valued options and were less able to distinguish between the best and second-best options. Group differences in value-based choice were robust to controlling for cognitive performance, comorbidities, impulsivity, psychotropic exposure, and possible brain damage from attempts. Serious suicidal behavior is associated with impaired reward learning, likely undermining the search for alternative solutions. Attempted suicide is associated with impaired value comparison during the choice process, potentially interfering with the consideration of deterrents and alternatives in a crisis.","link":"/opendata/dombrovski-et-al-2019/"},{"title":"Dombrovski et al. (2020)","text":"When making decisions, should one exploit known good options or explore potentially better alternatives? Exploration of spatially unstructured options depends on the neocortex, striatum, and amygdala. In natural environments, however, better options often cluster together, forming structured value distributions. The hippocampus binds reward information into allocentric cognitive maps to support navigation and foraging in such spaces. Here we report that human posterior hippocampus (PH) invigorates exploration while anterior hippocampus (AH) supports the transition to exploitation on a reinforcement learning task with a spatially structured reward function. These dynamics depend on differential reinforcement representations in the PH and AH. Whereas local reward prediction error signals are early and phasic in the PH tail, global value maximum signals are delayed and sustained in the AH body. AH compresses reinforcement information across episodes, updating the location and prominence of the value maximum and displaying goal cell-like ramping activity when navigating toward it.","link":"/opendata/dombrovski-et-al-2020/"},{"title":"Donegan et al. (2023)","text":"Model-based planning is thought to protect against over-reliance on habits. It is reduced in individuals high in compulsivity, but effect sizes are small and may depend on subtle features of the tasks used to assess it. We developed a diamond-shooting smartphone game that measures model-based planning in an at-home setting, and varied the game’s structure within and across participants to assess how it affects measurement reliability and validity with respect to previously established correlates of model-based planning, with a focus on compulsivity. Increasing the number of trials used to estimate model-based planning did remarkably little to affect the association with compulsivity. However, associations with compulsivity were higher when transition ratios were less deterministic and depending on the reward drift utilised. These findings suggest that model-based planning can be measured at home via an app, can be estimated in relatively few trials, and can be optimised for sensitivity to compulsive symptoms in the general population.","link":"/opendata/donegan-et-al-2023/"},{"title":"Dorfman et al. (2019)","text":"People learn differently from good and bad outcomes. We argue that valence-dependent learning asymmetries are partly driven by beliefs about the causal structure of the environment. If hidden causes can intervene to generate bad (or good) outcomes, then a rational observer will assign blame (or credit) to these hidden causes, rather than to the stable outcome distribution. Thus, a rational observer should learn less from bad outcomes when they are likely to have been generated by a hidden cause, and this pattern should reverse when hidden causes are likely to generate good outcomes. To test this hypothesis, we conducted two experiments ( N = 80, N = 255) in which we explicitly manipulated the behavior of hidden agents. This gave rise to both kinds of learning asymmetries in the same paradigm, as predicted by a novel Bayesian model. These results provide a mechanistic framework for understanding how causal attributions contribute to biased learning.","link":"/opendata/dorfman-et-al-2019/"},{"title":"Dorfman & Gershman (2019)","text":"A Pavlovian bias to approach reward-predictive cues and avoid punishment-predictive cues can conflict with instrumentally-optimal actions. Here, we propose that the brain arbitrates between Pavlovian and instrumental control by inferring which is a better predictor of reward. The instrumental predictor is more flexible; it can learn values that depend on both stimuli and actions, whereas the Pavlovian predictor learns values that depend only on stimuli. The arbitration theory predicts that the Pavlovian predictor will be favored when rewards are relatively uncontrollable, because the additional flexibility of the instrumental predictor is not useful. Consistent with this hypothesis, we find that the Pavlovian approach bias is stronger under low control compared to high control contexts.","link":"/opendata/dorfman-gershman-2019/"},{"title":"Dubois et al. (2022)","text":"Deciding between exploring new avenues and exploiting known choices is central to learning, and this exploration-exploitation trade-off changes during development. Exploration is not a unitary concept, and humans deploy multiple distinct mechanisms, but little is known about their specific emergence during development. Using a previously validated task in adults, changes in exploration mechanisms were investigated between childhood (8-9 y/o, N = 26; 16 females), early (12-13 y/o, N = 38; 21 females), and late adolescence (16-17 y/o, N = 33; 19 females) in ethnically and socially diverse schools from disadvantaged areas. We find an increased usage of a computationally light exploration heuristic in younger groups, effectively accommodating their limited neurocognitive resources. Moreover, this heuristic was associated with self-reported, attention-deficit/hyperactivity disorder symptoms in this population-based sample. This study enriches our mechanistic understanding about how exploration strategies mature during development.","link":"/opendata/dubois-et-al-2022/"},{"title":"Dubois & Hauser (2022)","text":"Deciding whether to forgo a good choice in favour of exploring a potentially more rewarding alternative is one of the most challenging arbitrations both in human reasoning and in artificial intelligence. Humans show substantial variability in their exploration, and theoretical (but only limited empirical) work has suggested that excessive exploration is a critical mechanism underlying the psychiatric dimension of impulsivity. In this registered report, we put these theories to test using large online samples, dimensional analyses, and computational modelling. Capitalising on recent advances in disentangling distinct human exploration strategies, we not only demonstrate that impulsivity is associated with a specific form of exploration-value-free random exploration-but also explore links between exploration and other psychiatric dimensions.","link":"/opendata/dubois-hauser-2022/"},{"title":"Dumbalska et al. (2022)","text":"When a target stimulus occurs in the presence of distracters, decisions are less accurate. But how exactly do distracters affect choices? Here, we explored this question using measurement of human behaviour, psychophysical reverse correlation and computational modelling. We contrasted two models: one in which targets and distracters had independent influence on choices (independent model) and one in which distracters modulated choices in a way that depended on their similarity to the target (interaction model). Across three experiments, participants were asked to make fine orientation judgments about the tilt of a target grating presented adjacent to an irrelevant distracter. We found strong evidence for the interaction model, in that decisions were more sensitive when target and distracter were consistent relative to when they were inconsistent. This consistency bias occurred in the frame of reference of the decision, that is, it operated on decision values rather than on sensory signals, and surprisingly, it was independent of spatial attention. A normalization framework, where target features are normalized by the expectation and variability of the local context, successfully captures the observed pattern of results.","link":"/opendata/dumbalska-et-al-2022/"},{"title":"Eckert et al. (2022)","text":"Predictive processing posits that perception emerges from inferential processes within a hierarchical cortical system. Alterations of these processes may result in psychotic experiences, such as hallucinations and delusions. Central to the predictive processing account of psychosis is the notion of aberrant weights attributed to prior information and sensory input. Based on the notion that previous perceptual choices represent a relevant source of prior information, we here asked whether the propensity towards psychotic experiences may be related to altered choice history biases in perceptual decision-making. We investigated the relationship between choice history biases in perceptual decision-making and psychosis proneness in the general population. Choice history biases and their adaptation to experimentally induced changes in stimulus serial dependencies were investigated in decision-making tasks with auditory (experiment 1) and visual (experiment 2) stimuli. We further explored a potential compensatory mechanism for reduced choice history biases by reliance on predictive cross-modal cues. In line with our preregistered hypothesis, psychosis proneness was associated with decreased choice history biases in both experiments. This association is generalized across conditions with and without stimulus serial dependencies. We did not find consistent evidence for a compensatory reliance on cue information in psychosis-prone individuals across experiments. Our results show reduced choice history biases in psychosis proneness. A compensatory mechanism between implicit choice history effects and explicit cue information is not supported unequivocally by our data.","link":"/opendata/eckert-et-al-2022/"},{"title":"Eckstein et al. (2022a)","text":"During adolescence, youth venture out, explore the wider world, and are challenged to learn how to navigate novel and uncertain environments. We investigated how performance changes across adolescent development in a stochastic, volatile reversal-learning task that uniquely taxes the balance of persistence and flexibility. In a sample of 291 participants aged 8-30, we found that in the mid-teen years, adolescents outperformed both younger and older participants. We developed two independent cognitive models, based on Reinforcement learning (RL) and Bayesian inference (BI). The RL parameter for learning from negative outcomes and the BI parameters specifying participants’ mental models were closest to optimal in mid-teen adolescents, suggesting a central role in adolescent cognitive processing. By contrast, persistence and noise parameters improved monotonically with age. We distilled the insights of RL and BI using principal component analysis and found that three shared components interacted to form the adolescent performance peak: adult-like behavioral quality, child-like time scales, and developmentally-unique processing of positive feedback. This research highlights adolescence as a neurodevelopmental window that can create performance advantages in volatile and uncertain environments. It also shows how detailed insights can be gleaned by using cognitive models in new ways.","link":"/opendata/eckstein-et-al-2022a/"},{"title":"Eckstein et al. (2022b)","text":"Reinforcement Learning (RL) models have revolutionized the cognitive and brain sciences, promising to explain behavior from simple conditioning to complex problem solving, to shed light on developmental and individual differences, and to anchor cognitive processes in specific brain mechanisms. However, the RL literature increasingly reveals contradictory results, which might cast doubt on these claims. We hypothesized that many contradictions arise from two commonly-held assumptions about computational model parameters that are actually often invalid: That parameters generalize between contexts (e.g. tasks, models) and that they capture interpretable (i.e. unique, distinctive) neurocognitive processes. To test this, we asked 291 participants aged 8-30 years to complete three learning tasks in one experimental session, and fitted RL models to each. We found that some parameters (exploration / decision noise) showed significant generalization: they followed similar developmental trajectories, and were reciprocally predictive between tasks. Still, generalization was significantly below the methodological ceiling. Furthermore, other parameters (learning rates, forgetting) did not show evidence of generalization, and sometimes even opposite developmental trajectories. Interpretability was low for all parameters. We conclude that the systematic study of context factors (e.g. reward stochasticity; task volatility) will be necessary to enhance the generalizability and interpretability of computational cognitive models.","link":"/opendata/eckstein-et-al-2022b/"},{"title":"Ehlers & Lonsdorf (2022)","text":"Data sharing holds promise for advancing and accelerating science by facilitating and fostering collaboration, reproducibility and optimal use of sparse resources. We argue that despite the existence of general data sharing guidelines (e.g, FAIR-principles), their translation and implementation requires field-specific considerations. Here, we addressed this timely question for the field of experimental research on fear and anxiety and showcase the enormous prospects by illustrating the wealth and richness of a curated data collection of publicly available datasets using the fear conditioning paradigm based on 103 studies and 8839 participants. We highlight challenges encountered when aiming to reuse the available data corpus and derive 10 simple steps for making data sharing in the field more efficient and sustainable and hence facilitating collaboration, cumulative knowledge generation and large scale mega-, meta- and psychometric analyses.We share our vision and first steps towards transforming such curated data collections into a homogenized and dynamically growing database allowing for easy contributions and for living analysis tools for the collective benefit of the research community.We share our vision and first steps towards transforming such curated data collections into a homogenized and dynamically growing database allowing for easy contributions and for living analysis tools for the collective benefit of the research community.","link":"/opendata/ehlers-lonsdorf-2022/"},{"title":"Eisenberg et al. (2021)","text":"Psychological sciences have identified a wealth of cognitive processes and behavioral phenomena, yet struggle to produce cumulative knowledge. Progress is hamstrung by siloed scientific traditions and a focus on explanation over prediction, two issues that are particularly damaging for the study of multifaceted constructs like self-regulation. Here, we derive a psychological ontology from a study of individual differences across a broad range of behavioral tasks, self-report surveys, and self-reported real-world outcomes associated with self-regulation. Though both tasks and surveys putatively measure self-regulation, they show little empirical relationship. Within tasks and surveys, however, the ontology identifies reliable individual traits and reveals opportunities for theoretic synthesis. We then evaluate predictive power of the psychological measurements and find that while surveys modestly and heterogeneously predict real-world outcomes, tasks largely do not. We conclude that self-regulation lacks coherence as a construct, and that data-driven ontologies lay the groundwork for a cumulative psychological science.","link":"/opendata/eisenberg-et-al-2021/"},{"title":"Eissa et al. (2022)","text":"Solutions to challenging inference problems are often subject to a fundamental trade-off between: 1) bias (being systematically wrong) that is minimized with complex inference strategies, and 2) variance (being oversensitive to uncertain observations) that is minimized with simple inference strategies. However, this trade-off is based on the assumption that the strategies being considered are optimal for their given complexity and thus has unclear relevance to forms of inference based on suboptimal strategies. We examined inference problems applied to rare, asymmetrically available evidence, which a large population of human subjects solved using a diverse set of strategies that varied in form and complexity. In general, subjects using more complex strategies tended to have lower bias and variance, but with a dependence on the form of strategy that reflected an inversion of the classic bias-variance trade-off: subjects who used more complex, but imperfect, Bayesian-like strategies tended to have lower variance but higher bias because of incorrect tuning to latent task features, whereas subjects who used simpler heuristic strategies tended to have higher variance because they operated more directly on the observed samples but lower, near-normative bias. Our results help define new principles that govern individual differences in behavior that depends on rare-event inference and, more generally, about the information-processing trade-offs that can be sensitive to not just the complexity, but also the optimality, of the inference process.","link":"/opendata/eissa-et-al-2022/"},{"title":"Elder et al. (2022)","text":"People learn about themselves from social feedback, but desires for coherence and positivity constrain how feedback is incorporated into the self-concept. We developed a network-based model of the self-concept and embedded it in a reinforcement-learning framework to provide a computational account of how motivations shape self-learning from feedback. Participants (N = 46 adult university students) received feedback while evaluating themselves on traits drawn from a causal network of trait semantics. Network-defined communities were assigned different likelihoods of positive feedback. Participants learned from positive feedback but dismissed negative feedback, as reflected by asymmetries in computational parameters that represent the incorporation of positive versus negative outcomes. Furthermore, participants were constrained in how they incorporated feedback: Self-evaluations changed less for traits that have more implications and are thus more important to the coherence of the network. We provide a computational explanation of how motives for coherence and positivity jointly constrain learning about the self from feedback, an explanation that makes testable predictions for future clinical research.","link":"/opendata/elder-et-al-2022/"},{"title":"Éltető et al. (2022)","text":"Humans can implicitly learn complex perceptuo-motor skills over the course of large numbers of trials. This likely depends on our becoming better able to take advantage of ever richer and temporally deeper predictive relationships in the environment. Here, we offer a novel characterization of this process, fitting a non-parametric, hierarchical Bayesian sequence model to the reaction times of human participants responses over ten sessions, each comprising thousands of trials, in a serial reaction time task involving higher-order dependencies. The model, adapted from the domain of language, forgetfully updates trial-by-trial, and seamlessly combines predictive information from shorter and longer windows onto past events, weighing the windows proportionally to their predictive power. As the model implies a posterior over window depths, we were able to determine how, and how many, previous sequence elements influenced individual participants internal predictions, and how this changed with practice. Already in the first session, the model showed that participants had begun to rely on two previous elements (i.e., trigrams), thereby successfully adapting to the most prominent higher-order structure in the task. The extent to which local statistical fluctuations in trigram frequency influenced participants responses waned over subsequent sessions, as participants forgot the trigrams less and evidenced skilled performance. By the eighth session, a subset of participants shifted their prior further to consider a context deeper than two previous elements. Finally, participants showed resistance to interference and slow forgetting of the old sequence when it was changed in the final sessions. Model parameters for individual participants covaried appropriately with independent measures of working memory and error characteristics. In sum, the model offers the first principled account of the adaptive complexity and nuanced dynamics of humans internal sequence representations during long-term implicit skill learning.","link":"/opendata/elteto-et-al-2022/"},{"title":"Embrey et al. (2022)","text":"Humans are often termed “cognitive misers” for their aversion to mental effort. Both in and outside the laboratory people often show preference for low-effort tasks and are willing to forgo financial reward to avoid more demanding alternatives. Mental effort, however, does not seem to be ubiquitously avoided: people play crosswords, board games, and read novels, all as forms of leisure. While such activities undoubtedly require effort, the type of cognitive demands they impose appear markedly different from the tasks typically used in mental-effort research (e.g., N-Back, demand selection tasks, vigilance tasks). We investigate the effect disparate demands such as rule discovery compared to rule implementation have on people’s aversion to or preference for increased mental effort. Across four experiments using three different tasks (i.e., N-Back, number sequence problems, and anagrams), and a mixture of online and lab-based settings we find that aversion to effort remains stable regardless of the types of cognitive demands a task imposes. The results are discussed in terms of other factors that might induce the pursuit of mental effort over and above the type of cognitive activity involved in a task.","link":"/opendata/embrey-et-al-2022/"},{"title":"Engelmann et al. (2017)","text":"Commonly observed distortions in decision-making among patients with major depressive disorder (MDD) may emerge from impaired reward processing and cognitive biases toward negative events. There is substantial theoretical support for the hypothesis that MDD patients overweight potential losses compared with gains, though the neurobiological underpinnings of this bias are uncertain. Twenty-one unmedicated patients with MDD were compared with 25 healthy controls (HC) using functional magnetic resonance imaging (fMRI) together with an economic decision-making task over mixed lotteries involving probabilistic gains and losses. Region-of-interest analyses evaluated neural signatures of gain and loss coding within a core network of brain areas known to be involved in valuation (anterior insula, caudate nucleus, ventromedial prefrontal cortex). Usable fMRI data were available for 19 MDD and 23 HC subjects. Anterior insula signal showed negative coding of losses (gain &gt; loss) in HC subjects consistent with previous findings, whereas MDD subjects demonstrated significant reversals in these associations (loss &gt; gain). Moreover, depression severity further enhanced the positive coding of losses in anterior insula, ventromedial prefrontal cortex, and caudate nucleus. The hyper-responsivity to losses displayed by the anterior insula of MDD patients was paralleled by a reduced influence of gain, but not loss, stake size on choice latencies. Patients with MDD demonstrate a significant shift from negative to positive coding of losses in the anterior insula, revealing the importance of this structure in value-based decision-making in the context of emotional disturbances.","link":"/opendata/engelmann-et-al-2017/"},{"title":"Erev et al. (2017)","text":"Experimental studies of choice behavior document distinct, and sometimes contradictory, deviations from maximization. For example, people tend to overweight rare events in 1-shot decisions under risk, and to exhibit the opposite bias when they rely on past experience. The common explanations of these results assume that the contradicting anomalies reflect situation-specific processes that involve the weighting of subjective values and the use of simple heuristics. The current article analyzes 14 choice anomalies that have been described by different models, including the Allais, St. Petersburg, and Ellsberg paradoxes, and the reflection effect. Next, it uses a choice prediction competition methodology to clarify the interaction between the different anomalies. It focuses on decisions under risk (known payoff distributions) and under ambiguity (unknown probabilities), with and without feedback concerning the outcomes of past choices. The results demonstrate that it is not necessary to assume situation-specific processes. The distinct anomalies can be captured by assuming high sensitivity to the expected return and 4 additional tendencies: pessimism, bias toward equal weighting, sensitivity to payoff sign, and an effort to minimize the probability of immediate regret. Importantly, feedback increases sensitivity to probability of regret. Simple abstractions of these assumptions, variants of the model Best Estimate and Sampling Tools (BEAST), allow surprisingly accurate ex ante predictions of behavior. Unlike the popular models, BEAST does not assume subjective weighting functions or cognitive shortcuts. Rather, it assumes the use of sampling tools and reliance on small samples, in addition to the estimation of the expected values.","link":"/opendata/erev-et-al-2017/"},{"title":"Ez-zizi et al. (2022)","text":"Two prominent types of uncertainty that have been studied extensively are expected and unexpected uncertainty. Studies suggest that humans are capable of learning from reward under both expected and unexpected uncertainty when the source of variability is the reward. How do people learn when the source of uncertainty is the environments state and rewards themselves are deterministic? How does their learning compare with the case of reward uncertainty? The present study addressed these questions using behavioural experimentation and computational modelling. Experiment 1 showed that human subjects were generally able to use reward feedback to successfully learn the task rules under state uncertainty, and were able to detect a non-signalled reversal of stimulus-response contingencies. Experiment 2, which combined all four types of uncertainties—expected versus unexpected uncertainty, and state versus reward uncertainty—highlighted key similarities and differences in learning between state and reward uncertainties. We found that subjects performed significantly better in the state uncertainty condition, primarily because they explored less and improved their state disambiguation. We also show that a simple reinforcement learning mechanism that ignores state uncertainty and updates the state-action value of only the identified state accounted for the behavioural data better than both a Bayesian reinforcement learning model that keeps track of belief states and a model that acts based on sampling from past experiences. Our findings suggest a common mechanism supports reward-based learning under state and reward uncertainty.","link":"/opendata/ez-zizi-et-al-2022/"},{"title":"Fan et al. (2021)","text":"Anxiety has been related to decreased physical exploration, but past findings on the interaction between anxiety and exploration during decision making were inconclusive. Here we examined how latent factors of trait anxiety relate to different exploration strategies when facing volatility-induced uncertainty. Across two studies (total N = 985), we demonstrated that people used a hybrid of directed, random and undirected exploration strategies, which were respectively sensitive to relative uncertainty, total uncertainty and value difference. Trait somatic anxiety, that is, the propensity to experience physical symptoms of anxiety, was inversely correlated with directed exploration and undirected exploration, manifesting as a lesser likelihood for choosing the uncertain option and reducing choice stochasticity regardless of uncertainty. Somatic anxiety is also associated with underestimation of relative uncertainty. Together, these results reveal the selective role of trait somatic anxiety in modulating both uncertainty-driven and value-driven exploration strategies.","link":"/opendata/fan-et-al-2021/"},{"title":"Fan et al. (2023)","text":"Exploration is an important part of decision making and is crucial to maximizing long-term reward. Past work has shown that people use different forms of uncertainty to guide exploration. In this study, we investigate the role of the pupil-linked arousal system in uncertainty-guided exploration. We measured participants’ pupil dilation (N = 48) while they performed a two- armed bandit task. Consistent with previous work, we found that people adopted a hybrid of directed, random and undirected exploration, which are sensitive to relative uncertainty, total uncertainty and value difference between options, respectively. We also found a positive correlation between pupil size and total uncertainty. Furthermore, augmenting the choice model with subject-specific total uncertainty estimates decoded from the pupil size improved predictions of held-out choices, suggesting that people used the uncertainty estimate encoded in pupil size to decide which option to explore Together, the data shed light on the computations underlying uncertainty-driven exploration. Under the assumption that pupil size reflects Locus Coeruleus-Norepinephrine (LC-NE) neuromodulatory activity, these results also extend the theory of LC-NE function in exploration, highlighting its selective role in driving uncertainty- guided random exploration.","link":"/opendata/fan-et-al-2023/"},{"title":"Farkas et al. (2023)","text":"Despite the fact that reliability estimation is crucial for robust inference, it is underutilized in neuroscience and cognitive psychology. Appreciating reliability can help researchers increase statistical power, effect sizes, and reproducibility, decrease the impact of measurement error, and inform methodological choices. However, accurately calculating reliability for many experimental learning tasks is challenging. In this study, we highlight a number of these issues, and estimate multiple metrics of internal consistency and split-half reliability of a widely used learning task on a large sample of 180 subjects. We show how pre-processing choices, task length, and sample size can affect reliability and its estimation. Our results show that the Alternating Serial Reaction Time Task has respectable reliability, especially when learning scores are calculated based on reaction times and two-stage averaging. We also show that a task length of 25 blocks can be sufficient to meet the usual thresholds for minimally acceptable reliability. We further illustrate how relying on a single point estimate of reliability can be misleading, and the calculation of multiple metrics, along with their uncertainties, can lead to a more complete characterization of the psychometric properties of tasks.","link":"/opendata/farkas-et-al-2023/"},{"title":"Felso et al. (2022)","text":"While making plans, people have to decide how far out into the future they want to plan: days, months, years, or even longer. Overly short-sighted planning can harm peoples well-being in important life domains, such as health, finances, and academics. While self-report scales exist to measure peoples planning, peoples answers to such questions may be distorted by their desire to make a good impression and conform to norms and expectations. Here, we introduce a method for objectively quantifying peoples propensity to plan into the future. Our method combines a process-tracing method with Bayesian inverse reinforcement learning to measure how prone an individual is to plan multiple steps ahead. To infer this from a persons process-tracing data, our method inverts a new resource-rational model of individual differences in planning. This model assumes that subjective planning costs are captured by a cost function with two parameters: a mental effort cost and a planning depth cost. Upon showing that our model of planning explains individual participants planning behavior better than the best previous models, we validate our method on simulated data and real data from a large online experiment where the cost of planning was manipulated within participants. Our results show that our method can infer individual differences in the planning depth cost. Our model provides a mechanistic account for why some people plan too shortsightedly. The subjective planning costs inferred by our method can be used as an objective, non-self-report measure of individual differences in peoples propensity to plan into the future.","link":"/opendata/felso-et-al-2022/"},{"title":"Ferrucci et al. (2021)","text":"A standard view in the literature is that decisions are the result of a process that accumulates evidence in favor of each alternative until such accumulation reaches a threshold and a decision is made. However, this view has been recently questioned by an alternative proposal that suggests that, instead of accumulated, evidence is combined with an urgency signal. Both theories have been mathematically formalized and supported by a variety of decision-making tasks with constant information. However, recently, tasks with changing information have shown to be more effective to study the dynamics of decision making. Recent research using one of such tasks, the tokens task, has shown that decisions are better described by an urgency mechanism than by an accumulation one. However, the results of that study could depend on a task where all fundamental information was noiseless and always present, favoring a mechanism of non-integration, such as the urgency one. Here, we wanted to address whether the same conclusions were also supported by an experimental paradigm in which sensory evidence was removed shortly after it was provided, making working memory necessary to properly perform the task. Here, we show that, under such condition, participants’ behavior could be explained by an urgency-gating mechanism that low-pass filters the mnemonic information and combines it with an urgency signal that grows with time but not by an accumulation process that integrates the same mnemonic information. Thus, our study supports the idea that, under certain situations with dynamic sensory information, decisions are better explained by an urgency-gating mechanism than by an accumulation one.","link":"/opendata/ferrucci-et-al-2021/"},{"title":"Fielder & Glöckner (2012)","text":"In the last years, research on risky choice has moved beyond analyzing choices only. Models have been suggested that aim to describe the underlying cognitive processes and some studies have tested process predictions of these models. Prominent approaches are evidence accumulation models such as decision field theory (DFT), simple serial heuristic models such as the adaptive toolbox, and connectionist approaches such as the parallel constraint satisfaction (PCS) model. In two studies involving measures of attention and pupil dilation, we investigate hypotheses derived from these models in choices between two gambles with two outcomes each. We show that attention to an outcome of a gamble increases with its probability and its value and that attention shifts toward the subsequently favored gamble after about two thirds of the decision process, indicating a gaze-cascade effect. Information search occurs mostly within-gambles, and the direction of search does not change over the course of decision making. Pupil dilation, which reflects both cognitive effort and arousal, increases during the decision process and increases with mean expected value. Overall, the results support aspects of automatic integration models for risky choice such as DFT and PCS, but in their current specification none of them can account for the full pattern of results.","link":"/opendata/fielder-glockner-2012/"},{"title":"Fleming et al. (2023)","text":"An important finding in the cognitive effort literature has been that sensitivity to the costs of effort varies between individuals, suggesting that some people find effort more aversive than others. It has been suggested this may explain individual differences in other aspects of cognition; in particular that greater effort sensitivity may underlie some of the symptoms of conditions such as depression and schizophrenia. In this paper, we highlight a major problem with existing measures of cognitive effort that hampers this line of research, specifically the confounding of effort and difficulty. This means that behaviour thought to reveal effort costs could equally be explained by cognitive capacity, which influences the frequency of success and thereby the chance of obtaining reward. To address this shortcoming, we introduce a new test, the Number Switching Task (NST), specially designed such that difficulty will be unaffected by the effort manipulation and can easily be standardised across participants. In a large, online sample, we show that these criteria are met successfully and reproduce classic effort discounting results with the NST. We also demonstrate the use of Bayesian modelling with this task, producing behavioural parameters which can be associated with other measures, and report a preliminary association with the Need for Cognition scale.","link":"/opendata/fleming-et-al-2023/"},{"title":"Fontanesi et al. (2019)","text":"Reinforcement learning (RL) models describe how humans and animals learn by trial-and-error to select actions that maximize rewards and minimize punishments. Traditional RL models focus exclusively on choices, thereby ignoring the interactions between choice preference and response time (RT), or how these interactions are influenced by contextual factors. However, in the field of perceptual decision-making, such interactions have proven to be important to dissociate between different underlying cognitive processes. Here, we investigated such interactions to shed new light on overlooked differences between learning to seek rewards and learning to avoid losses. We leveraged behavioral data from four RL experiments, which feature manipulations of two factors: outcome valence (gains vs. losses) and feedback information (partial vs. complete feedback). A Bayesian meta-analysis revealed that these contextual factors differently affect RTs and accuracy: While valence only affects RTs, feedback information affects both RTs and accuracy. To dissociate between the latent cognitive processes, we jointly fitted choices and RTs across all experiments with a Bayesian, hierarchical diffusion decision model (DDM). We found that the feedback manipulation affected drift rate, threshold, and non-decision time, suggesting that it was not a mere difficulty effect. Moreover, valence affected non-decision time and threshold, suggesting a motor inhibition in punishing contexts. To better understand the learning dynamics, we finally fitted a combination of RL and DDM (RLDDM). We found that while the threshold was modulated by trial-specific decision conflict, the non-decision time was modulated by the learned context valence. Overall, our results illustrate the benefits of jointly modeling RTs and choice data during RL, to reveal subtle mechanistic differences underlying decisions in different learning contexts.","link":"/opendata/fontanesi-et-al-2019/"},{"title":"Fontanesi et al. (2022)","text":"Recent years have witnessed a surge of interest in understanding the neural and cognitive dynamics that drive sequential decision making in general and foraging behavior in particular. Due to the intrinsic properties of most sequential decision-making paradigms, however, previous research in this area has suffered from the difficulty to disentangle properties of the decision related to (a) the value of switching to a new patch versus, which increases monotonically, and (b) the conflict experienced between choosing to stay or leave, which first increases but then decreases after reaching the point of indifference between staying and switching. Here, we show how the same problems arise in studies of sequential decision-making under risk, and how they can be overcome, taking as a specific example recent research on the ‘pig’ dice game. In each round of the ‘pig’ dice game, people roll a die and accumulate rewards until they either decide to proceed to the next round or lose all rewards. By combining simulation-based dissections of the task structure with two experiments, we show how an extension of the standard paradigm, together with cognitive modeling of decision-making processes, allows to disentangle properties related to either switch value or choice conflict. Our study elucidates the cognitive mechanisms of sequential decision making and underscores the importance of avoiding potential pitfalls of paradigms that are commonly used in this research area.","link":"/opendata/fontanesi-et-al-2022/"},{"title":"Forbes & Bennett (2023)","text":"The valence of an individual’s emotional response to an event is often thought to depend on their prior expectations for the event: better-than-expected outcomes produce positive affect and worse-than-expected outcomes produce negative affect. In recent years, this hypothesis has been instantiated within influential computational models of subjective affect that assume the valence of affect is driven by reward prediction errors. However, there remain a number of open questions regarding this association. In this project, we investigated the moderating effects of outcome valence and decision context (Experiment 1: free vs. forced choices; Experiment 2: trials with versus trials without counterfactual feedback) on the effects of reward prediction errors on subjective affect. We conducted two large-scale online experiments (N = 300 in total) of general-population samples recruited via Prolific to complete a risky decision-making task with embedded high-resolution sampling of subjective affect. Hierarchical Bayesian computational modelling revealed that the effects of reward prediction errors on subjective affect were significantly moderated by both outcome valence and decision context. Specifically, after accounting for concurrent reward amounts we found evidence that only negative reward prediction errors (worse-than-expected outcomes) influenced subjective affect, with no significant effect of positive reward prediction errors (better-than-expected outcomes). Moreover, these effects were only apparent on trials in which participants made a choice freely (but not on forced-choice trials) and when counterfactual feedback was absent (but not when counterfactual feedback was present). These results deepen our understanding of the effects of reward prediction errors on subjective affect.","link":"/opendata/forbes-bennett-2023/"},{"title":"Forys et al. (2022)","text":"We must often decide how much effort to exert or withhold to avoid undesirable outcomes or obtain rewards. In depression and anxiety, levels of avoidance can be excessive and reward-seeking may be reduced. Yet outstanding questions remain about the links between motivated action/inhibition and anxiety and depression levels, and whether they differ between men and women. Here we examined the relationship between anxiety and depression scores, and performance on effortful active and inhibitory avoidance (Study 1) and reward seeking (Study 2) in humans. Undergraduates and paid online workers (NAvoid=545, NReward=310; NFemale=368, NMale=450, MAge=22.58, RangeAge=17-62) were assessed on the Beck Depression Inventory II (BDI) and the Beck Anxiety Inventory (BAI) and performed an instructed online avoidance or reward-seeking task. Participants had to make multiple presses on active trials and withhold presses on inhibitory trials to avoid an unpleasant sound (Study 1) or obtain points towards a monetary reward (Study 2). Overall, men deployed more effort than women in both avoidance and reward-seeking, and anxiety scores were negatively associated with active reward-seeking performance based on sensitivity scores. Gender interacted with anxiety scores and inhibitory avoidance performance, such that women with higher anxiety showed worse avoidance performance. Our results illuminate effects of gender in the relationship between anxiety and depression levels and the motivation to actively and effortfully respond to obtain positive and avoid negative outcomes. We must often take or withhold effortful action to avoid unpleasant outcomes or obtain rewards. Depression and anxiety can impact these behaviours’ effectiveness, but the roles of avoidance in depression and reward-seeking in anxiety are not fully understood. Gender differences in avoidance and reward-seeking have also not been examined. We present a task in which community participants with a range of anxiety and depression levels made or withheld button presses to avoid hearing an unpleasant sound or obtain a reward. Men deployed more effort than women in avoidance, and women with higher anxiety scores had lower avoidance performance than men. We illuminate gender differences in how depressive and anxiety scores impact our ability to avoid threats and obtain rewards.","link":"/opendata/forys-et-al-2022/"},{"title":"Fox et al. (2023)","text":"Prior studies have found metacognitive impairments are linked to a transdiagnostic dimension of anxious-depression, manifesting as reduced confidence in performance (‘metacognitive bias’). However, previous work has been cross-sectional and so it is unclear if under-confidence is a trait-like marker of anxious-depression vulnerability, or if it resolves when anxious-depression improves. Data were collected as part of the ‘Precision in Psychiatry’ study, a large-scale transdiagnostic, four-week observational study of individuals initiating internet-based cognitive behavioural therapy (iCBT) or antidepressant medication. Self-reported clinical questionnaires and perceptual task performance were gathered to assess anxious-depression and metacognitive bias at baseline and four-week follow-up. Primary analyses were conducted for individuals who received iCBT (n=649), with comparisons between smaller samples that received antidepressant medication (n=88) and a control group receiving no intervention (n=82). Prior to receiving treatment, anxious-depression severity was associated with under-confidence in performance in the iCBT arm, replicating previous work. From baseline to follow-up, levels of anxious-depression were significantly reduced, and this was accompanied by a significant increase in metacognitive confidence (B=0.17, SE=0.02, p&lt;0.001). These changes were correlated (r(647)=-0.12, p=0.002); those with the greatest reductions in anxious-depression levels had the largest increase in confidence. In the antidepressant arm, anxious-depression reduced (B=-0.61, SE=0.09, p&lt;0.001) and confidence increased (B=0.31, SE=0.08, p&lt;0.001). Among controls, confidence remained stable from baseline to follow-up (B=0.11, SE=0.07, p=0.103). Metacognitive biases in anxious-depression are state-dependent; when symptoms improve with treatment, so does confidence in performance. Our results suggest this is not specific to the type of intervention.","link":"/opendata/fox-et-al-2023/"},{"title":"Fradkin et al. (2020)","text":"Obsessive compulsive (OC) symptoms involve excessive information gathering (e.g., checking, reassurance-seeking), and uncertainty about possible, often catastrophic, future events. Here we propose that these phenomena are the result of excessive uncertainty regarding state transitions (transition uncertainty): a computational impairment in Bayesian inference leading to a reduced ability to use the past to predict the present and future, and to oversensitivity to feedback (i.e. prediction errors). Using a computational model of Bayesian learning under uncertainty in a reversal learning task, we investigate the relationship between OC symptoms and transition uncertainty. Individuals high and low in OC symptoms performed a task in which they had to detect shifts (i.e. transitions) in cue-outcome contingencies. Modeling subjects choices was used to estimate each individual participants transition uncertainty and associated responses to feedback. We examined both an optimal observer model and an approximate Bayesian model in which participants were assumed to attend (and learn about) only one of several cues on each trial. Results suggested the participants were more likely to distribute attention across cues, in accordance with the optimal observer model. As hypothesized, participants with higher OC symptoms exhibited increased transition uncertainty, as well as a pattern of behavior potentially indicative of a difficulty in relying on learned contingencies, with no evidence for perseverative behavior. Increased transition uncertainty compromised these individuals ability to predict ensuing feedback, rendering them more surprised by expected outcomes. However, no evidence for excessive belief updating was found. These results highlight a potential computational basis for OC symptoms and obsessive compulsive disorder (OCD). The fact the OC symptoms predicted a decreased reliance on the past rather than perseveration challenges preconceptions of OCD as a disorder of inflexibility. Our results have implications for the understanding of the neurocognitive processes leading to excessive uncertainty and distrust of past experiences in OCD.","link":"/opendata/fradkin-et-al-2020/"},{"title":"Franklin & Frank (2020)","text":"Humans routinely face novel environments in which they have to generalize in order to act adaptively. However, doing so involves the non-trivial challenge of deciding which aspects of a task domain to generalize. While it is sometimes appropriate to simply re-use a learned behavior, often adaptive generalization entails recombining distinct components of knowledge acquired across multiple contexts. Theoretical work has suggested a computational trade-off in which it can be more or less useful to learn and generalize aspects of task structure jointly or compositionally, depending on previous task statistics, but it is unknown whether humans modulate their generalization strategy accordingly. Here we develop a series of navigation tasks that separately manipulate the statistics of goal values (what to do) and state transitions (how to do it) across contexts and assess whether human subjects generalize these task components separately or conjunctively. We find that human generalization is sensitive to the statistics of the previously experienced task domain, favoring compositional or conjunctive generalization when the task statistics are indicative of such structures, and a mixture of the two when they are more ambiguous. These results support a normative meta-generalization account and suggests that people not only generalize previous task components but also generalize the statistical structure most likely to support generalization.","link":"/opendata/franklin-frank-2020/"},{"title":"Frey et al. (2017)","text":"To what extent is there a general factor of risk preference, R, akin to g, the general factor of intelligence? Can risk preference be regarded as a stable psychological trait? These conceptual issues persist because few attempts have been made to integrate multiple risk-taking measures, particularly measures from different and largely unrelated measurement traditions (self-reported propensity measures assessing stated preferences, incentivized behavioral measures eliciting revealed preferences, and frequency measures assessing actual risky activities). Adopting a comprehensive psychometric approach (1507 healthy adults completing 39 risk-taking measures, with a subsample of 109 participants completing a retest session after 6 months), we provide a substantive empirical foundation to address these issues, finding that correlations between propensity and behavioral measures were weak. Yet, a general factor of risk preference, R, emerged from stated preferences and generalized to specific and actual real-world risky activities (for example, smoking). Moreover, R proved to be highly reliable across time, indicative of a stable psychological trait. Our findings offer a first step toward a general mapping of the construct risk preference, which encompasses both general and domain-specific components, and have implications for the assessment of risk preference in the laboratory and in the wild.","link":"/opendata/frey-et-al-2017/"},{"title":"Fung et al. (2019)","text":"Theoretical models distinguish between neural responses elicited by distal threats and those evoked by more immediate threats1-3. Specifically, slower cognitive fear responses towards distal threats involve a network of brain regions including the ventral hippocampus (vHPC) and medial prefrontal cortex (mPFC), while immediate reactive fear responses rely on regions such as the periaqueductal grey4,5. However, it is unclear how anxiety and its neural substrates relate to these distinct defensive survival circuits. We tested whether individual differences in trait anxiety would impact escape behaviour and neural responses to slow and fast attacking predators: conditions designed to evoke cognitive and reactive fear, respectively. Behaviourally, we found that trait anxiety was not related to escape decisions for fast threats, but individuals with higher trait anxiety escaped earlier during slow threats. Functional magnetic resonance imaging showed that when subjects faced slow threats, trait anxiety positively correlated with activity in the vHPC, mPFC, amygdala and insula. Furthermore, the strength of functional coupling between two components of the cognitive circuit-the vHPC and mPFC-was correlated with the degree of trait anxiety. This suggests that anxiety predominantly affects cognitive fear circuits that are involved in volitional strategic escape.","link":"/opendata/fung-et-al-2019/"},{"title":"Funkhouser et al. (2020)","text":"The popularity of network analysis in psychopathology research has increased exponentially in recent years. Yet, little research has examined the replicability of cross-sectional psychopathology network models, and those that have used single items for symptoms rather than multiitem scales. The present study therefore examined the replicability and generalizability of regularized partial correlation networks of internalizing symptoms within and across 5 samples (total N = 2,573) using the Inventory for Depression and Anxiety Symptoms, a factor analytically derived measure of individual internalizing symptoms. As different metrics may yield different conclusions about the replicability of network parameters, we examined both global and specific metrics of similarity between networks. Correlations within and between nonclinical samples suggested considerable global similarities in network structure (rss = .53-.87) and centrality strength (rss = .37-.86), but weaker similarities in network structure (rss = .36-.66) and centrality (rss = .04-.54) between clinical and nonclinical samples. Global strength (i.e., connectivity) did not significantly differ across all 5 networks and few edges (0-5.5%) significantly differed between networks. Specific metrics of similarity indicated that, on average, approximately 80% of edges were consistently estimated within and between all 5 samples. The most central symptom (i.e., dysphoria) was consistent within and across samples, but there were few other matches in centrality rank-order. In sum, there were considerable similarities in network structure, the presence and sign of individual edges, and the most central symptom within and across internalizing symptom networks estimated from nonclinical samples, but global metrics suggested network structure and symptom centrality had weak to moderate generalizability from nonclinical to clinical samples.","link":"/opendata/funkhouser-et-al-2020/"},{"title":"Gagne et al. (2020)","text":"Using a contingency volatility manipulation, we tested the hypothesis that difficulty adapting probabilistic decision-making to second-order uncertainty might reflect a core deficit that cuts across anxiety and depression and holds regardless of whether outcomes are aversive or involve reward gain or loss. We used bifactor modeling of internalizing symptoms to separate symptom variance common to both anxiety and depression from that unique to each. Across two experiments, we modeled performance on a probabilistic decision-making under volatility task using a hierarchical Bayesian framework. Elevated scores on the common internalizing factor, with high loadings across anxiety and depression items, were linked to impoverished adjustment of learning to volatility regardless of whether outcomes involved reward gain, electrical stimulation, or reward loss. In particular, high common factor scores were linked to dampened learning following better-than-expected outcomes in volatile environments. No such relationships were observed for anxiety- or depression-specific symptom factors.","link":"/opendata/gagne-et-al-2020/"},{"title":"Gagne et al. (2022)","text":"Individuals prone to anxiety and depression often report beliefs and make judgements about themselves that are more negative than those reported by others. We use computational modeling of a richly naturalistic task to disentangle the role of negative priors versus negatively biased belief updating and to investigate their association with different dimensions of Internalizing psychopathology. Undergraduate participants first provided profiles for a hypothetical tech internship. They then viewed pairs of other profiles and selected the individual they would prefer to work alongside out of each pair. In a subsequent phase of the experiment, participants made judgments about their relative popularity as hypothetical internship partners both before any feedback and after each of 20 items of feedback revealing whether or not they had been selected as the preferred teammate from a given pairing. Scores on latent factors of general negative affect, anxiety-specific affect and depression-specific affect were estimated using participants self-report scores on standardized measures of anxiety and depression together with factor loadings from a bifactor analysis conducted previously. Higher scores on the depression-specific factor were linked to more negative prior beliefs but were not associated with differences in belief updating. In contrast, higher scores on the anxiety-specific factor were associated with a negative bias in belief updating but no difference in prior beliefs. These findings indicate that, to at least some extent, distinct processes may impact the formation of belief priors and in-the-moment belief updating and that these processes may be differentially disrupted in depression and anxiety. Future directions for enquiry include examination of the possibility that prior beliefs biases in depression might reflect generalization from prior experiences or global schema whereas belief updating biases in anxiety might be more situationally specific.","link":"/opendata/gagne-et-al-2022/"},{"title":"Garcia et al. (2023)","text":"Standard models of decision-making assume each option is associated with subjective value, regardless of whether this value is inferred from experience (experiential) or explicitly instructed probabilistic outcomes (symbolic). In this study, we present results that challenge the assumption of unified representation of experiential and symbolic value. Across nine experiments, we presented participants with hybrid decisions between experiential and symbolic options. Participants choices exhibited a pattern consistent with a systematic neglect of the experiential values. This normatively irrational decision strategy held after accounting for alternative explanations, and persisted even when it bore an economic cost. Overall, our results demonstrate that experiential and symbolic values are not symmetrically considered in hybrid decisions, suggesting they recruit different representational systems that may be assigned different priority levels in the decision process. These findings challenge the dominant models commonly used in value-based decision-making research.","link":"/opendata/garcia-et-al-2023/"},{"title":"Garrett & Daw (2020)","text":"Deciding which options to engage, and which to forego, requires developing accurate beliefs about the overall distribution of prospects. Here we adapt a classic prey selection task from foraging theory to examine how individuals keep track of an environments reward rate and adjust choices in response to its fluctuations. Preference shifts were most pronounced when the environment improved compared to when it deteriorated. This is best explained by a trial-by-trial learning model in which participants estimate the reward rate with upward vs. downward changes controlled by separate learning rates. A failure to adjust expectations sufficiently when an environment becomes worse leads to suboptimal choices: options that are valuable given the environmental conditions are rejected in the false expectation that better options will materialize. These findings offer a previously unappreciated parallel in the serial choice setting of observations of asymmetric updating and resulting biased (often overoptimistic) estimates in other domains.","link":"/opendata/garrett-daw-2020/"},{"title":"Geddert & Egner (2022)","text":"Adaptive behavior requires the ability to focus on a current task and protect it from distraction (cognitive stability), as well as the ability to rapidly switch to another task in light of changing circumstances (cognitive flexibility). Cognitive stability and flexibility have been conceptualized as opposite endpoints on a stability-flexibility trade-off continuum, implying an obligatory reciprocity between the two: Greater flexibility necessitates less stability, and vice versa. Surprisingly, rigorous empirical tests of this critical assumption are lacking. Here, we acquired simultaneous measurements of cognitive stability (congruency effects) and flexibility (switch costs) on the same stimuli within the same task while independently varying contextual demands on these functions with block-wise manipulations of the proportion of incongruent trials and task switches, respectively. If cognitive stability and flexibility are reciprocal, increases in flexibility in response to higher switch rates should lead to commensurate decreases in stability, and increases in stability in response to more frequent incongruent trials should result in decreased flexibility. Across three experiments, using classic cued task-switching (Experiments 1 and 3) and attentional set-shifting (Experiment 2) protocols, we found robust evidence against an obligatory stability-flexibility trade-off. Although we observed the expected contextual adaptation of stability and flexibility to changing demands, strategic adjustments in stability had little influence on flexibility, and vice versa. These results refute the long-held assumption of a stability-flexibility trade-off, documenting instead that the cognitive processes mediating these functions can be regulated independently-it is possible to be both stable and flexible at the same time.","link":"/opendata/geddert-egner-2022/"},{"title":"Gera et al. (2022)","text":"Habits are a prominent feature of both adaptive and maladaptive behavior. Yet, despite substantial research efforts, there are currently no well-established experimental procedures for habit induction in humans. It is likely that laboratory experimental settings, as well as the session-based structure typically used in controlled experiments (also outside the lab), impose serious constraints on studying habits and other effects that are sensitive to context, motivation, and training duration and frequency. To overcome these challenges, we devised a unique real-world free-operant task structure, implemented through a novel smartphone application, whereby participants could freely enter the app (24 hours a day, 7 days a week) to win rewards. This procedure is free of typical laboratory constraints, yet well-controlled. Using the canonical sensitivity to outcome devaluation criterion, we successfully demonstrated habit formation as a function of training duration, a longstanding challenge in the field. Additionally, we show a positive relationship between multiple facets of engagement/motivation and goal-directedness. We suggest that our novel paradigm can be used to study the neurobehavioral and psychological mechanism underlying habits in humans. Moreover, the real-world free-operant framework can potentially be used to examine other instrumental behavior- related questions, with greater face validity in naturalistic conditions.","link":"/opendata/gera-et-al-2022/"},{"title":"Gerhardsson et al. (2020)","text":"To learn from feedback (trial and error) is essential for all species. Insufficient sleep has been found to reduce the sensitivity to feedback as well as increase reward sensitivity. To determine whether insufficient sleep alters learning from positive and negative feedback, healthy participants (n = 32, mean age 29.0 years, 18 women) were tested once after normal sleep (8 hr time in bed for 2 nights) and once after 2 nights of sleep restriction (4 hr/night) on a probabilistic selection task where learning behaviour was evaluated in three ways: as generalised learning, short-term win-stay/lose-shift learning strategies, and trial-by-trial learning rate. Sleep restriction did not alter the sensitivity to either positive or negative feedback on generalised learning. Also, short-term win-stay/lose-shift strategies were not affected by sleep restriction. Similarly, results from computational models that assess the trial-by-trial update of stimuli value demonstrated no difference between sleep conditions after the first block. However, a slower learning rate from negative feedback when evaluating all learning blocks was found after sleep restriction. Despite a marked increase in sleepiness and slowed learning rate for negative feedback, sleep restriction did not appear to alter strategies and generalisation of learning from positive or negative feedback.","link":"/opendata/gerhardsson-et-al-2020/"},{"title":"Gillan et al. (2016)","text":"Prominent theories suggest that compulsive behaviors, characteristic of obsessive-compulsive disorder and addiction, are driven by shared deficits in goal-directed control, which confers vulnerability for developing rigid habits. However, recent studies have shown that deficient goal-directed control accompanies several disorders, including those without an obvious compulsive element. Reasoning that this lack of clinical specificity might reflect broader issues with psychiatric diagnostic categories, we investigated whether a dimensional approach would better delineate the clinical manifestations of goal-directed deficits. Using large-scale online assessment of psychiatric symptoms and neurocognitive performance in two independent general-population samples, we found that deficits in goal-directed control were most strongly associated with a symptom dimension comprising compulsive behavior and intrusive thought. This association was highly specific when compared to other non-compulsive aspects of psychopathology. These data showcase a powerful new methodology and highlight the potential of a dimensional, biologically-grounded approach to psychiatry research.","link":"/opendata/gillan-et-al-2016/"},{"title":"Gillan et al. (2020)","text":"Goal-directed control guides optimal decision-making and it is an important cognitive faculty that protects against developing habits. Previous studies have found some evidence of goal-directed deficits when healthy individuals are stressed, and in psychiatric conditions characterised by compulsive behaviours and anxiety. Here, we tested if goal-directed control is affected by state anxiety, which might explain the former results. We carried out a causal test of this hypothesis in two experiments (between-subject N = 88; within-subject N = 50) that used the inhalation of hypercapnic gas (7.5% CO2) to induce an acute state of anxiety in healthy volunteers. In a third experiment (N = 1413), we used a correlational design to test if real-life anxiety-provoking events (panic attacks, stressful events) are associated with impaired goal-directed control. In the former two causal experiments, we induced a profoundly anxious state, both physiologically and psychologically, but this did not affect goal-directed performance. In the third, correlational, study, we found no evidence for an association between goal-directed control, panic attacks or stressful life eventsover and above variance accounted for by trait differences in compulsivity. In sum, three complementary experiments found no evidence that anxiety impairs goal-directed control in human subjects.","link":"/opendata/gillan-et-al-2020/"},{"title":"Giron et al. (2022)","text":"Analogies to stochastic optimization are common in developmental psychology, describing a gradual reduction in randomness (cooling off) over the lifespan. Yet for lack of concrete empirical comparison, there is ambiguity in interpreting this analogy. Using data from n=281 participants ages 5 to 55, we show that `cooling off does not only apply to the single dimension of randomness. Rather, development resembles an optimization process along multiple dimensions of learning (i.e., reward generalization, uncertainty-directed exploration, and random temperature). What begins as large tweaks in the parameters that define learning during childhood plateaus and converges to efficient parameter constellations in adulthood. The developmental trajectory of human parameters is strikingly similar to several stochastic optimization algorithms, yet we observe intriguing differences in convergence. Notably, none of the optimization algorithms discovered reliably better regions of the strategy space than adult participants, suggesting a remarkable efficiency of human development.","link":"/opendata/giron-et-al-2022/"},{"title":"Glickman et al. (2022)","text":"Evidence integration is a normative algorithm for choosing between alternatives with noisy evidence, which has been successful in accounting for vast amounts of behavioural and neural data. However, this mechanism has been challenged by non-integration heuristics, and tracking decision boundaries has proven elusive. Here we first show that the decision boundaries can be extracted using a model-free behavioural method termed decision classification boundary, which optimizes choice classification based on the accumulated evidence. Using this method, we provide direct support for evidence integration over non-integration heuristics, show that the decision boundaries collapse across time and identify an integration bias whereby incoming evidence is modulated based on its consistency with preceding information. This consistency bias, which is a form of pre-decision confirmation bias, was supported in four cross-domain experiments, showing that choice accuracy and decision confidence are modulated by stimulus consistency. Strikingly, despite its seeming sub-optimality, the consistency bias fosters performance by enhancing robustness to integration noise.","link":"/opendata/glickman-et-al-2022/"},{"title":"Glockner & Pachur (2012)","text":"In the behavioral sciences, a popular approach to describe and predict behavior is cognitive modeling with adjustable parameters (i.e., which can be fitted to data). Modeling with adjustable parameters allows, among other things, measuring differences between people. At the same time, parameter estimation also bears the risk of overfitting. Are individual differences as measured by model parameters stable enough to improve the ability to predict behavior as compared to modeling without adjustable parameters? We examined this issue in cumulative prospect theory (CPT), arguably the most widely used framework to model decisions under risk. Specifically, we examined (a) the temporal stability of CPTs parameters; and (b) how well different implementations of CPT, varying in the number of adjustable parameters, predict individual choice relative to models with no adjustable parameters (such as CPT with fixed parameters, expected value theory, and various heuristics). We presented participants with risky choice problems and fitted CPT to each individuals choices in two separate sessions (which were 1 week apart). All parameters were correlated across time, in particular when using a simple implementation of CPT. CPT allowing for individual variability in parameter values predicted individual choice better than CPT with fixed parameters, expected value theory, and the heuristics. CPTs parameters thus seem to pick up stable individual differences that need to be considered when predicting risky choice.","link":"/opendata/glockner-pachur-2012/"},{"title":"Goris et al. (2019)","text":"A common idea about individuals with autism spectrum disorder (ASD) is that they have an above-average preference for predictability and sameness. However, surprisingly little research has gone toward this core symptom, and some studies suggest the preference for predictability in ASD might be less general than commonly assumed. Here, we investigated this important symptom of ASD using three different paradigms, which allowed us to measure preference for predictability under well-controlled experimental conditions. Specifically, we used a dimensional approach by investigating correlations between autistic traits (as measured with the Autism-Spectrum Quotient and Social Responsiveness Scale in a neurotypical population) and the scores on three different tasks. The music preference task assessed preferences for tone sequences that varied in predictability. The perceptual fluency task required participants to evaluate stimuli that were preceded by a similar versus dissimilar subliminally presented prime. The gambling task presented four decks of cards that had equal outcome probabilities but varied in predictability. We observed positive correlations between autistic traits and a preference for predictability in both the music preference and perceptual fluency task. We did not find our hypothesized correlation with gambling behavior but did observe a post hoc correlation showing that participants with more autistic traits were faster to choose the predictable deck. Together, these findings show that a relation between autistic traits and preference for predictability can be observed in a standardized lab environment, and should be considered an important first step toward a better, more mechanistic understanding of insistence on sameness in ASD.","link":"/opendata/goris-et-al-2019/"},{"title":"Grahek et al. (2022)","text":"To determine how much cognitive control to invest in a task, people need to consider whether exerting control matters for obtaining rewards. In particular, they need to account for the efficacy of their performance-the degree to which rewards are determined by performance or by independent factors. Yet it remains unclear how people learn about their performance efficacy in an environment. Here we combined computational modeling with measures of task performance and EEG, to provide a mechanistic account of how people (i) learn and update efficacy expectations in a changing environment and (ii) proactively adjust control allocation based on current efficacy expectations. Across 2 studies, subjects performed an incentivized cognitive control task while their performance efficacy (the likelihood that rewards are performance-contingent or random) varied over time. We show that people update their efficacy beliefs based on prediction errors-leveraging similar neural and computational substrates as those that underpin reward learning-and adjust how much control they allocate according to these beliefs. Using computational modeling, we show that these control adjustments reflect changes in information processing, rather than the speed-accuracy tradeoff. These findings demonstrate the neurocomputational mechanism through which people learn how worthwhile their cognitive control is.","link":"/opendata/grahek-et-al-2022/"},{"title":"Grogan et al. (2022)","text":"Motivation can improve performance when the potential rewards outweigh the cost of effort expended. In working memory (WM), people can prioritise rewarded items at the expense of unrewarded items, suggesting a fixed memory capacity. But can capacity itself change with motivation? Across four experiments (N = 30-34) we demonstrate motivational improvements in WM even when all items were rewarded. However, this was not due to better memory precision, but rather better selection of the probed item within memory. Motivational improvements operated independently of encoding, maintenance, or attention shifts between items in memory. Moreover, motivation slowed responses. This contrasted with the benefits of rewarding items unequally, which allowed prioritisation of one item over another. We conclude that motivation can improve memory recall, not via precision or capacity, but via speed-accuracy trade-offs when selecting the item to retrieve.","link":"/opendata/grogan-et-al-2022/"},{"title":"Gross et al. (2021)","text":"Helping other people can entail risks for the helper. For example, when treating infectious patients, medical volunteers risk their own health. In such situations, decisions to help should depend on the individual’s valuation of others’ well-being (social preferences) and the degree of personal risk the individual finds acceptable (risk preferences). We investigated how these distinct preferences are psychologically and neurobiologically integrated when helping is risky. We used incentivized decision-making tasks (Study 1; N = 292 adults) and manipulated dopamine and norepinephrine levels in the brain by administering methylphenidate, atomoxetine, or a placebo (Study 2; N = 154 adults). We found that social and risk preferences are independent drivers of risky helping. Methylphenidate increased risky helping by selectively altering risk preferences rather than social preferences. Atomoxetine influenced neither risk preferences nor social preferences and did not affect risky helping. This suggests that methylphenidate-altered dopamine concentrations affect helping decisions that entail a risk to the helper.","link":"/opendata/gross-et-al-2021/"},{"title":"Grosskurth et al. (2019)","text":"Human decisions can be habitual or goal-directed, also known as model-free (MF) or model-based (MB) control. Previous work suggests that the balance between the two decision systems is impaired in psychiatric disorders such as compulsion and addiction, via overreliance on MF control. However, little is known whether the balance can be altered through task training. Here, 20 healthy participants performed a well-established two-step task that differentiates MB from MF control, across five training sessions. We used computational modelling and functional near-infrared spectroscopy to assess changes in decision-making and brain hemodynamic over time. Mixed-effects modelling revealed overall no substantial changes in MF and MB behavior across training. Although our behavioral and brain findings show task-induced changes in learning rates, these parameters have no direct relation to either MF or MB control or the balance between the two systems, and thus do not support the assumption of training effects on MF or MB strategies. Our findings indicate that training on the two-step paradigm in its current form does not support a shift in the balance between MF and MB control. We discuss these results with respect to implications for restoring the balance between MF and MB control in psychiatric conditions.","link":"/opendata/grosskurth-et-al-2019/"},{"title":"Haddara & Rahnev (2022)","text":"It is widely believed that feedback improves behavior, but the mechanisms behind this improvement remain unclear. Different theories postulate that feedback has either a direct effect on performance through automatic reinforcement mechanisms or only an indirect effect mediated by a deliberate change in strategy. To adjudicate between these competing accounts, we performed two large experiments on human adults (total N = 518); approximately half the participants received trial-by-trial feedback on a perceptual task, whereas the other half did not receive any feedback. We found that feedback had no effect on either perceptual or metacognitive sensitivity even after 7 days of training. On the other hand, feedback significantly affected participants’ response strategies by reducing response bias and improving confidence calibration. These results suggest that the beneficial effects of feedback stem from allowing people to adjust their strategies for performing the task and not from direct reinforcement mechanisms, at least in the domain of perception.","link":"/opendata/haddara-rahnev-2022/"},{"title":"Haines et al. (2020)","text":"Trait impulsivity—defined by strong preference for immediate over delayed rewards and difficulties inhibiting prepotent behaviors—is observed in all externalizing disorders, including substance-use disorders. Many laboratory tasks have been developed to identify decision-making mechanisms and correlates of impulsive behavior, but convergence between task measures and self-reports of impulsivity are consistently low. Long-standing theories of personality and decision-making predict that neurally mediated individual differences in sensitivity to (a) reward cues and (b) punishment cues (frustrative nonreward) interact to affect behavior. Such interactions obscure one-to-one correspondences between single personality traits and task performance. We used hierarchical Bayesian analysis in three samples with differing levels of substance use (N = 967) to identify interactive dependencies between trait impulsivity and state anxiety on impulsive decision-making. Our findings reveal how anxiety modulates impulsive decision-making and demonstrate benefits of hierarchical Bayesian analysis over traditional approaches for testing theories of psychopathology spanning levels of analysis.","link":"/opendata/haines-et-al-2020/"},{"title":"Hakim et al. (2019)","text":"Complex cognition relies on both on-line representations in working memory (WM), said to reside in the focus of attention, and passive off-line representations of related information. Here, we dissected the focus of attention by showing that distinct neural signals index the on-line storage of objects and sustained spatial attention. We recorded electroencephalogram (EEG) activity during two tasks that employed identical stimulus displays but varied the relative demands for object storage and spatial attention. We found distinct delay-period signatures for an attention task (which required only spatial attention) and a WM task (which invoked both spatial attention and object storage). Although both tasks required active maintenance of spatial information, only the WM task elicited robust contralateral delay activity that was sensitive to mnemonic load. Thus, we argue that the focus of attention is maintained via a collaboration between distinct processes for covert spatial orienting and object-based storage.","link":"/opendata/hakim-et-al-2019/"},{"title":"Hammond et al. (2020)","text":"High anxiety may be related insufficient sensitivity to changing reinforcement during operant learning. Whether such findings are specific to anxiety is unclear given a wider literature relating negative affect to abnormal learning and the possibility that relationships are not consistent across incentive types (i.e. punishment and reward) and outcomes (i.e., positive or negative). In two separate samples ( = 76; = 49), participants completed an operant learning task with positive, negative, and neutral socio-affective feedback, designed to assess adaptive responses to changing environmental volatility. Contrary to expectations, general affective distress, rather than anxiety or depression specifically, was related to an increase, rather than a decrease, in the rate of learning for negative outcomes in volatile, relative to stable, environments. Our results suggest an important but general role in anxiety and depression of overweighting negative feedback when the value of an action becomes uncertain, as when environmental volatility increases.","link":"/opendata/hammond-et-al-2020/"},{"title":"Hao et al. (2022)","text":"The Value Learning Task (VLT; e.g., Raymond &amp; OBrien, 2009) is widely used to investigate how acquired value impacts how we perceive and process stimuli. The task consists of a series of trials in which participants attempt to maximize accumulated winnings as they make choices from a pair of presented images associated with probabilistic win, loss, or no-change outcomes. The probabilities and outcomes are initially unknown to the participant and thus the task involves decision making and learning under uncertainty. Despite the symmetric outcome structure for win and loss pairs, people learn win associations better than loss associations (Lin, Cabrera-Haro, &amp; Reuter-Lorenz, 2020). This learning asymmetry could lead to differences when the stimuli are probed in subsequent tasks, compromising inferences about how acquired value affects downstream processing. We investigate the nature of the asymmetry using a standard error-driven reinforcement learning model with a softmax choice rule. Despite having no special role for valence, the model yields the learning asymmetry observed in human behavior, whether the model parameters are set to maximize empirical fit, or task payoff. The asymmetry arises from an interaction between a neutral initial value estimate and a choice policy that exploits while exploring, leading to more poorly discriminated value estimates for loss stimuli. We also show how differences in estimated individual learning rates help to explain individual differences in the observed win-loss asymmetries, and how the final value estimates produced by the model provide a simple account of a post-learning explicit value categorization task.","link":"/opendata/hao-et-al-2022/"},{"title":"Harhen & Bornstein (2022)","text":"Patch foraging presents a sequential decision-making problem widely studied across organisms — stay with a current option or leave it in search of a better alternative? Behavioral ecology has identified an optimal strategy for these decisions, but, across species, foragers systematically deviate from it, staying too long with an option or overharvesting relative to this optimum. Despite the ubiquity of this behavior, the mechanism underlying it remains unclear and an object of extensive investigation. Here, we address this gap by approaching foraging as both a decision-making and learning problem. Specifically, we propose a model in which foragers 1) rationally infer the structure in their environment and 2) use their uncertainty over the inferred structure representation to adaptively discount future rewards. We find that overharvesting can emerge from this rational statistical inference and uncertainty adaptation process. In a patch leaving task, we show that human participants adapt their foraging to the richness and dynamics of the environment in ways consistent with our model. These findings suggest that definitions of optimal foraging could be extended by considering how foragers reduce and adapt to uncertainty over representations of their environment.","link":"/opendata/harhen-bornstein-2022/"},{"title":"Harootonian et al. (2022)","text":"Successful navigation requires the ability to compute one’s location and heading from incoming multisensory information. Previous work has shown that this multisensory input comes in two forms: body-based idiothetic cues, from one’s own rotations and translations, and visual allothetic cues, from the environment (usually visual landmarks). However, exactly how these two streams of information are integrated is unclear, with some models suggesting the body-based idiothetic and visual allothetic cues are combined, while others suggest they compete. In this paper we investigated the integration of body-based idiothetic and visual allothetic cues in the computation of heading using virtual reality. In our experiment, participants performed a series of body turns of up to 360 degrees in the dark with only a brief flash (300ms) of visual feedback en route. Because the environment was virtual, we had full control over the visual feedback and were able to vary the offset between this feedback and the true heading angle. By measuring the effect of the feedback offset on the angle participants turned, we were able to determine the extent to which they incorporated visual feedback as a function of the offset error. By further modeling this behavior we were able to quantify the computations people used. While there were considerable individual differences in performance on our task, with some participants mostly ignoring the visual feedback and others relying on it almost entirely, our modeling results suggest that almost all participants used the same strategy in which idiothetic and allothetic cues are combined when the mismatch between them is small, but compete when the mismatch is large. These findings suggest that participants update their estimate of heading using a hybrid strategy that mixes the combination and competition of cues.","link":"/opendata/harootonian-et-al-2022/"},{"title":"Hayes & Wedell (2022a)","text":"Previous studies of reinforcement learning (RL) have established that choice outcomes are encoded in a context-dependent fashion. Several computational models have been proposed to explain context-dependent encoding, including reference point centering and range adaptation models. The former assumes that outcomes are centered around a running estimate of the average reward in each choice context, while the latter assumes that outcomes are compared to the minimum reward and then scaled by an estimate of the range of outcomes in each choice context. However, there are other computational mechanisms that can explain context dependence in RL. In the present study, a frequency encoding model is introduced that assumes outcomes are evaluated based on their proportional rank within a sample of recently experienced outcomes from the local context. A range-frequency model is also considered that combines the range adaptation and frequency encoding mechanisms. We conducted two fully incentivized behavioral experiments using choice tasks for which the candidate models make divergent predictions. The results were most consistent with models that incorporate frequency or rank-based encoding. The findings from these experiments deepen our understanding of the underlying computational processes mediating context-dependent outcome encoding in human RL.","link":"/opendata/hayes-wedell-2022a/"},{"title":"Hayes & Wedell (2022b)","text":"In reinforcement learning tasks, people learn the values of options relative to other options in the local context. Prior research suggests that relative value learning is enhanced when choice contexts are temporally clustered in a blocked sequence compared to a randomly interleaved sequence. The present study was aimed at further investigating the effects of blocked versus interleaved training using a choice task that distinguishes among different contextual encoding models. Our results showed that the presentation format in which contexts are experienced can lead to qualitatively distinct forms of relative value learning. This conclusion was supported by a combination of model-free and model-based analyses. In the blocked condition, choice behavior was most consistent with a reference point model in which outcomes are encoded relative to a dynamic estimate of the contextual average reward. In contrast, the interleaved condition was best described by a range-frequency encoding model. We propose that blocked training makes it easier to track contextual outcome statistics, such as the average reward, which may then be used to relativize the values of experienced outcomes. When contexts are interleaved, range-frequency encoding may serve as a more efficient means of storing option values in memory for later retrieval.","link":"/opendata/hayes-wedell-2022b/"},{"title":"Heffner et al. (2021)","text":"People make decisions based on deviations from expected outcomes, known as prediction errors. Past work has focused on reward prediction errors, largely ignoring violations of expected emotional experiences-emotion prediction errors. We leverage a method to measure real-time fluctuations in emotion as people decide to punish or forgive others. Across four studies (N = 1,016), we reveal that emotion and reward prediction errors have distinguishable contributions to choice, such that emotion prediction errors exert the strongest impact during decision-making. We additionally find that a choice to punish or forgive can be decoded in less than a second from an evolving emotional response, suggesting that emotions swiftly influence choice. Finally, individuals reporting significant levels of depression exhibit selective impairments in using emotion-but not reward-prediction errors. Evidence for emotion prediction errors potently guiding social behaviours challenge standard decision-making models that have focused solely on reward.","link":"/opendata/heffner-et-al-2021/"},{"title":"Hein et al. (2021)","text":"Clinical and subclinical (trait) anxiety impairs decision making and interferes with learning. Less understood are the effects of temporary anxious states on learning and decision making in healthy populations, and whether these can serve as a model for clinical anxiety. Here we test whether anxious states in healthy individuals elicit a pattern of aberrant behavioural, neural, and physiological responses comparable with those found in anxiety disorders-particularly when processing uncertainty in unstable environments. In our study, both a state anxious and a control group learned probabilistic stimulus-outcome mappings in a volatile task environment while we recorded their electrophysiological (EEG) signals. By using a hierarchical Bayesian model of inference and learning, we assessed the effect of state anxiety on Bayesian belief updating with a focus on uncertainty estimates. State anxiety was associated with an underestimation of environmental uncertainty, and informational uncertainty about the reward tendency. Anxious individuals beliefs about reward contingencies were more precise (had smaller uncertainty) and thus more resistant to updating, ultimately leading to impaired reward-based learning. State anxiety was also associated with greater uncertainty about volatility. We interpret this pattern as evidence that state anxious individuals are less tolerant to informational uncertainty about the contingencies governing their environment and more willing to be uncertain about the level of stability of the world itself. Further, we tracked the neural representation of belief update signals in the trial-by-trial EEG amplitudes. In control participants, lower-level precision-weighted prediction errors (pwPEs) about reward tendencies were represented in the ERP signals across central and parietal electrodes peaking at 496 ms, overlapping with the late P300 in classical ERP analysis. The state anxiety group did not exhibit a significant representation of low-level pwPEs, and there were no significant differences between the groups. Smaller variance in low-level pwPE about reward tendencies in state anxiety could partially account for the null results. Expanding previous computational work on trait anxiety, our findings establish that temporary anxious states in healthy individuals impair reward-based learning in volatile environments, primarily through changes in uncertainty estimates, which play a central role in current Bayesian accounts of perceptual inference and learning.","link":"/opendata/hein-et-al-2021/"},{"title":"Hellmann et al. (2022)","text":"Many decisions must be made with incomplete information. The ability to evaluate the resulting uncertainty is a key aspect of metacognition. As both confidence judgments and reaction times are expected to be closely related to sensory uncertainty, a mathematical model of human perceptual decision-making should be able to explain them both. Here, we propose the new dynamical evidence and visibility model (dynWEV), an extension of the drift diffusion model of decision making, to account for choices, reaction times, and confidence at the same time. The decision process in a binary perceptual task is described as a Wiener process accumulating sensory evidence about the choice options bounded by two constant thresholds. To account for confidence judgments, we assume a period of postdecisional accumulation of sensory evidence and parallel accumulation of information about the reliability of the present stimulus. We examined model fits in two experiments, a motion discrimination task with random dot kinematograms and a post-masked orientation discrimination task. A comparison between the dynamical evidence and visibility model, two-stage dynamical signal detection theory, and several versions of race models of decision making showed that only dynWEV produced acceptable fits of choices, confidence, and reaction time. This finding suggests that confidence judgments not only depend on choice evidence, but also on a parallel estimate of sensory uncertainty as well as postdecisional accumulation of evidence.","link":"/opendata/hellmann-et-al-2022/"},{"title":"Hertz et al. (2021)","text":"Social learning underpins our speciess extraordinary success. Learning through observation has been investigated in several species, but learning from advice-where information is intentionally broadcast-is less understood. We used a pre-registered, online experiment (n = 1492) combined with computational modelling to examine learning through observation and advice. Participants were more likely to immediately follow advice than to copy an observed choice, but this was dependent upon trust in the adviser: highly paranoid participants were less likely to follow advice in the short term. Reinforcement learning modelling revealed two distinct patterns regarding the long-term effects of social information: some individuals relied fully on social information, whereas others reverted to trial-and-error learning. This variation may affect the prevalence and fidelity of socially transmitted information. Our results highlight the privileged status of advice relative to observation and how the assimilation of intentionally broadcast information is affected by trust in others.","link":"/opendata/hertz-et-al-2021/"},{"title":"Hirmas & Engelmann (2023)","text":"Does attention have a causal impact on risky decisions? We address this question in a preregistered experiment in which participants accept or reject a series of mixed gambles while exogenously varying how information can be sampled. Specifically, in each trial participants observe the outcomes of a mixed-gamble with gains and losses presented sequentially. To isolate the causal role of attention on the decision process, we manipulate for how long a specific attribute is presented before showing the next one (e.g., 600 ms/800 ms vs 400 ms). Our results partially confirm our preregistered hypotheses that longer exposure to an attribute increases its weight on the decision. While we find no effects on choice frequency, we observe specific effects on the decision weights of our Random Utility Model. Presenting losses longer (for 600 ms, but not 800 ms) than gains (400 ms) leads to increased sensitivity for losses. When gains are presented for longer (600 ms and 800 ms) than losses (400 ms), the participants show increased sensitivity to both gain and loss values in their decision. Loss aversion reflects this trend across attention treatments, but differences remain non-significant. Further exploratory analyses show that specifically participants with higher impulsiveness become more sensitive to attribute values when gains are presented for longer. Jointly, these results support the notion that attention has a causal impact on the sensitivity to specific attributes during risky choice. Moreover, our results underline the moderating role of impulsiveness on the relationship between attention and choice.","link":"/opendata/hirmas-engelmann-2023/"},{"title":"Hitchcock et al. (2021)","text":"How does rumination affect reinforcement learning-the ubiquitous process by which we adjust behavior after error in order to behave more effectively in the future? In a within-subject design (n=49), we tested whether experimentally manipulated rumination disrupts reinforcement learning in a multidimensional learning task previously shown to rely on selective attention. Rumination impaired performance, yet unexpectedly this impairment could not be attributed to decreased attentional breadth (quantified using a decay parameter in a computational model). Instead, trait rumination (between subjects) was associated with higher decay rates (implying narrower attention), yet not with impaired performance. Our task-performance results accord with the possibility that state rumination promotes stress-generating behavior in part by disrupting reinforcement learning. The trait-rumination finding accords with the predictions of a prominent model of trait rumination (the attentional-scope model). More work is needed to understand the specific mechanisms by which state rumination disrupts reinforcement learning.","link":"/opendata/hitchcock-et-al-2021/"},{"title":"Hitchcock et al. (2022)","text":"Cognitive theories of depression, and mindfulness theories of well-being, converge on the notion that self-judgment plays a critical role in mental health. However, these theories have rarely been tested via tasks and computational modeling analyses that can disentangle the information processes operative in self-judgments. We applied a drift-diffusion computational model to the self-referential encoding task (SRET) collected before and after an 8-week mindfulness intervention (n = 96). A drift-rate regression parameter representing positive-relative to negative-self-referential judgment strength positively related to mindful awareness and inversely related to depression, both at baseline and over time; however, this parameter did not significantly relate to the interaction between mindful awareness and nonjudgmentalness. At the level of individual depression symptoms, at baseline, a spectrum of symptoms (inversely) correlated with the drift-rate regression parameter, suggesting that many distinct depression symptoms relate to valenced self-judgment between subjects. By contrast, over the intervention, changes in only a smaller subset of anhedonia-related depression symptoms showed substantial relationships with this parameter. Both behavioral and model-derived measures showed modest split-half and test-retest correlations. Results support cognitive theories that implicate self-judgment in depression and mindfulness theories, which imply that mindful awareness should lead to more positive self-views.","link":"/opendata/hitchcock-et-al-2022/"},{"title":"Homan et al. (2019)","text":"By combining computational, morphological, and functional analyses, this study relates latent markers of associative threat learning to overt post-traumatic stress disorder (PTSD) symptoms in combat veterans. Using reversal learning, we found that symptomatic veterans showed greater physiological adjustment to cues that did not predict what they had expected, indicating greater sensitivity to prediction errors for negative outcomes. This exaggerated weighting of prediction errors shapes the dynamic learning rate (associability) and value of threat predictive cues. The degree to which the striatum tracked the associability partially mediated the positive correlation between prediction-error weights and PTSD symptoms, suggesting that both increased prediction-error weights and decreased striatal tracking of associability independently contribute to PTSD symptoms. Furthermore, decreased neural tracking of value in the amygdala, in addition to smaller amygdala volume, independently corresponded to higher PTSD symptom severity. These results provide evidence for distinct neurocomputational contributions to PTSD symptoms.","link":"/opendata/homan-et-al-2019/"},{"title":"Horvath et al. (2021)","text":"Humans often face sequential decision-making problems, in which information about the environmental reward structure is detached from rewards for a subset of actions. In the current exploratory study, we introduce an information-selective symmetric reversal bandit task to model such situations and obtained choice data on this task from 24 participants. To arbitrate between different decision-making strategies that participants may use on this task, we developed a set of probabilistic agent-based behavioral models, including exploitative and explorative Bayesian agents, as well as heuristic control agents. Upon validating the model and parameter recovery properties of our model set and summarizing the participants choice data in a descriptive way, we used a maximum likelihood approach to evaluate the participants choice data from the perspective of our model set. In brief, we provide quantitative evidence that participants employ a belief state-based hybrid explorative-exploitative strategy on the information-selective symmetric reversal bandit task, lending further support to the finding that humans are guided by their subjective uncertainty when solving exploration-exploitation dilemmas. SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1007/s42113-021-00112-3.","link":"/opendata/horvath-et-al-2021/"},{"title":"Horwath et al. (2022)","text":"A large body of research illustrates the prioritization of goal-relevant information in memory; however, it is unclear how reward-related memories are organized. Using a rewarded free recall paradigm, we investigated how reward motivation structures the organization of memory around temporal and higher-order contexts. To better understand these processes, we simulated our findings using a reward-modulated variant of the Context Maintenance and Retrieval Model (CMR; Polyn et al., 2009). In the first study, we found that reward did not influence temporal clustering, but instead organized memory based on reward category. Further, we showed that a reward-modulated learning rate and source features of CMR most accurately depict reward’s enhancement of memory and clustering by value. In a second study, we showed that reward-memory effects can exist in both extended periods of sustained motivation and frequent changes in motivation, by showing equivocal reward effects using mixed- and pure-list motivation manipulations. However, we showed that a reward-modulated learning rate in isolation most accurately depicts reward’s enhancement of memory using a pure-list manipulation. Overall, we conclude that reward-related memories are adaptively organized by higher-order value information, and contextual binding to value contexts may only be necessary when rewards are intermittent versus sustained.","link":"/opendata/horwath-et-al-2022/"},{"title":"Hotaling et al. (2019)","text":"When people make risky choices, two kinds of information are crucial: outcome values and outcome probabilities. Here, we demonstrate that the juncture at which value and probability information is provided has a fundamental effect on choice. Across four experiments involving 489 participants, we compared two decision-making scenarios: one in which value information was revealed during sampling (standard) and one in which value information was revealed after sampling (value ignorance). On average, participants made riskier choices when value information was provided after sampling. Moreover, parameter estimates from a hierarchical Bayesian implementation of cumulative-prospect theory suggested that participants overweighted rare events when value information was absent during sampling but did not overweight such events in the standard condition. This suggests that the impact of rare events on choice relies crucially on the timing of probability and value integration. We provide paths toward mechanistic explanations of our results based on frameworks that assume different underlying cognitive architectures.","link":"/opendata/hotaling-et-al-2019/"},{"title":"Hoven et al. (2022)","text":"A growing body of evidence suggests that, during decision-making, BOLD signal in the ventromedial prefrontal cortex (VMPFC) correlates both with motivational variables - such as incentives and expected values - and metacognitive variables - such as confidence judgments - which reflect the subjective probability of being correct. At the behavioral level, we recently demonstrated that the value of monetary stakes bias confidence judgments, with gain (respectively loss) prospects increasing (respectively decreasing) confidence judgments, even for similar levels of difficulty and performance. If and how this value-confidence interaction is reflected in the VMPFC remains unknown. Here, we used an incentivized perceptual decision-making fMRI task that dissociates key decision-making variables, thereby allowing to test several hypotheses about the role of the VMPFC in the value-confidence interaction. While our initial analyses seemingly indicate that the VMPFC combines incentives and confidence to form an expected value signal, we falsified this conclusion with a meticulous dissection of qualitative activation patterns. Rather, our results show that strong VMPFC confidence signals observed in trials with gain prospects are disrupted in trials with no - or negative (loss) - monetary prospects. Deciphering how decision variables are represented and interact at finer scales seems necessary to better understand biased (meta)cognition.","link":"/opendata/hoven-et-al-2022/"},{"title":"Hunter et al. (2021)","text":"A goal of computational psychiatry is to ground symptoms in basic mechanisms. Theory suggests that avoidance in anxiety disorders may reflect dysregulated mental simulation, a process for evaluating candidate actions. If so, these covert processes should have observable consequences: choices reflecting increased and biased deliberation. In two online general population samples, we examined how self-report symptoms of social anxiety disorder predict choices in a socially framed reinforcement learning task, the patent race, in which the pattern of choices reflects the content of deliberation. Using a computational model to assess learning strategy, we found that self-report social anxiety was indeed associated with increased deliberative evaluation. This effect was stronger for a particular subset of feedback (upward counterfactual) in one of the experiments, broadly matching the biased content of rumination in social anxiety disorder, and robust to controlling for other psychiatric symptoms. These results suggest a grounding of symptoms of social anxiety disorder in more basic neuro-computational mechanisms.","link":"/opendata/hunter-et-al-2021/"},{"title":"Jana & Aron (2022)","text":"Mind wandering is a state in which our mental focus shifts toward task-unrelated thoughts. Although it is known that mind wandering has a detrimental effect on concurrent task performance (e.g., decreased accuracy), its effect on executive functions is poorly studied. Yet the latter question is relevant to many real-world situations, such as rapid stopping during driving. Here, we studied how mind wandering would affect the requirement to subsequently stop an incipient motor response. In healthy adults, we tested whether mind wandering affected stopping and, if so, which component of stopping was affected: the triggering of the inhibitory brake or the implementation of the brake following triggering. We observed that during mind wandering, stopping latency increased, as did the percentage of trials with failed triggering. Indeed, 67% of the variance of the increase in stopping latency was explained by increased trigger failures. Thus, mind wandering primarily affects stopping by affecting the triggering of the brake.","link":"/opendata/jana-aron-2022/"},{"title":"Jang et al. (2019)","text":"Dopamine is thought to provide reward prediction error signals to temporal lobe memory systems, but the role of these signals in episodic memory has not been fully characterized. Here we developed an incidental memory paradigm to (i) estimate the influence of reward prediction errors on the formation of episodic memories, (ii) dissociate this influence from surprise and uncertainty, (iii) characterize the role of temporal correspondence between prediction error and memoranda presentation and (iv) determine the extent to which this influence is dependent on memory consolidation. We found that people encoded incidental memoranda more strongly when they gambled for potential rewards. Moreover, the degree to which gambling strengthened encoding scaled with the reward prediction error experienced when memoranda were presented (and not before or after). This encoding enhancement was detectable within minutes and did not differ substantially after 24 h, indicating that it is not dependent on memory consolidation. These results suggest a computationally and temporally specific role for reward prediction error signalling in memory formation.","link":"/opendata/jang-et-al-2019/"},{"title":"Jaswetz et al. (2022)","text":"Simultaneous execution of memory retrieval and cognitively demanding interventions alter the subjective experience of aversive memories. This principle can be used in treatment to target traumatic memories. An often-used interpretation is that cognitive demand interferes with memory reconsolidation. Laboratory models applying this technique often do not meet some important procedural steps thought necessary to trigger reconsolidation. It remains therefore unclear whether cognitively demanding interventions can alter the reconsolidation process of aversive memories. Here, 78 (41 included) healthy participants completed an established 3-day threat conditioning paradigm. Two conditioned stimuli were paired with a shock (CS+ s) and one was not (CS-). The next day, one CS+ (CS+ R), but not the other (CS+), was presented as a reminder. After 10 min, participants performed a 2-back working memory task. On day three, we assessed retention. We found successful acquisition of conditioned threat and retention (CS+ s &gt; CS-). However, SCRs to the CS+ R and the CS+ during retention did not significantly differ. Although threat conditioning was successful, the well-established cognitively demanding intervention did not alter the reconsolidation process of conditioned threat memories. These findings challenge current views on how cognitively demand may enhance psychotherapy-outcome.","link":"/opendata/jaswetz-et-al-2022/"},{"title":"Jean-Richard-dit-Bressel et al. (2021)","text":"Punishment maximises the probability of our individual survival by reducing behaviours that cause us harm, and also sustains trust and fairness in groups essential for social cohesion. However, some individuals are more sensitive to punishment than others and these differences in punishment sensitivity have been linked to a variety of decision-making deficits and psychopathologies. The mechanisms for why individuals differ in punishment sensitivity are poorly understood, although recent studies of conditioned punishment in rodents highlight a key role for punishment contingency detection (Jean-Richard-Dit-Bressel et al., 2019). Here, we applied a novel Planets and Pirates conditioned punishment task in humans, allowing us to identify the mechanisms for why individuals differ in their sensitivity to punishment. We show that punishment sensitivity is bimodally distributed in a large sample of normal participants. Sensitive and insensitive individuals equally liked reward and showed similar rates of reward-seeking. They also equally disliked punishment and did not differ in their valuation of cues that signalled punishment. However, sensitive and insensitive individuals differed profoundly in their capacity to detect and learn volitional control over aversive outcomes. Punishment insensitive individuals did not learn the instrumental contingencies, so they could not withhold behaviour that caused punishment and could not generate appropriately selective behaviours to prevent impending punishment. These differences in punishment sensitivity could not be explained by individual differences in behavioural inhibition, impulsivity, or anxiety. This bimodal punishment sensitivity and these deficits in instrumental contingency learning are identical to those dictating punishment sensitivity in non-human animals, suggesting that they are general properties of aversive learning and decision-making.","link":"/opendata/jean-richard-dit-bressel-et-al-2021/"},{"title":"Jean-Richard-dit-Bressel et al. (2023)","text":"Individuals differ in sensitivity to the adverse consequences of their actions, leading some to persist in maladaptive behaviours. Two pathways have been identified for this insensitivity: a motivational pathway based on reward valuation and a behavioural pathway based on stimulus–response mechanisms. Here we identify a third, cognitive pathway based on differences in punishment knowledge. Exposed to identical punishment contingencies, some people (Sensitive) form correct causal beliefs that guide their behaviour to avoid punishment, whereas others form incorrect causal beliefs that lead them to earn punishment. Incorrect causal beliefs were not inherently problematic, many individuals benefited from information about why punishment was occurring, revaluing their actions and changing their behaviour (Unaware). However, we identify one condition where incorrect causal beliefs can be problematic: when punishment is infrequent. Under this condition, more individuals showed detrimental patterns of behaviour that resisted information-driven updating (Compulsive). For these individuals, rare punishment inoculated behavioural preferences against cognitive and behavioural updating.","link":"/opendata/jean-richard-dit-bressel-et-al-2023/"},{"title":"Kaanders et al. (2022)","text":"No one likes to be wrong. Previous research has shown that participants may underweight information incompatible with previous choices, a phenomenon called confirmation bias. In this paper, we argue that a similar bias exists in the way information is actively sought. We investigate how choice influences information gathering using a perceptual choice task and find that participants sample more information from a previously chosen alternative. Furthermore, the higher the confidence in the initial choice, the more biased information sampling becomes. As a consequence, when faced with the possibility of revising an earlier decision, participants are more likely to stick with their original choice, even when incorrect. Critically, we show that agency controls this phenomenon. The effect disappears in a fixed sampling condition where presentation of evidence is controlled by the experimenter, suggesting that the way in which confirmatory evidence is acquired critically impacts the decision process. These results suggest active information acquisition plays a critical role in the propagation of strongly held beliefs over time.","link":"/opendata/kaanders-et-al-2022/"},{"title":"Kahveci et al. (2022)","text":"Reaction time (RT) data are often pre-processed before analysis by rejecting outliers and errors and aggregating the data. In stimulus-response compatibility paradigms such as the Approach-Avoidance Task (AAT), researchers often decide how to pre-process the data without an empirical basis, leading to the use of methods that may hurt rather than help data quality. To provide this empirical basis, we investigated how different pre-processing methods affect the reliability and validity of this task. Our literature review revealed 108 different pre-processing pipelines among 163 examined studies. Using simulated and real datasets, we found that validity and reliability were negatively affected by retaining error trials, by replacing error RTs with the mean RT plus a penalty, by retaining outliers, and by removing the highest and lowest sample-wide RT percentiles as outliers. We recommend removing error trials and rejecting RTs deviating more than 2 or 3 SDs from the participant mean. Bias scores were more reliable but not more valid if computed with means or D-scores rather than with medians. Bias scores were less accurate if based on averaging multiple conditions together, as with compatibility scores, rather being than based on separate averages per condition, as with double-difference scores. We call upon the field to drop the suboptimal practices to improve the psychometric properties of the AAT. We also call for similar investigations in related RT-based cognitive bias measures such as the implicit association task, as their commonly accepted pre-processing practices currently involve many of the aforementioned discouraged methods.","link":"/opendata/kahveci-et-al-2022/"},{"title":"Kaplan & Solway (2022)","text":"Computational models of decision making have identified a relationship between obsessive-compulsive symptoms (OCS), both in the general population and in patients, and impairments in perceptual evidence accumulation. Some studies have interpreted these deficits to reflect global disease traits which give rise to clusters of OCS. Such assumptions are not uncommon, even if implicit, in computational psychiatry more broadly. However, it is well established that state- and trait-symptom scores are often correlated (e.g., state and trait anxiety), and the extent to which perceptual deficits are actually explained by state-based symptoms is unclear. State-based symptoms may give rise to information processing differences in a number of ways, including the mechanistically less interesting possibility of tying up working memory and attentional resources for off-task processing. In a general population sample (N = 150), we investigated the extent to which previously identified impairments in perceptual evidence accumulation were related to trait vs stated-based OCS. In addition, we tested whether differences in working memory capacity moderated state-based impairments, such that impairments were worse in individuals with lower working memory capacity. We replicated previous work demonstrating a negative relationship between the rate of evidence accumulation and trait-based OCS when state-based symptoms were unaccounted for. When state-based effects were included in the model, they captured a significant degree of impairment while trait-based effects were attenuated, although they did not disappear completely. We did not find evidence that working memory capacity moderated the state-based effects. Our work suggests that investigating the relationship between information processing and state-based symptoms may be important more generally in computational psychiatry beyond this specific context.","link":"/opendata/kaplan-solway-2022/"},{"title":"Karagoz et al. (2022)","text":"When making decisions, we sometimes rely on habit and at other times plan towards goals. Planning requires the construction and use of an internal representation of the environment, a cognitive map. How are these maps constructed, and how do they guide goal-directed decisions? We coupled a sequential decision-making task with a behavioral representational similarity analysis approach to examine how relationships between choice options change when people build a cognitive map of the task structure. We found that participants who encoded stronger higher-order relationships among choice options showed increased planning and better performance. These higher-order relationships were more strongly encoded among objects encountered in high-reward contexts, indicating a role for motivation during cognitive map construction. In contrast, lower-order relationships such as simple visual co-occurrence of objects did not predict goal-directed planning. These results show that humans actively construct and use cognitive maps of task structure to make goal-directed decisions.","link":"/opendata/karagoz-et-al-2022/"},{"title":"Kapser et al. (2023)","text":"Why can initial biases persist in repeated choice tasks? Previous research has shown that frequent rewards can lure the decision maker into premature exploitation of a supposedly best option, which can result in the persistence of initial biases. Here, we demonstrate that even in the absence of rewards, initial biases can be perpetuated through a positive testing strategy. After eliciting a biased preference for one of two equally rewarding options, participants (N = 203) could sample freely from both options without the lure of any financial rewards. When participants were told to rule out alternatives in this phase, they explored the supposedly worse option and thereby managed to overcome their initial bias. When told to optimize their strategy, however, they exhibited a positive testing strategy resulting in the continued exploitation of the supposedly better option, a bias they maintained in an incentivized choice phase and later judgments. Across all participants, individual tendencies to exploit one option in earlier phases predicted biased behavior in subsequent phases. The findings highlight that not only the pursuit of instrumental rewards can lead to exploitation and the maintenance of initial biases. We discuss potential consequences for interventions.","link":"/opendata/kapser-et-al-2023/"},{"title":"Kasparek et al. (2020)","text":"Childhood adversity is common and strongly associated with risk for psychopathology. Identifying factors that buffer children from experiencing psychopathology following adversity is critical for developing more effective intervention approaches. The present study examined several behavioral metrics of reward processing reflecting global approach motivation for reward and the degree to which reward responses scaled with reward value (i.e., behavioral sensitivity to reward value) as potential moderators of the association of multiple dimensions of adversity-including trauma, caregiver neglect, and food insecurity-with depression and externalizing psychopathology in a sample of youth aged 8-16 years (n = 132). Trauma exposure and externalizing problems were positively associated at low and moderate levels of reward reactivity, but this association became non-significant at high levels of reward reactivity. Our findings extend prior work, suggesting that high behavioral sensitivity to reward value may buffer against externalizing problems following exposure to trauma.","link":"/opendata/kasparek-et-al-2020/"},{"title":"Kelly & Sharot (2021)","text":"Vast amounts of personalized information are now available to individuals. A vital research challenge is to establish how people decide what information they wish to obtain. Here, over five studies examining information-seeking in different domains we show that information-seeking is associated with three diverse motives. Specifically, we find that participants assess whether information is useful in directing action, how it will make them feel, and whether it relates to concepts they think of often. We demonstrate that participants integrate these assessments into a calculation of the value of information that explains information seeking or its avoidance. Different individuals assign different weights to these three factors when seeking information. Using a longitudinal approach, we find that the relative weights assigned to these information-seeking motives within an individual show stability over time, and are related to mental health as assessed using a battery of psychopathology questionnaires.","link":"/opendata/kelly-sharot-2021/"},{"title":"Kemp et al. (2022)","text":"The underlying vulnerability for schizophrenia-spectrum disorders is expressed across a continuum of clinical and subclinical symptoms and impairment referred to as schizotypy. Schizotypy is a multidimensional construct with positive, negative, and disorganized dimensions. Models of pathological personality provide useful frameworks for assessing the multidimensional structure of schizotypy. The present study examined the association of positive, negative, and disorganized schizotypy with pathological personality traits and facets assessed by the Personality Inventory for DSM-5 (PID-5) in 1,342 young adults. As hypothesized, positive schizotypy was largely associated with the PID-5 psychoticism domain and facets, negative schizotypy was primarily associated with the detachment domain and facets and the restricted affectivity facet, and disorganized schizotypy’s strongest associations were with the distractibility and eccentricity facets and the negative affect domain. Negative schizotypy was differentiated from the other two schizotypy dimensions in its pattern of correlations with the PID-5 domains and facets. As expected, positive and disorganized schizotypy exhibited a moderate degree of similarity in their associations. Overall, the PID-5 domains accounted for approximately half of the variance in each of the schizotypy dimensions, and the PID-5 facets accounted for upwards of 2/3rds of the variance in each schizotypy dimension. The associations among the schizotypy and PID-5 measures did not appear to reflect highly redundant items across the measures. We conclude by providing regression-based algorithms for computing positive, negative, and disorganized schizotypy scores based on the PID-5 facets.","link":"/opendata/kemp-et-al-2022/"},{"title":"Klein et al. (2017)","text":"To decide optimally between available options, organisms need to learn the values associated with these options. Reinforcement learning models offer a powerful explanation of how these values are learnt from experience. However, human choices often violate normative principles. We suggest that seemingly counterintuitive decisions may arise as a natural consequence of the learning mechanisms deployed by humans. Here, using fMRI and a novel behavioural task, we show that, when suddenly switched to novel choice contexts, participants choices are incongruent with values learnt by standard learning algorithms. Instead, behaviour is compatible with the decisions of an agent learning how good an option is relative to an option with which it had previously been paired. Striatal activity exhibits the characteristics of a prediction error used to update such relative option values. Our data suggest that choices can be biased by a tendency to learn option values with reference to the available alternatives.","link":"/opendata/klein-et-al-2017/"},{"title":"Klingelhöfer-Jens et al. (2022)","text":"Here, we follow the call to target measurement reliability as a key prerequisite for individual-level predictions in translational neuroscience by investigating (1) longitudinal reliability at the individual and (2) group level, (3) internal consistency and (4) response predictability across experimental phases. One hundred and twenty individuals performed a fear conditioning paradigm twice 6 months apart. Analyses of skin conductance responses, fear ratings and blood oxygen level dependent functional magnetic resonance imaging (BOLD fMRI) with different data transformations and included numbers of trials were conducted. While longitudinal reliability was rather limited at the individual level, it was comparatively higher for acquisition but not extinction at the group level. Internal consistency was satisfactory. Higher responding in preceding phases predicted higher responding in subsequent experimental phases at a weak to moderate level depending on data specifications. In sum, the results suggest that while individual-level predictions are meaningful for (very) short time frames, they also call for more attention to measurement properties in the field.","link":"/opendata/klingelhofer-jens-et-al-2022/"},{"title":"Kobor et al. (2021)","text":"Both primarily and recently encountered information have been shown to influence experience-based risky decision making. The primacy effect predicts that initial experience will influence later choices even if outcome probabilities change and reward is ultimately more or less sparse than primarily experienced. However, it has not been investigated whether extended initial experience would induce a more profound primacy effect upon risky choices than brief experience. Therefore, the present study tested in two experiments whether young adults adjusted their risk-taking behavior in the Balloon Analogue Risk Task after an unsignaled and unexpected change point. The change point separated early good luck or bad luck trials from subsequent ones. While mostly positive (more reward) or mostly negative (no reward) events characterized the early trials, subsequent trials were unbiased. In Experiment 1, the change point occurred after one-sixth or one-third of the trials (brief vs. extended experience) without intermittence, whereas in Experiment 2, it occurred between separate task phases. In Experiment 1, if negative events characterized the early trials, after the change point, risk-taking behavior increased as compared with the early trials. Conversely, if positive events characterized the early trials, risk-taking behavior decreased after the change point. Although the adjustment of risk-taking behavior occurred due to integrating recent experiences, the impact of initial experience was simultaneously observed. The length of initial experience did not reliably influence the adjustment of behavior. In Experiment 2, participants became more prone to take risks as the task progressed, indicating that the impact of initial experience could be overcome. Altogether, we suggest that initial beliefs about outcome probabilities can be updated by recent experiences to adapt to the continuously changing decision environment.","link":"/opendata/kobor-et-al-2021/"},{"title":"Konovalov & Krajbich (2020)","text":"Converging evidence has demonstrated that humans exhibit two distinct strategies when learning in complex environments. One is model-free learning, i.e., simple reinforcement of rewarded actions, and the other is model-based learning, which considers the structure of the environment. Recent work has argued that people exhibit little model-based behavior unless it leads to higher rewards. Here we use mouse tracking to study model-based learning in stochastic and deterministic (pattern-based) environments of varying difficulty. In both tasks participants mouse movements reveal that they learned the structures of their environments, despite the fact that standard behavior-based estimates suggested no such learning in the stochastic task. Thus, we argue that mouse tracking can reveal whether subjects have structure knowledge, which is necessary but not sufficient for model-based choice.","link":"/opendata/konovalov-krajbich-2020/"},{"title":"Konstantinidis et al. (2018)","text":"Recent experimental evidence in experience-based decision-making suggests that people are more risk seeking in the gains domain relative to the losses domain. This critical result is at odds with the standard reflection effect observed in description-based choice and explained by Prospect Theory. The so-called reversed-reflection effect has been predicated on the extreme-outcome rule, which suggests that memory biases affect risky choice from experience. To test the general plausibility of the rule, we conducted two experiments examining how the magnitude of prospective outcomes impacts risk preferences. We found that while the reversed-reflection effect was present with small-magnitude payoffs, using payoffs of larger magnitude brought participants behavior back in line with the standard reflection effect. Our results suggest that risk preferences in experience-based decision-making are not only affected by the relative extremeness but also by the absolute extremeness of past events.","link":"/opendata/konstantinidis-et-al-2018/"},{"title":"Kool et al. (2017)","text":"Human behavior is sometimes determined by habit and other times by goal-directed planning. Modern reinforcement-learning theories formalize this distinction as a competition between a computationally cheap but inaccurate model-free system that gives rise to habits and a computationally expensive but accurate model-based system that implements planning. It is unclear, however, how people choose to allocate control between these systems. Here, we propose that arbitration occurs by comparing each systems task-specific costs and benefits. To investigate this proposal, we conducted two experiments showing that people increase model-based control when it achieves greater accuracy than model-free control, and especially when the rewards of accurate performance are amplified. In contrast, they are insensitive to reward amplification when model-based and model-free control yield equivalent accuracy. This suggests that humans adaptively balance habitual and planned action through on-line cost-benefit analysis.","link":"/opendata/kool-et-al-2017/"},{"title":"Kool et al. (2018)","text":"Decision-making algorithms face a basic tradeoff between accuracy and effort (i.e., computational demands). It is widely agreed that humans can choose between multiple decision-making processes that embody different solutions to this tradeoff: Some are computationally cheap but inaccurate, whereas others are computationally expensive but accurate. Recent progress in understanding this tradeoff has been catalyzed by formalizing it in terms of model-free (i.e., habitual) versus model-based (i.e., planning) approaches to reinforcement learning. Intuitively, if two tasks offer the same rewards for accuracy but one of them is much more demanding, we might expect people to rely on habit more in the difficult task: Devoting significant computation to achieve slight marginal accuracy gains would not be worth it. We test and verify this prediction in a sequential reinforcement learning task. Because our paradigm is amenable to formal analysis, it contributes to the development of a computational model of how people balance the costs and benefits of different decision-making processes in a task-specific manner; in other words, how we decide when hard thinking is worth it.","link":"/opendata/kool-et-al-2018/"},{"title":"Koppel et al. (2022)","text":"Most disciplines rely on economic games to measure prosocial behavior in controlled experimental settings. However, participants’ comprehension of these games might be lower than desirable, which complicates interpretation of results. We here assess subject comprehension of the payoff structure of five standard economic games commonly used to study prosocial behavior: the Dictator Game, Ultimatum Game, Trust Game, Public Goods Game, and Prisoner’s Dilemma. Participants were recruited from two online platforms: Prolific (n = 528) and CloudResearch (using the CloudResearch MTurk toolkit; n = 540). The Trust Game had the highest level of misunderstanding (70%), followed by the Public Goods Game and the Prisoner’s Dilemma (each at 52%), the Ultimatum Game (27%), and the Dictator Game (24%). Study platform was a significant predictor of misunderstanding in the Dictator Game, Ultimatum Game, and Public Goods Game, with greater misunderstanding on Prolific than CloudResearch. Incentivizing the comprehension questions had no significant impact on misunderstanding in any of the games. The only variable that significantly predicted misunderstanding across all games was numeracy, which was associated with lower misunderstanding. Finally, we found suggestive evidence in exploratory analyses that misunderstanding predicts greater contributions in the Public Goods Game (in line with previous studies) and in the Dictator Game, increased the likelihood to choose the option that maximizes total payoff in the Prisoner’s Dilemma and reduced back transfers in the Trust Game. These findings suggest that misunderstanding may be an important factor in explaining prosocial behavior and that reliance on standard one-shot games may lead researchers to overestimate the importance of social preferences.","link":"/opendata/koppel-et-al-2022/"},{"title":"Kraft et al. (2022)","text":"Cognitive flexibility - the ability to adjust one ´s behavior to changing environmental demands - is crucial for controlled behavior. However, the term cognitive flexibility is used heterogeneously, and associations between cognitive flexibility and other facets of flexible behavior have only rarely been studied systematically. To resolve some of these conceptual uncertainties, we directly compared cognitive flexibility (cue-instructed switching between two affectively neutral tasks), affective flexibility (switching between a neutral and an affective task using emotional stimuli), and feedback-based flexibility (non-cued, feedback-dependent switching between two neutral tasks). Three experimental paradigms were established that share as many procedural features (in terms of stimuli and/or task rules) as possible and administered in a pre-registered study plan (N = 100). Correlation analyses revealed significant associations between the efficiency of cognitive and affective task switching (response time switch costs). Feedback-based flexibility (measured as mean number of errors after rule reversals) did not correlate with task switching efficiency in the other paradigms, but selectively with the effectiveness of affective switching (error rate costs when switching from neutral to emotion task). While preregistered confirmatory factor analysis (CFA) provided no clear evidence for a shared factor underlying the efficiency of switching in all three domains of flexibility, an exploratory CFA suggested commonalities regarding switching effectiveness (accuracy-based switch costs). We propose shared mechanisms controlling the efficiency of cue-dependent task switching across domains, while the relationship to feedback-based flexibility may depend on mechanisms controlling switching effectiveness. Our results call for a more stringent conceptual differentiation between different variants of psychological flexibility.","link":"/opendata/kraft-et-al-2022/"},{"title":"Kristjansson & Kristjansson (2023)","text":"Go/No-Go responses in visual search yield different estimates of the properties of visual search than more standard present and absent tasks. Such minor methodological tweaks have a surprisingly large effect on measures that have, for the last half-century or so, formed the backbone of prominent theories of visual attention. Secondly, priming effects in visual search have a dominating influence on visual search, accounting for effects that have been attributed to top-down guidance in standard theories. Priming effects in visual search have never been investigated for Go/No-Go present/absent decisions. Here, Go/No-Go tasks were used to assess visual search for an odd-one-out face, defined either by color or facial expression. The Go/No-Go responses for the color-based task were very fast for both present and absent and interestingly “Go” responses were even faster for the target absent case. The “Go” responses were, on the other hand, much slower for expression and became higher with increased set-size, particularly for the target-absent response. Priming effects were considerable for the feature search, but for expression, the target absent priming was strong but very weak for target present trials, arguing that repetition priming for this search mainly reflects priming of context rather than target features. Overall, the results reinforce the point that Go/No-Go tasks are highly informative for theoretical accounts of visual attention, and cast a new light on attentional priming.","link":"/opendata/kristjansson-kristjansson-2023/"},{"title":"Kroker et al. (2022)","text":"SummaryThe framing-effect is a bias that affects decision-making depending on whether the available options are presented with positive or negative connotations. Even when the outcome of two choices is equivalent, people have a strong tendency to avoid the negatively framed option because losses are perceived about twice as salient as gains of the same amount (i.e. loss-aversion). The ventromedial prefrontal cortex (vmPFC) is crucial for rational decision-making, and dysfunctions in this region have been linked to cognitive biases, impulsive behavior and gambling addiction. Using a financial decision-making task in combination with magnetoencephalographic neuroimaging, we show that excitatory compared to inhibitory non-invasive transcranial direct current stimulation (tDCS) of the vmPFC reduces framing-effects while improving the assessment of loss-probabilities, ultimately leading to increased overall gains. Behavioral and neural data consistently suggest that this improvement in rational decision-making is predominately a consequence of reduced loss-aversion. These findings recommend further research towards clinical applications of vmPFC-tDCS in addictive disorders.","link":"/opendata/kroker-et-al-2022/"},{"title":"Kucina et al. (2022)","text":"Standard, well-established cognitive tasks that produce reliable effects in group comparisons also lead to unreliable measurement when assessing individual differences. This “reliability paradox” has been demonstrated in decision-conflict tasks such as the Simon, Flanker, and Stroop tasks, which measure various aspects of cognitive control. We aimed to address this paradox by implementing carefully calibrated versions of the standard tests with an additional manipulation to encourage processing of conflicting information, as well as combinations of standard tasks. A series of experiments concluded that a Flanker task and a combined Simon and Stroop task with the additional manipulation produced reliable estimates of individual differences in under 100 trials per task, which markedly improves on the reliability seen in benchmark Flanker, Simon, and Stroop data. We make the new tasks freely available and discuss both theoretical and applied implications regarding how the cognitive testing of individual differences is carried out.","link":"/opendata/kucina-et-al-2022/"},{"title":"Kurtenbach et al. 2022","text":"Performance during instrumental learning is commonly believed to reflect the knowledge that has been acquired up to that point. However, recent work in rodents found that instrumental performance was enhanced during periods when reinforcement was withheld, relative to periods when reinforcement was provided. This suggests that reinforcement may mask acquired knowledge and lead to impaired performance. In the present study, we investigated whether such a beneficial effect of removing reinforcement translates to humans. Specifically, we tested whether performance during learning was improved during non-reinforced relative to reinforced task periods using signal detection theory and a computational modelling approach. To this end, 60 healthy volunteers performed a novel visual go/no-go learning task with deterministic reinforcement. To probe acquired knowledge in the absence of reinforcement, we interspersed blocks without feedback. In these non-reinforced task blocks, we found an increased d, indicative of enhanced instrumental performance. However, computational modelling showed that this improvement in performance was not due to an increased sensitivity of decision making to learnt values, but to a more cautious mode of responding, as evidenced by a reduction of a general response bias. Together with an initial tendency to act, this is sufficient to drive differential changes in hit and false alarm rates that jointly lead to an increased d. To conclude, the improved instrumental performance in the absence of reinforcement observed in studies using asymmetrically reinforced go/no-go tasks may reflect a change in response bias rather than unmasking latent knowledge.","link":"/opendata/kurtenbach-et-al-2022/"},{"title":"Kvam et al. (2023)","text":"People discount both future outcomes that could happen and past outcomes that could have happened according to how far away they are in time. A common finding is that future outcomes are often preferred to past ones when the payoffs and temporal distance (how long ago/until they occur) are matched, referred to as temporal value asymmetry. In this article, we examine the consistency of this effect by examining the effect of manipulating the magnitude and delays of past and future payoffs on participants’ choices and challenge the claim that differences in value are primarily due to differences in discounting rates for past and future events. We find reversals of the temporal value asymmetry when payoffs are low and when temporal distance is large, suggesting that people have different sensitivity to the magnitude of past and future payoffs. We show that these effects can be accommodated in a direct difference model of intertemporal choice but not in the most common discounting models (hyperboloid), suggesting that both temporal distance and payoff magnitude carry independent influences on the subjective value of past and future outcomes. Finally, we explore how these tendencies to represent past and future outcome values are related to one another and to individual differences in personality and psychological traits, showing how these measures cluster according to whether they measure processes related to past/future events, payoffs/delays, and whether they are behavioral/self-report measures.","link":"/opendata/kvam-et-al-2023/"},{"title":"Lamba et al. (2020)","text":"Very little is known about how individuals learn under uncertainty when other people are involved. We propose that humans are particularly tuned to social uncertainty, which is especially noisy and ambiguous. Individuals exhibiting less tolerance for uncertainty, such as those with anxiety, may have greater difficulty learning in uncertain social contexts and therefore provide an ideal test population to probe learning dynamics under uncertainty. Using a dynamic trust game and a matched nonsocial task, we found that healthy subjects (n = 257) were particularly good at learning under negative social uncertainty, swiftly figuring out when to stop investing in an exploitative social partner. In contrast, subjects with anxiety (n = 97) overinvested in exploitative partners. Computational modeling attributed this pattern to a selective reduction in learning from negative social events and a failure to enhance learning as uncertainty rises-two mechanisms that likely facilitate adaptive social choice.","link":"/opendata/lamba-et-al-2020/"},{"title":"Lange et al. (2021)","text":"Making good decisions requires updating beliefs according to new evidence. This is a dynamical process that is prone to biases: in some cases, beliefs become entrenched and resistant to new evidence (leading to primacy effects), while in other cases, beliefs fade over time and rely primarily on later evidence (leading to recency effects). How and why either type of bias dominates in a given context is an important open question. Here, we study this question in classic perceptual decision-making tasks, where, puzzlingly, previous empirical studies differ in the kinds of biases they observe, ranging from primacy to recency, despite seemingly equivalent tasks. We present a new model, based on hierarchical approximate inference and derived from normative principles, that not only explains both primacy and recency effects in existing studies, but also predicts how the type of bias should depend on the statistics of stimuli in a given task. We verify this prediction in a novel visual discrimination task with human observers, finding that each observers temporal bias changed as the result of changing the key stimulus statistics identified by our model. The key dynamic that leads to a primacy bias in our model is an overweighting of new sensory information that agrees with the observers existing belief-a type of confirmation bias. By fitting an extended drift-diffusion model to our data we rule out an alternative explanation for primacy effects due to bounded integration. Taken together, our results resolve a major discrepancy among existing perceptual decision-making studies, and suggest that a key source of bias in human decision-making is approximate hierarchical inference.","link":"/opendata/lange-et-al-2021/"},{"title":"Larsen et al. (2022)","text":"Hallucinations are characterized by disturbances of perceptual processes involved in decision-making about environmental stimuli. Here, we examine whether cognitive and computational processes by which sensory information is integrated may offer insight into the perceptual mechanisms of hallucinatory symptoms. We used a multi-element perceptual averaging task in which observers made dichotomous judgments about the “average color” (red or blue) of an array of stimuli in trials that varied in the strength (mean) and reliability (variance) of the decision-relevant perceptual evidence. Generally, observers excluded or down-weighted extreme (outlying) perceptual evidence akin to a statistician excluding outlying data points; however, individuals prone to hallucinations afforded more weight to more extreme or untrustworthy evidence. Computational modeling showed that individuals prone to hallucinations tended not to use the optimal model in which evidence is integrated as a function of the log odds of each perceptual option leading to “robust averaging”. Finally, observers generally adapted to trials with unreliable evidence by increasingly downweighting extreme evidence, but the weighting strategy in hallucination prone individuals remained insensitive to the reliability of evidence. By showing that hallucination proneness is associated with reduced attenuation of untrustworthy evidence in perceptual decision-making, our findings suggest a novel perceptual mechanism underlying hallucinations. Our findings also provide support for the view that hallucination-proneness relates to alterations in the perceptual systems that track statistical regularities in environmental stimuli.","link":"/opendata/larsen-et-al-2022/"},{"title":"Latzman et al. (2020)","text":"A robust literature demonstrates that psychopathology and personality pathology are well-represented within quantitatively-derived, hierarchical dimensional models. Nevertheless, the location of core traits comprising psychopathic personality (psychopathy) as defined by the triarchic model has not been clearly explicated. We extended hierarchical structural models of personality pathology to include triarchic psychopathy trait dimensions (boldness, meanness, disinhibition) to interface the hierarchical framework of pathological personality dimensions with basic psychopathy trait dimensions. Using data from a racially diverse undergraduate sample (N = 749), “bass-ackwards” analyses revealed a coherently organized hierarchical structure of personality pathology. Psychopathy dimensions were clearly situated within levels of the hierarchy extending beyond the highest, undifferentiated general-factor level. A broad externalizing factor emerged at level 2, which bifurcated into callous-disinhibition and fearless dominance subfactors at level 3 – encompassing psychopathic traits of meanness and disinhibition (thought to represent the trait commonality between antisocial personality disorder and psychopathy) and boldness (thought to differentiate psychopathy from antisocial personality disorder), respectively, at the final two levels of the hierarchy. These results position triarchic psychopathy traits within an extended externalizing spectrum that accommodates boldness-related content.","link":"/opendata/latzman-et-al-2020/"},{"title":"Lawrence et al. (2022)","text":"Theoretical accounts have linked anxiety to intolerance of ambiguity. However, this relationship has not been well operationalized empirically. Here, we used computational and neuro-imaging methods to characterize anxiety-related differences in aversive decision-making under ambiguity and associated patterns of cortical activity. Adult human participants chose between two urns on each trial. The ratio of tokens (Os and Xs) in each urn determined probability of electrical stimulation receipt. A number above each urn indicated the magnitude of stimulation that would be received if a shock was delivered. On ambiguous trials, one of the two urns had tokens occluded. By varying the number of tokens occluded, we manipulated the extent of missing information. At higher levels of missing information, there is greater second order uncertainty, i.e., more uncertainty as to the probability of pulling a given type of token from the urn. Adult human participants demonstrated avoidance of ambiguous options which increased with level of missing information. Extent of information-level dependent ambiguity aversion was significantly positively correlated with trait anxiety. Activity in both the dorsal anterior cingulate cortex and inferior frontal sulcus during the decision-making period increased as a function of missing information. Greater engagement of these regions, on high missing information trials, was observed when participants went on to select the ambiguous option; this was especially apparent in high trait anxious individuals. These findings are consistent with individuals vulnerable to anxiety requiring greater activation of frontal regions supporting rational decision-making to overcome a predisposition to engage in ambiguity avoidance at high levels of missing information.","link":"/opendata/lawrence-et-al-2022/"},{"title":"Lefebvre et al. (2017)","text":"When forming and updating beliefs about future life outcomes, people tend to consider good news and to disregard bad news. This tendency is assumed to support the optimism bias. Whether this learning bias is specific to ‘high-level’ abstract belief update or a particular expression of a more general ‘low-level’ reinforcement learning process is unknown. Here we report evidence in favour of the second hypothesis. In a simple instrumental learning task, participants incorporated better-than-expected outcomes at a higher rate than worse-than-expected ones. In addition, functional imaging indicated that inter-individual difference in the expression of optimistic update corresponds to enhanced prediction error signalling in the reward circuitry. Our results constitute a step towards the understanding of the genesis of optimism bias at the neurocomputational level.","link":"/opendata/lefebvre-et-al-2017/"},{"title":"Lehmann et al. (2019)","text":"In many daily tasks, we make multiple decisions before reaching a goal. In order to learn such sequences of decisions, a mechanism to link earlier actions to later reward is necessary. Reinforcement learning (RL) theory suggests two classes of algorithms solving this credit assignment problem: In classic temporal-difference learning, earlier actions receive reward information only after multiple repetitions of the task, whereas models with eligibility traces reinforce entire sequences of actions from a single experience (one-shot). Here, we show one-shot learning of sequences. We developed a novel paradigm to directly observe which actions and states along a multi-step sequence are reinforced after a single reward. By focusing our analysis on those states for which RL with and without eligibility trace make qualitatively distinct predictions, we find direct behavioral (choice probability) and physiological (pupil dilation) signatures of reinforcement learning with eligibility trace across multiple sensory modalities.","link":"/opendata/lehmann-et-al-2019/"},{"title":"Leng et al. (2021)","text":"To invest effort into any cognitive task, people must be sufficiently motivated. Whereas prior research has focused primarily on how the cognitive control required to complete these tasks is motivated by the potential rewards for success, it is also known that control investment can be equally motivated by the potential negative consequence for failure. Previous theoretical and experimental work has yet to examine how positive and negative incentives differentially influence the manner and intensity with which people allocate control. Here, we develop and test a normative model of control allocation under conditions of varying positive and negative performance incentives. Our model predicts, and our empirical findings confirm, that rewards for success and punishment for failure should differentially influence adjustments to the evidence accumulation rate versus response threshold, respectively. This dissociation further enabled us to infer how motivated a given person was by the consequences of success versus failure.","link":"/opendata/leng-et-al-2021/"},{"title":"Leong et al. (2021)","text":"People’s perceptual reports are biased toward percepts they are motivated to see. The arousal system coordinates the body’s response to motivationally significant events and is well positioned to regulate motivational effects on perceptual judgments. However, it remains unclear whether arousal would enhance or reduce motivational biases. Here, we measured pupil dilation as a measure of arousal while participants (N = 38) performed a visual categorization task. We used monetary bonuses to motivate participants to perceive one category over another. Even though the reward-maximizing strategy was to perform the task accurately, participants were more likely to report seeing the desirable category. Furthermore, higher arousal levels were associated with making motivationally biased responses. Analyses using computational models suggested that arousal enhanced motivational effects by biasing evidence accumulation in favor of desirable percepts. These results suggest that heightened arousal biases people toward what they want to see and away from an objective representation of the environment.","link":"/opendata/leong-et-al-2021/"},{"title":"Lewis et al. (2022)","text":"In cost-benefit decision-making, women and men often show different trade-offs. However, surprisingly little is known about sex differences in instrumental tasks, where physical effort is exerted to gain rewards. To this end, we tested 81 individuals (47 women) with an effort allocation task, where participants had to repeatedly press a button to collect food and money tokens. We analyzed the motivational phases of invigoration and effort maintenance with varying reward magnitude, difficulty, and reward type. Whereas women and men did not differ in invigoration, we found that women showed higher effort maintenance as well as higher subjective wanting and exertion ratings for small rewards compared with men. Notably, men increased their effort more than women for higher rewards to match women’s levels of performance. Crucially, we found no sex differences depending on reward type or difficulty, indicating that sex differences were specific to the encoding of the magnitude of benefits, not costs. To summarize, women exerted higher physical effort for small rewards, which corresponded with an elevated subjective value in women compared with men. Therefore, sex differences in perceived reward magnitude may contribute to differential behavioral preferences highlighting the potential of cost-benefit decision-making to provide insights about potential mechanisms.","link":"/opendata/lewis-et-al-2022/"},{"title":"Li et al. (2022)","text":"While making decisions, we often rely on past experiences to guide our choices. However, not all experiences are remembered equally well, and some elements of an experience are more memorable than others. Thus, the intrinsic memorability of past experiences may bias our decisions. Here, we hypothesized that individuals would tend to choose more memorable options than less memorable ones. We investigated the effect of item memorability on choice in two experiments. First, using food images, we found that the same items were consistently remembered, and others consistently forgotten, across participants. However, contrary to our hypothesis, we found that participants did not prefer or choose the more memorable over the less memorable items when choice options were matched for the individuals valuation of the items. Second, we replicated these findings in an alternate stimulus domain, using words that described the same food items. These findings suggest that stimulus memorability does not play a significant role in determining choice based on subjective value.","link":"/opendata/li-et-al-2022/"},{"title":"Ligneul (2019)","text":"The Iowa Gambling Task (IGT) is one of the most common paradigms used to assess decision-making and executive functioning in neurological and psychiatric disorders. Several reinforcement-learning (RL) models were recently proposed to refine the qualitative and quantitative inferences that can be made about these processes based on IGT data. Yet, these models do not account for the complex exploratory patterns which characterize participants behavior in the task. Using a dataset of more than 500 subjects, we demonstrate the existence of sequential exploration in the IGT and we describe a new computational architecture disentangling exploitation, random exploration and sequential exploration in this large population of participants. The new Value plus Sequential Exploration (VSE) architecture provided a better fit than previous models. Parameter recovery, model recovery and simulation analyses confirmed the superiority of the VSE scheme. Furthermore, using the VSE model, we confirmed the existence of a significant reduction in directed exploration across lifespan in the IGT, as previously reported with other paradigms. Finally, we provide a user-friendly toolbox enabling researchers to easily and flexibly fit computational models on the IGT data, hence promoting reanalysis of the numerous datasets acquired in various populations of patients and contributing to the development of computational psychiatry.","link":"/opendata/ligneul-2019/"},{"title":"Ligneul et al. (2022)","text":"Estimating the controllability of the environment enables agents to better predict upcoming events and decide when to engage controlled action selection. How does the human brain estimate controllability? Trial-by-trial analysis of choices, decision times and neural activity in an explore-and-predict task demonstrate that humans solve this problem by comparing the predictions of an actor model with those of a reduced spectator model of their environment. Neural blood oxygen level-dependent responses within striatal and medial prefrontal areas tracked the instantaneous difference in the prediction errors generated by these two statistical learning models. Blood oxygen level-dependent activity in the posterior cingulate, temporoparietal and prefrontal cortices covaried with changes in estimated controllability. Exposure to inescapable stressors biased controllability estimates downward and increased reliance on the spectator model in an anxiety-dependent fashion. Taken together, these findings provide a mechanistic account of controllability inference and its distortion by stress exposure.","link":"/opendata/ligneul-et-al-2022/"},{"title":"Lin et al. (2020)","text":"Neutral stimuli can acquire value when people learn to associate them with positive or negative outcomes (i.e., gain versus loss associations). Acquired value has been shown to affect how gain and loss associated stimuli are attended, remembered, and acted upon. Here we investigate a potential and previously unreported learning asymmetry in the acquisition of gain and loss associations that may have consequences for subsequent cognitive processing. In our first study, we provide meta-analytic evidence that in probabilistic learning tasks that pair neutral stimuli with intermixed win, loss, and no-change outcomes, people learn win-associations better than loss-associations despite the symmetrical task structure and symmetrical outcome probabilities. Then in two empirical studies, we demonstrate that this learning asymmetry is evident when acquiring gain versus loss associations to gray-scale landscape images whether participants earn points or money (Study 2), and whether or not they receive explicit instructions about the outcome contingencies (Study 3). Furthermore, performance on a post-learning source recognition task was also asymmetrical: explicit knowledge of associated outcomes was superior for optimal gain than optimal loss scenes. These findings indicate the acquisition of gain and loss associations need not be equivalent, despite symmetrical outcome probabilities, equivalent numbers of learning trials, and a constant learning criterion. Consequently, learning asymmetries could contribute to valence and optimality differences in subsequent cognitive processing.","link":"/opendata/lin-et-al-2020/"},{"title":"Lin et al. (2022)","text":"People who take on challenges and persevere longer are more likely to succeed in life. But individuals often avoid exerting effort, and there is limited experimental research investigating whether we can learn to value effort. Because existing research focuses on enhancing cognitive performance rather than increasing the value of effort, it also remains unclear whether individuals can learn to care more about challenging themselves than performing well. We developed a paradigm to test an intuitive idea: that people can learn to value effort and will seek effortful challenges if directly incentivized to do so. What’s more, we dissociate the effects of rewarding people for choosing effortful challenges and performing well. Results revealed that rewarding effort increased people’s willingness to choose harder tasks, even when rewards were no longer offered (near-transfer). Critically, the effects of this brief manipulation also carried over to an unrelated and unrewarded task (far-transfer). Our results suggest people can learn to value effort and that this valuation can generalise to unfamiliar and unrewarded tasks.","link":"/opendata/lin-et-al-2022/"},{"title":"Lockwood et al. (2021)","text":"Social cohesion relies on prosociality in increasingly aging populations. Helping other people requires effort, yet how willing people are to exert effort to benefit themselves and others, and whether such behaviors shift across the life span, is poorly understood. Using computational modeling, we tested the willingness of 95 younger adults (18-36 years old) and 92 older adults (55-84 years old) to put physical effort into self- and other-benefiting acts. Participants chose whether to work and exert force (30%-70% of maximum grip strength) for rewards (2-10 credits) accrued for themselves or, prosocially, for another. Younger adults were somewhat selfish, choosing to work more at higher effort levels for themselves, and exerted less force in prosocial work. Strikingly, compared with younger adults, older people were more willing to put in effort for others and exerted equal force for themselves and others. Increased prosociality in older people has important implications for human behavior and societal structure.","link":"/opendata/lockwood-et-al-2021/"},{"title":"Lojowska et al. (2023)","text":"Humans are exposed to environmental and economic threats that can profoundly affect individual survival and group functioning. Although anecdotal evidence suggests that threat exposure can increase collective action, the effects of threat on decision-making have been mainly investigated at the individual level. Here we examine how threat exposure and concomitant physiological responses modulate cooperation in small groups. Individuals (N = 105, ages 18-34 years) in groups of three were exposed to threat of electric shocks while deciding how much to contribute to a public good. Threat of shock induced a state of physiological freezing and, compared with no-threat conditions, reduced free riding and enabled groups to maintain higher cooperation over time. Exploratory analyses revealed that more cooperative responses under threat were driven by stronger baseline prosociality, suggesting that habitual prosociality is reinforced under threat. The current results support the view that human groups respond to outside threat with increased cooperation.","link":"/opendata/lojowska-et-al-2023/"},{"title":"MacDonald et al. (2016)","text":"Childhood maltreatment has diverse, lifelong impact on morbidity and mortality. The Childhood Trauma Questionnaire (CTQ) is one of the most commonly used scales to assess and quantify these experiences and their impact. Curiously, despite very widespread use of the CTQ, scores on its Minimization-Denial (MD) subscale-originally designed to assess a positive response bias-are rarely reported. Hence, little is known about this measure. If response biases are either common or consequential, current practices of ignoring the MD scale deserve revision. Therewith, we designed a study to investigate 3 aspects of minimization, as defined by the CTQs MD scale: 1) its prevalence; 2) its latent structure; and finally 3) whether minimization moderates the CTQs discriminative validity in terms of distinguishing between psychiatric patients and community volunteers. Archival, item-level CTQ data from 24 multinational samples were combined for a total of 19,652 participants. Analyses indicated: 1) minimization is common; 2) minimization functions as a continuous construct; and 3) high MD scores attenuate the ability of the CTQ to distinguish between psychiatric patients and community volunteers. Overall, results suggest that a minimizing response bias-as detected by the MD subscale-has a small but significant moderating effect on the CTQs discriminative validity. Results also may suggest that some prior analyses of maltreatment rates or the effects of early maltreatment that have used the CTQ may have underestimated its incidence and impact. We caution researchers and clinicians about the widespread practice of using the CTQ without the MD or collecting MD data but failing to assess and control for its effects on outcomes or dependent variables.","link":"/opendata/macdonald-et-al-2016/"},{"title":"Madan et al. (2021)","text":"Both memory and choice are influenced by context: Memory is enhanced when encoding and retrieval contexts match, and choice is swayed by available options. Here, we assessed how context influences risky choice in an experience-based task in two main experiments (119 and 98 participants retained, respectively) and two additional experiments reported in the Supplemental Material available online (152 and 106 participants retained, respectively). Within a single session, we created two separate contexts by presenting blocks of trials in distinct backgrounds. Risky choices were context dependent; given the same choice, people chose differently depending on other outcomes experienced in that context. Choices reflected an overweighting of the most extreme outcomes within each local context rather than the global context of all outcomes. When tested in the nontrained context, people chose according to the context at encoding and not retrieval. In subsequent memory tests, people displayed biases specific to distinct contexts: Extreme outcomes from each context were more accessible and judged as more frequent. These results pose a challenge for theories of choice that rely on retrieval as guiding choice.","link":"/opendata/madan-et-al-2021/"},{"title":"Makarov et al. (2023)","text":"Can synchrony in stimulation guide attention and aid perceptual performance? Here, in a series of three experiments, we tested the influence of visual and auditory synchrony on attentional selection during a visual foraging task. Experiment 1 was performed online, where the task was to forage for 10 (out of 20) vertical lines among 60 randomly oriented distractor lines that changed color between yellow and blue at random intervals. The targets either changed colors in visual synchrony or not. In another condition, a non-spatial sound additionally occurred synchronously with the color change of the targets. Experiment 2 was run in the laboratory (within-subjects) with the same design. When the targets changed color in visual synchrony, foraging times were significantly shorter than when they randomly changed colors, but there was no additional benefit for the sound synchrony. In Experiment 3, task difficulty was increased as participants foraged for as many 45° rotated lines as possible among lines of different orientations within 10 seconds, with the same synchrony conditions as in Experiments 1 and 2. Again, there was a large benefit of visual synchrony but no additional benefit for sound synchronization. Our results provide strong evidence that visual synchronization can guide attention during multiple target foraging. This likely reflects temporal grouping of the synchronized targets. No additional benefit occurred for sound synchrony, even when the foraging task was quite difficult (Experiment 3).","link":"/opendata/makarov-et-al-2023/"},{"title":"Marchant et al. (2023)","text":"Humans excel at causal reasoning, yet at the same time consistently fail to respect its basic axioms. They seemingly fail to recognize, for instance, that only the direct causes of an event can affect its probability (the Markov condition). How can one explain this paradox? Here we argue that standard normative analyses of causal reasoning mostly apply to the idealized case where the reasoner has perfect confidence in her knowledge of the underlying causal model. Given uncertainty about the correct representation of a causal system, it is not always rational for a reasoner to respect the Markov condition and other ‘normative’ principles. To test whether uncertainty can account for the apparent fallibility of human judgments, we formulate a simple computational model of a rational-but-uncertain causal reasoner. In a re-analysis of a recent causal reasoning study, the model fits the data significantly better than its standard normative counterpart.","link":"/opendata/marchant-et-al-2023/"},{"title":"Marton et al. (2019)","text":"Doubt is subjective uncertainty about ones perceptions and recall. It can impair decision-making and is a prominent feature of obsessive-compulsive disorder (OCD). We propose that evaluation of doubt during decision-making provides a useful endophenotype with which to study the underlying pathophysiology of OCD and potentially other psychopathologies. For the current study, we developed a new instrument, the Doubt Questionnaire, to clinically assess doubt. The random dot motion task was used to measure reaction time and subjective certainty, at varying levels of perceptual difficulty, in individuals who scored high and low on doubt, and in individuals with and without OCD. We found that doubt scores were significantly higher in OCD cases than controls. Drift diffusion modeling revealed that high doubt scores predicted slower evidence accumulation than did low doubt scores; and OCD diagnosis lower than controls. At higher levels of dot coherence, OCD participants exhibited significantly slower drift rates than did controls (q&lt;0.05 for 30%, and 45% coherence; q&lt;0.01 for 70% coherence). In addition, at higher levels of coherence, high doubt subjects exhibited even slower drift rates and reaction times than low doubt subjects (q&lt;0.01 for 70% coherence). Moreover, under high coherence conditions, individuals with high doubt scores reported lower certainty in their decisions than did those with low doubt scores. We conclude that the Doubt Questionnaire is a useful instrument for measuring doubt. Compared to those with low doubt, those with high doubt accumulate evidence more slowly and report lower certainty when making decisions under conditions of low uncertainty. High doubt may affect the decision-making process in individuals with OCD. The dimensional doubt measure is a useful endophenotype for OCD research and could enable computationally rigorous and neurally valid understanding of decision-making and its pathological expression in OCD and other disorders.","link":"/opendata/marton-et-al-2019/"},{"title":"Mason et al. (2022)","text":"Decision-making involves weighing up the outcome likelihood, potential rewards, and effort needed. Previous research has focused on the trade-offs between risk and reward or between effort and reward. Here we bridge this gap and examine how risk in effort levels influences choice. With outcome uncertainty, people’s risk attitudes follow a fourfold pattern, varying with the domain (gains or losses) and probability (rare or common). Three experiments assessed people’s risk attitudes for money, physical effort, and mental effort. With monetary gambles, risk attitudes followed the classic fourfold pattern, and people were risk averse for increases in money (gains). With both physical and mental effort, however, people exhibited a “flipped” fourfold pattern of risk preferences and were instead risk seeking for increases in effort. Overall, these findings indicate that people treat effort as a loss of resources and are more willing to take risks to avoid potentially high levels of effort.","link":"/opendata/mason-et-al-2022/"},{"title":"McDonald et al. (2019)","text":"Previous studies of strategic social interaction in game theory have predominantly used games with clearly-defined turns and limited choices. Yet, most real-world social behaviors involve dynamic, coevolving decisions by interacting agents, which poses challenges for creating tractable models of behavior. Here, using a game in which humans competed against both real and artificial opponents, we show that it is possible to quantify the instantaneous dynamic coupling between agents. Adopting a reinforcement learning approach, we use Gaussian Processes to model the policy and value functions of participants as a function of both game state and opponent identity. We found that higher-scoring participants timed their final change in direction to moments when the opponents counter-strategy was weaker, while lower-scoring participants less precisely timed their final moves. This approach offers a natural set of metrics for facilitating analysis at multiple timescales and suggests new classes of experimental paradigms for assessing behavior.","link":"/opendata/mcdonald-et-al-2019/"},{"title":"McDougle et al. (2019)","text":"Decisions must be implemented through actions, and actions are prone to error. As such, when an expected outcome is not obtained, an individual should be sensitive to not only whether the choice itself was suboptimal but also whether the action required to indicate that choice was executed successfully. The intelligent assignment of credit to action execution versus action selection has clear ecological utility for the learner. To explore this, we used a modified version of a classic reinforcement learning task in which feedback indicated whether negative prediction errors were, or were not, associated with execution errors. Using fMRI, we asked if prediction error computations in the human striatum, a key substrate in reinforcement learning and decision making, are modulated when a failure in action execution results in the negative outcome. Participants were more tolerant of non-rewarded outcomes when these resulted from execution errors versus when execution was successful, but reward was withheld. Consistent with this behavior, a model-driven analysis of neural activity revealed an attenuation of the signal associated with negative reward prediction errors in the striatum following execution failures. These results converge with other lines of evidence suggesting that prediction errors in the mesostriatal dopamine system integrate high-level information during the evaluation of instantaneous reward outcomes.","link":"/opendata/mcdougle-et-al-2019/"},{"title":"Mennella et al. (2022)","text":"Adaptation to our social environment requires learning how to avoid potentially harmful situations, such as encounters with aggressive individuals. Threatening facial expressions can evoke automatic stimulus-driven reactions, but whether their aversive motivational value suffices to drive instrumental active avoidance remains unclear. When asked to freely choose between different action alternatives, participants spontaneously-without instruction or monetary reward-developed a preference for choices that maximized the probability of avoiding angry individuals (sitting away from them in a waiting room). Most participants showed clear behavioral signs of instrumental learning, even in the absence of an explicit avoidance strategy. Inter-individual variability in learning depended on participants subjective evaluations and sensitivity to threat approach feedback. Counterfactual learning best accounted for avoidance behaviors, especially in participants who developed an explicit avoidance strategy. Our results demonstrate that implicit defensive behaviors in social contexts are likely the product of several learning processes, including instrumental learning.","link":"/opendata/mennella-et-al-2022/"},{"title":"Michely et al. (2022)","text":"Instrumental learning is driven by a history of outcome success and failure. Here, we examined the impact of serotonin on learning from positive and negative outcomes. Healthy human volunteers were assessed twice, once after acute (single-dose), and once after prolonged (week-long) daily administration of the SSRI citalopram or placebo. Using computational modelling, we show that prolonged boosting of serotonin enhances learning from punishment and reduces learning from reward. This valence-dependent learning asymmetry increases subjects tendency to avoid actions as a function of cumulative failure without leading to detrimental, or advantageous, outcomes. By contrast, no significant modulation of learning was observed following acute SSRI administration. However, differences between the effects of acute and prolonged administration were not significant. Overall, these findings may help explain how serotonergic agents impact on mood disorders.","link":"/opendata/michely-et-al-2022/"},{"title":"Mikus et al. (2022)","text":"Human behaviour requires flexible arbitration between actions we do out of habit and actions that are directed towards a specific goal. Drugs that target opioid and dopamine receptors are notorious for inducing maladaptive habitual drug consumption; yet, how the opioidergic and dopaminergic neurotransmitter systems contribute to the arbitration between habitual and goal-directed behaviour is poorly understood. By combining pharmacological challenges with a well-established decision-making task and a novel computational model, we show that the administration of the dopamine D2/3 receptor antagonist amisulpride led to an increase in goal-directed or model-based relative to habitual or model-free behaviour, whereas the non-selective opioid receptor antagonist naltrexone had no appreciable effect. The effect of amisulpride on model-based/model-free behaviour did not scale with drug serum levels in the blood. Furthermore, participants with higher amisulpride serum levels showed higher explorative behaviour. These findings highlight the distinct functional contributions of dopamine and opioid receptors to goal-directed and habitual behaviour and support the notion that even small doses of amisulpride promote flexible application of cognitive control.","link":"/opendata/mikus-et-al-2022/"},{"title":"Millner et al. (2018)","text":"To survive in complex environments, animals need to have mechanisms to select effective actions quickly, with minimal computational costs. As perhaps the computationally most parsimonious of these systems, Pavlovian control accomplishes this by hardwiring specific stereotyped responses to certain classes of stimuli. It is well documented that appetitive cues initiate a Pavlovian bias toward vigorous approach; however, Pavlovian responses to aversive stimuli are less well understood. Gaining a deeper understanding of aversive Pavlovian responses, such as active avoidance, is important given the critical role these behaviors play in several psychiatric conditions. The goal of the current study was to establish a behavioral and computational framework to examine aversive Pavlovian responses (activation vs. inhibition) depending on the proximity of an aversive state (escape vs. avoidance). We introduce a novel task in which participants are exposed to primary aversive (noise) stimuli and characterized behavior using a novel generative computational model. This model combines reinforcement learning and drift-diffusion models so as to capture effects of invigoration/inhibition in both explicit choice behavior as well as changes in RT. Choice and RT results both suggest that escape is associated with a bias for vigorous action, whereas avoidance is associated with behavioral inhibition. These results lay a foundation for future work seeking insights into typical and atypical aversive Pavlovian responses involved in psychiatric disorders, allowing us to quantify both implicit and explicit indices of vigorous choice behavior in the context of aversion.","link":"/opendata/millner-et-al-2018/"},{"title":"Mkrtchian et al. (2017)","text":"Serious and debilitating symptoms of anxiety are the most common mental health problem worldwide, accounting for around 5% of all adult years lived with disability in the developed world. Avoidance behavior-avoiding social situations for fear of embarrassment, for instance-is a core feature of such anxiety. However, as for many other psychiatric symptoms the biological mechanisms underlying avoidance remain unclear. Reinforcement learning models provide formal and testable characterizations of the mechanisms of decision making; here, we examine avoidance in these terms. A total of 101 healthy participants and individuals with mood and anxiety disorders completed an approach-avoidance go/no-go task under stress induced by threat of unpredictable shock. We show an increased reliance in the mood and anxiety group on a parameter of our reinforcement learning model that characterizes a prepotent (pavlovian) bias to withhold responding in the face of negative outcomes. This was particularly the case when the mood and anxiety group was under stress. This formal description of avoidance within the reinforcement learning framework provides a new means of linking clinical symptoms with biophysically plausible models of neural circuitry and, as such, takes us closer to a mechanistic understanding of mood and anxiety disorders.","link":"/opendata/mkrtchian-et-al-2017/"},{"title":"Mkrtchian et al. (2023)","text":"Computational models can offer mechanistic insight into cognition and therefore have the potential to transform our understanding of psychiatric disorders and their treatment. For translational efforts to be successful, it is imperative that computational measures capture individual characteristics reliably. To date, this issue has received little consideration. Here we examine the reliability of reinforcement learning and economic models derived from two commonly used tasks. Healthy individuals (N=50) completed a restless four-armed bandit and a calibrated gambling task twice, two weeks apart. Reward and punishment processing parameters from the reinforcement learning model showed fair-to-good reliability, while risk/loss aversion parameters from a prospect theory model exhibited good-to-excellent reliability. Both models were further able to predict future behaviour above chance within individuals. This prediction was better when based on participants’ own model parameters than other participants’ parameter estimates. These results suggest that reinforcement learning, and particularly prospect theory parameters, can be measured reliably to assess learning and decision-making mechanisms, and that these processes may represent relatively distinct computational profiles across individuals. Overall, these findings indicate the translational potential of clinically-relevant computational parameters for precision psychiatry.","link":"/opendata/mkrtchian-et-al-2023/"},{"title":"Moeller et al. (2021)","text":"Reward prediction errors (RPEs) and risk preferences have two things in common: both can shape decision making behavior, and both are commonly associated with dopamine. RPEs drive value learning and are thought to be represented in the phasic release of striatal dopamine. Risk preferences bias choices towards or away from uncertainty; they can be manipulated with drugs that target the dopaminergic system. Based on the common neural substrate, we hypothesize that RPEs and risk preferences are linked on the level of behavior as well. Here, we develop this hypothesis theoretically and test it empirically. First, we apply a recent theory of learning in the basal ganglia to predict how RPEs influence risk preferences. We find that positive RPEs should cause increased risk-seeking, while negative RPEs should cause risk-aversion. We then test our behavioral predictions using a novel bandit task in which value and risk vary independently across options. Critically, conditions are included where options vary in risk but are matched for value. We find that our prediction was correct: participants become more risk-seeking if choices are preceded by positive RPEs, and more risk-averse if choices are preceded by negative RPEs. These findings cannot be explained by other known effects, such as nonlinear utility curves or dynamic learning rates.","link":"/opendata/moeller-et-al-2021/"},{"title":"Moran et al. (2019)","text":"An extensive reinforcement learning literature shows that organisms assign credit efficiently, even under conditions of state uncertainty. However, little is known about credit-assignment when state uncertainty is subsequently resolved. Here, we address this problem within the framework of an interaction between model-free (MF) and model-based (MB) control systems. We present and support experimentally a theory of MB retrospective-inference. Within this framework, a MB system resolves uncertainty that prevailed when actions were taken thus guiding an MF credit-assignment. Using a task in which there was initial uncertainty about the lotteries that were chosen, we found that when participants momentary uncertainty about which lottery had generated an outcome was resolved by provision of subsequent information, participants preferentially assigned credit within a MF system to the lottery they retrospectively inferred was responsible for this outcome. These findings extend our knowledge about the range of MB functions and the scope of system interactions.","link":"/opendata/moran-et-al-2019/"},{"title":"Morris et al. (2021)","text":"Humans have a remarkable capacity for flexible decision-making, deliberating among actions by modeling their likely outcomes. This capacity allows us to adapt to the specific features of diverse circumstances. In real-world decision-making, however, people face an important challenge: There are often an enormous number of possibilities to choose among, far too many for exhaustive consideration. There is a crucial, understudied prechoice step in which, among myriad possibilities, a few good candidates come quickly to mind. How do people accomplish this? We show across nine experiments (N = 3,972 U.S. residents) that people use computationally frugal cached value estimates to propose a few candidate actions on the basis of their success in past contexts (even when irrelevant for the current context). Deliberative planning is then deployed just within this set, allowing people to compute more accurate values on the basis of context-specific criteria. This hybrid architecture illuminates how typically valuable thoughts come quickly to mind during decision-making.","link":"/opendata/morris-et-al-2021/"},{"title":"Moutoussis et al. (2018)","text":"Pavlovian influences are important in guiding decision-making across health and psychopathology. There is an increasing interest in using concise computational tasks to parametrise such influences in large populations, and especially to track their evolution during development and changes in mental health. However, the developmental course of Pavlovian influences is uncertain, a problem compounded by the unclear psychometric properties of the relevant measurements. We assessed Pavlovian influences in a longitudinal sample using a well characterised and widely used Go-NoGo task. We hypothesized that the strength of Pavlovian influences and other psychomarkers guiding decision-making would behave like traits. As reliance on Pavlovian influence is not as profitable as precise instrumental decision-making in this Go-NoGo task, we expected this influence to decrease with higher IQ and age. Additionally, we hypothesized it would correlate with expressions of psychopathology. We found that Pavlovian effects had weak temporal stability, while model-fit was more stable. In terms of external validity, Pavlovian effects decreased with increasing IQ and experience within the task, in line with normative expectations. However, Pavlovian effects were poorly correlated with age or psychopathology. Thus, although this computational construct did correlate with important aspects of development, it does not meet conventional requirements for tracking individual development. We suggest measures that might improve psychometric properties of task-derived Pavlovian measures for future studies.","link":"/opendata/moutoussis-et-al-2018/"},{"title":"Mueller et al. (2019)","text":"In classical fear conditioning, neutral conditioned stimuli that have been paired with aversive physical unconditioned stimuli eventually trigger fear responses. Here, we tested whether aversive mental images systematically paired with a conditioned stimulus also cause de novo fear learning in the absence of any external aversive stimulation. In two experiments (N = 45 and N = 41), participants were first trained to produce aversive, neutral, or no imagery in response to three different visual-imagery cues. In a subsequent imagery-based differential-conditioning paradigm, each of the three cues systematically co-terminated with one of three different neutral faces. Although the face that was paired with the aversive-imagery cue was never paired with aversive external stimuli or threat-related instructions, participants rated it as more arousing, unpleasant, and threatening and displayed relative fear bradycardia and fear-potentiated startle. These results could be relevant for the development of fear and related disorders without trauma.","link":"/opendata/mueller-et-al-2019/"},{"title":"Müller et al. (2022)","text":"Research suggests that the temporal order in which people receive information about costs and benefits whilst making decisions can influence their choices. But, do people have a preference for seeking information about costs or benefits when making effort-based decisions, and does this impact motivation? Here, participants made choices about whether to exert different levels of physical effort to obtain different magnitudes of reward, or rest for low reward. Prior to each effort-based choice, they also had to decide which information they wanted to see first: how much physical effort would be required, or how large the reward would be. We found no overall preference for seeking reward or effort information first, but motivation did change when people saw reward or effort information first. Seeking effort information first, both someones average tendency to do so and their choice to see effort first on a given trial, was associated with reductions in the willingness to exert higher effort. Moreover, the tendency to prefer effort information first was associated with reduced vigorous exercise and higher levels of fatigue in everyday life. These findings highlight that preferences for seeking effort information may be a bias that reduces peoples willingness to exert effort in the lab and in everyday life.","link":"/opendata/muller-et-al-2022/"},{"title":"Naefgen et al. (2022)","text":"We expand the usually cross-sectional perspective on dual-tasking performance toinclude both intra- and interpersonal variability, which should capture within-persondynamics and psychological processes better. Two simple tasks, first as single-, then as dualtasks, were performed by 58 participants over 20 session. We found positive relationships between (1) single- and dual-tasking performance and (2) the dual-task component tasks both inter- and intrapersonally. Better single-taskers were better dual-taskers and better singletasking sessions were better dual-tasking sessions. This implies shared capacities that covary both inter- and intraindividually. We conclude that taking intra- and interpersonal variability into account is a promising future perspective.","link":"/opendata/naefgen-et-al-2022/"},{"title":"Najar et al. (2020)","text":"While there is no doubt that social signals affect human reinforcement learning, there is still no consensus about how this process is computationally implemented. To address this issue, we compared three psychologically plausible hypotheses about the algorithmic implementation of imitation in reinforcement learning. The first hypothesis, decision biasing (DB), postulates that imitation consists in transiently biasing the learners action selection without affecting their value function. According to the second hypothesis, model-based imitation (MB), the learner infers the demonstrators value function through inverse reinforcement learning and uses it to bias action selection. Finally, according to the third hypothesis, value shaping (VS), the demonstrators actions directly affect the learners value function. We tested these three hypotheses in 2 experiments (N = 24 and N = 44) featuring a new variant of a social reinforcement learning task. We show through model comparison and model simulation that VS provides the best explanation of learners behavior. Results replicated in a third independent experiment featuring a larger cohort and a different design (N = 302). In our experiments, we also manipulated the quality of the demonstrators choices and found that learners were able to adapt their imitation rate, so that only skilled demonstrators were imitated. We proposed and tested an efficient meta-learning process to account for this effect, where imitation is regulated by the agreement between the learner and the demonstrator. In sum, our findings provide new insights and perspectives on the computational mechanisms underlying adaptive imitation in human reinforcement learning.","link":"/opendata/najar-et-al-2020/"},{"title":"Navarro et al. (2018)","text":"In everyday life, people need to make choices without full information about the environment, which poses an explore-exploit dilemma in which one must balance the need to learn about the world and the need to obtain rewards from it. The explore-exploit dilemma is often studied using the multi-armed restless bandit task, in which people repeatedly select from multiple options, and human behaviour is modelled as a form of reinforcement learning via Kalman filters. Inspired by work in the judgment and decision-making literature, we present two experiments using multi-armed bandit tasks in both static and dynamic environments, in situations where options can become unviable and vanish if they are not pursued. A Kalman filter model using Thompson sampling provides an excellent account of human learning in a standard restless bandit task, but there are systematic departures in the vanishing bandit task. We explore the nature of this loss aversion signal and consider theoretical explanations for the results.","link":"/opendata/navarro-et-al-2018/"},{"title":"Nicholas et al. (2022)","text":"A key question in decision-making is how humans arbitrate between competing learning and memory systems to maximize reward. We address this question by probing the balance between the effects, on choice, of incremental trial-and-error learning versus episodic memories of individual events. Although a rich literature has studied incremental learning in isolation, the role of episodic memory in decision-making has only recently drawn focus, and little research disentangles their separate contributions. We hypothesized that the brain arbitrates rationally between these two systems, relying on each in circumstances to which it is most suited, as indicated by uncertainty. We tested this hypothesis by directly contrasting contributions of episodic and incremental influence to decisions, while manipulating the relative uncertainty of incremental learning using a well-established manipulation of reward volatility. Across two large, independent samples of young adults, participants traded these influences off rationally, depending more on episodic information when incremental summaries were more uncertain. These results support the proposal that the brain optimizes the balance between different forms of learning and memory according to their relative uncertainties and elucidate the circumstances under which episodic memory informs decisions.","link":"/opendata/nicholas-et-al-2022/"},{"title":"Nitsch et al. (2022)","text":"A contemporary research agenda in behavioral economics and neuroeconomics aims to identify individual differences and (neuro)psychological correlates of rationality. This research has been widely received in important interdisciplinary and field outlets. However, the psychometric reliability of such measurements of rationality has been presumed without enough methodological scrutiny. Drawing from multiple original and published datasets (in total over 1,600 participants), we unequivocally show that contemporary measurements of rationality have moderate to poor reliability according to common standards. Further analyses of the variance components, as well as a allowing participants to revise previous choices, suggest that this is driven by low between-subject variance rather than high measurement error. As has been argued previously for other behavioral measurements, this poses a challenge to the predominant correlational research designs and the search for sociodemographic or neural predictors. While our results draw a sobering picture of the prospects of contemporary measurements of rationality, they are not necessarily surprising from a theoretical perspective, which we outline in our discussion.","link":"/opendata/nitsch-et-al-2022/"},{"title":"Niv et al. (2012)","text":"Humans and animals are exquisitely, though idiosyncratically, sensitive to risk or variance in the outcomes of their actions. Economic, psychological, and neural aspects of this are well studied when information about risk is provided explicitly. However, we must normally learn about outcomes from experience, through trial and error. Traditional models of such reinforcement learning focus on learning about the mean reward value of cues and ignore higher order moments such as variance. We used fMRI to test whether the neural correlates of human reinforcement learning are sensitive to experienced risk. Our analysis focused on anatomically delineated regions of a priori interest in the nucleus accumbens, where blood oxygenation level-dependent (BOLD) signals have been suggested as correlating with quantities derived from reinforcement learning. We first provide unbiased evidence that the raw BOLD signal in these regions corresponds closely to a reward prediction error. We then derive from this signal the learned values of cues that predict rewards of equal mean but different variance and show that these values are indeed modulated by experienced risk. Moreover, a close neurometric-psychometric coupling exists between the fluctuations of the experience-based evaluations of risky options that we measured neurally and the fluctuations in behavioral risk aversion. This suggests that risk sensitivity is integral to human learning, illuminating economic models of choice, neuroscientific models of affective learning, and the workings of the underlying neural mechanisms.","link":"/opendata/niv-et-al-2012/"},{"title":"NSPN Consortium (2022)","text":"Data from the NSPN study, a dataset of N=2400 adolescents and young adults (ages 14-24) who completed many self-report, cognitive, and reinforcement learning measures.","link":"/opendata/nspn-consortium-2022/"},{"title":"Nussenbaum et al. (2020)","text":"For years, adult psychological research has benefitted from web-based data collection. There is growing interest in harnessing this approach to facilitate data collection from children and adolescents to address foundational questions about cognitive development. To date, however, few studies have directly tested whether findings from in-lab developmental psychology tasks can be replicated online, particularly in the domain of value-based learning and decision-making. To address this question, we set up a pipeline for online data collection with children, adolescents, and adults, and conducted a replication of Decker et al. (2016). The original in-lab study employed a sequential decision-making paradigm to examine shifts in value-learning strategies from childhood to adulthood. Here, we used the same paradigm in a sample of 151 children (N = 50; ages 8 - 12 years), adolescents (N = 50; ages 13 - 17 years), and adults (N = 51; ages 18 - 25 years) and replicated the main finding that the use of a “model-based” learning strategy increases with age. In addition, we adapted a new index of abstract reasoning (MaRs-IB; Chierchia et al. 2019) for use online, and replicated a key result from Potter et al. (2017), which found that abstract reasoning ability mediated the relation between age and model-based learning. Our re-analyses of two previous in-lab datasets alongside our analysis of our online dataset revealed few qualitative differences across task administrations. These findings suggest that with appropriate precautions, researchers can effectively examine developmental differences in learning computations through unmoderated, online experiments.","link":"/opendata/nussenbaum-et-al-2020/"},{"title":"O'Connell et al. (2202)","text":"Empathic experiences shape social behaviors and display considerable individual variation. Recent advances in computational behavioral modeling can help rigorously quantify individual differences, but remain understudied in the context of empathy and antisocial behavior. We adapted a go/no-go reinforcement learning task across social and non-social contexts such that monetary gains and losses explicitly impacted the subject, a study partner, or no one. Empathy was operationalized as sensitivity to others’ rewards, sensitivity to others’ losses, and as the Pavlovian influence of empathic outcomes on approach and avoidance behavior. Results showed that 61 subjects learned for a partner in a way that was computationally similar to how they learned for themselves. Results supported the psychometric value of individualized model parameters such as sensitivity to others’ loss, which was inversely associated with antisociality. Modeled empathic sensitivity also mapped onto motivation ratings, but was not associated with self-reported trait empathy. This work is the first to apply a social reinforcement learning task that spans affect and action requirement (go/no-go) to measure multiple facets of empathic sensitivity.","link":"/opendata/o-connell-et-al-2202/"},{"title":"Oguchi et al. (2023)","text":"Humans form complex societies in which we routinely engage in social decision-making regarding the allocation of resources among ourselves and others. One dimension that characterizes social decision-making in particular is whether to prioritize self-interest or respect for others-proself or prosocial. What causes this individual difference in social value orientation? Recent developments in the social dual-process theory argue that social decision-making is characterized by its underlying domain-general learning systems: the model-free and model-based systems. In line with this learning approach, we propose and experimentally test the hypothesis that differences in social preferences stem from which learning system is dominant in an individual. Here, we used a non-social state transition task that allowed us to assess the balance between model-free/model-based learning and investigate its relation to the social value orientations. The results showed that proselfs depended more on model-based learning, whereas prosocials depended more on model-free learning. Reward amount and reaction time analyses showed that proselfs learned the task structure earlier in the session than prosocials, reflecting their difference in model-based/model-free learning dependence. These findings support the learning hypothesis on what makes differences in social preferences and have implications for understanding the mechanisms of prosocial behavior.","link":"/opendata/oguchi-et-al-2023/"},{"title":"Olschewski et al. (2019)","text":"The perception and integration of sequential numerical information is a common cognitive task. It is a prerequisite for experience-based economic choices, but it is usually not part of economic decision theory. To better understand the process of symbolic number integration and its influence on economic behavior, we performed three experimental studies that examined mean estimates and economic valuations of continuous number distributions. The results indicate that participants valued random number distributions below their respective arithmetic means and valued distributions as lower when their variance increased, indicating risk aversion. A similar though less pronounced pattern also occurred in the matched mean estimation task where accuracy was incentivized and preferences played no role. These patterns suggest that seemingly risk-averse preferences are partly due to cognitive biases when perceiving and estimating numbers. In addition, participants apparent economic preference for right-skewed outcome distributions could be attributed mainly to estimation biases. We discuss the extent to which the results can be explained based on a compressed mental number line and different sample weighting models. Finally, a new model that can account for the qualitative data pattern and has stronger overweighting of lower than higher numbers as its core feature is developed. Together, our results indicate that basic cognitive processes in perceiving and integrating number sequences play a key role in understanding experience-based economic behavior.","link":"/opendata/olschewski-et-al-2019/"},{"title":"Pachur et al. (2017)","text":"We separate for the first time the roles of cognitive and motivational factors in shaping age differences in decision making under risk. Younger and older adults completed gain, loss, and mixed-domain choice problems as well as measures of cognitive functioning and affect. The older adults decision quality was lower than the younger adults in the loss domain, and this age difference was attributable to the older adults lower cognitive abilities. In addition, the older adults chose the more risky option more often than the younger adults in the gain and mixed domains; this difference in risk aversion was attributable to less pronounced negative affect among the older adults. Computational modeling with a hierarchical Bayesian implementation of cumulative prospect theory revealed that the older adults had higher response noise and more optimistic decision weights for gains than did the younger adults. Moreover, the older adults showed no loss aversion, a finding that supports a positivity-focus (rather than a loss-prevention) view of motivational reorientation in older age.","link":"/opendata/pachur-et-al-2017/"},{"title":"Pachur et al. (2018)","text":"There is a disconnect in the literature between analyses of risky choice based on cumulative prospect theory (CPT) and work on predecisional information processing. One likely reason is that for expectation models (e.g., CPT), it is often assumed that people behaved only as if they conducted the computations leading to the predicted choice and that the models are thus mute regarding information processing. We suggest that key psychological constructs in CPT, such as loss aversion and outcome and probability sensitivity, can be interpreted in terms of attention allocation. In two experiments, we tested hypotheses about specific links between CPT parameters and attentional regularities. Experiment 1 used process tracing to monitor participants predecisional attention allocation to outcome and probability information. As hypothesized, individual differences in CPTs loss-aversion, outcome-sensitivity, and probability-sensitivity parameters (estimated from participants choices) were systematically associated with individual differences in attention allocation to outcome and probability information. For instance, loss aversion was associated with the relative attention allocated to loss and gain outcomes, and a more strongly curved weighting function was associated with less attention allocated to probabilities. Experiment 2 manipulated participants attention to losses or gains, causing systematic differences in CPTs loss-aversion parameter. This result indicates that attention allocation can to some extent cause choice regularities that are captured by CPT. Our findings demonstrate an as-if models capacity to reflect characteristics of information processing. We suggest that the observed CPT-attention links can be harnessed to inform the development of process models of risky choice.","link":"/opendata/pachur-et-al-2018/"},{"title":"Palminteri et al. (2016)","text":"Adolescence is a period of life characterised by changes in learning and decision-making. Learning and decision-making do not rely on a unitary system, but instead require the coordination of different cognitive processes that can be mathematically formalised as dissociable computational modules. Here, we aimed to trace the developmental time-course of the computational modules responsible for learning from reward or punishment, and learning from counterfactual feedback. Adolescents and adults carried out a novel reinforcement learning paradigm in which participants learned the association between cues and probabilistic outcomes, where the outcomes differed in valence (reward versus punishment) and feedback was either partial or complete (either the outcome of the chosen option only, or the outcomes of both the chosen and unchosen option, were displayed). Computational strategies changed during development: whereas adolescents behaviour was better explained by a basic reinforcement learning algorithm, adults behaviour integrated increasingly complex computational features, namely a counterfactual learning module (enabling enhanced performance in the presence of complete feedback) and a value contextualisation module (enabling symmetrical reward and punishment learning). Unlike adults, adolescent performance did not benefit from counterfactual (complete) feedback. In addition, while adults learned symmetrically from both reward and punishment, adolescents learned from reward but were less likely to learn from punishment. This tendency to rely on rewards and not to consider alternative consequences of actions might contribute to our understanding of decision-making in adolescence.","link":"/opendata/palminteri-et-al-2016/"},{"title":"Palminteri et al. (2017)","text":"Previous studies suggest that factual learning, that is, learning from obtained outcomes, is biased, such that participants preferentially take into account positive, as compared to negative, prediction errors. However, whether or not the prediction error valence also affects counterfactual learning, that is, learning from forgone outcomes, is unknown. To address this question, we analysed the performance of two groups of participants on reinforcement learning tasks using a computational model that was adapted to test if prediction error valence influences learning. We carried out two experiments: in the factual learning experiment, participants learned from partial feedback (i.e., the outcome of the chosen option only); in the counterfactual learning experiment, participants learned from complete feedback information (i.e., the outcomes of both the chosen and unchosen option were displayed). In the factual learning experiment, we replicated previous findings of a valence-induced bias, whereby participants learned preferentially from positive, relative to negative, prediction errors. In contrast, for counterfactual learning, we found the opposite valence-induced bias: negative prediction errors were preferentially taken into account, relative to positive ones. When considering valence-induced bias in the context of both factual and counterfactual learning, it appears that people tend to preferentially take into account information that confirms their current choice.","link":"/opendata/palminteri-et-al-2017/"},{"title":"Pauli et al. (2022)","text":"Theoretical and empirical accounts suggest that adolescence is associated with heightened reward learning and impulsivity. Experimental tasks and computational models that can dissociate reward learning from the tendency to initiate actions impulsively (action initiation bias) are thus critical to characterise the mechanisms that drive developmental differences. However, existing work has rarely quantified both learning ability and action initiation, or it has tested small samples. Here, using computational modelling of a learning task collected from a large sample (N=742, 9-18 years, 11 countries), we tested differences in reward and punishment learning and action initiation from childhood to adolescence. Computational modelling revealed that whilst punishment learning rates increased with age, reward learning remained stable. In parallel, action initiation biases decreased with age. Results were similar when considering pubertal stage instead of chronological age. We conclude that heightened reward responsivity in adolescence can reflect differences in action initiation rather than enhanced reward learning.","link":"/opendata/pauli-et-al-2022/"},{"title":"Pedersen et al. (2021)","text":"Adaptive behavior requires balancing approach and avoidance based on the rewarding and aversive consequences of actions. Imbalances in this evaluation are thought to characterize mood disorders such as major depressive disorder (MDD). We present a novel application of the drift diffusion model (DDM) suited to quantify how offers of reward and aversiveness, and neural correlates thereof, are dynamically integrated to form decisions, and how such processes are altered in MDD. Hierarchical parameter estimation from the DDM demonstrated that the MDD group differed in three distinct reward-related parameters driving approach-based decision making. First, MDD was associated with reduced reward sensitivity, measured as the impact of offered reward on evidence accumulation. Notably, this effect was replicated in a follow-up study. Second, the MDD group showed lower starting point bias towards approaching offers. Third, this starting point was influenced in opposite directions by Pavlovian effects and by nucleus accumbens activity across the groups: greater accumbens activity was related to approach bias in controls but avoid bias in MDD. Cross-validation revealed that the combination of these computational biomarkers were diagnostic of patient status, with accumbens influences being particularly diagnostic. Finally, within the MDD group, reward sensitivity and nucleus accumbens parameters were differentially related to symptoms of perceived stress and depression. Collectively, these findings establish the promise of computational psychiatry approaches to dissecting approach-avoidance decision dynamics relevant for affective disorders.","link":"/opendata/pedersen-et-al-2021/"},{"title":"Peng et al. (2022)","text":"Obsessive-compulsive disorder (OCD) is characterized by uncontrollable repetitive actions thought to rely on abnormalities within fundamental instrumental learning systems. We investigated cognitive and computational mechanisms underlying Pavlovian biases on instrumental behavior in both clinical OCD patients and healthy controls using a Pavlovian-Instrumental Transfer (PIT) task. PIT is typically evidenced by increased responding in the presence of a positive (previously rewarded) Pavlovian cue, and reduced responding in the presence of a negative cue. Thirty OCD patients and thirty-one healthy controls completed the Pavlovian Instrumental Transfer test, which included instrumental training, Pavlovian training for positive, negative and neutral cues, and a PIT phase in which participants performed the instrumental task in the presence of the Pavlovian cues. Modified Rescorla-Wagner models were fitted to trial-by-trial data of participants to estimate underlying computational mechanism and quantify individual differences during training and transfer stages. Bayesian hierarchical methods were used to estimate free parameters and compare the models. Behavioral and computational results indicated a weaker Pavlovian influence on instrumental behavior in OCD patients than in HC, especially for negative Pavlovian cues. Our results contrast with the increased PIT effects reported for another set of disorders characterized by compulsivity, substance use disorders, in which PIT is enhanced. A possible reason for the reduced PIT in OCD may be impairment in using the contextual information provided by the cues to appropriately adjust behavior, especially when inhibiting responding when a negative cue is present. This study provides deeper insight into our understanding of deficits in OCD from the perspective of Pavlovian influences on instrumental behavior and may have implications for OCD treatment modalities focused on reducing compulsive behaviors.","link":"/opendata/peng-et-al-2022/"},{"title":"Pereg et al. (2022)","text":"The study of social learning examines how individuals learn from others by means of observation, imitation, or compliance with advice. However, it still remains largely unknown whether social learning processes have a distinct contribution to choice behavior, independent from non-social trial-and-error learning that often occurs simultaneously. 153 participants completed a reinforcement learning task, where they were asked to make choices to gain rewards. Advice from an artificial teacher was presented on 60% of the trials, allowing us to compare choice behavior with and without advice. Results showed a strong and reliable tendency to follow advice (test-retest reliability ~.73). Computational modeling suggested a unique contribution of three distinct learning strategies: (a) individual learning (i.e., learning the value of actions, independent of advice), (b) informed advice-taking (i.e., learning the value of following advice), and (c) non-informed advice-taking (i.e., a constant bias to follow advice regardless of outcome history). Computational lesion simulations analyses provided specific regression signatures to both informed and non-informed advice taking processes that were then confirmed by empirical data. We discuss the theoretical implications of integrating internal and external information during the learning process.","link":"/opendata/pereg-et-al-2022/"},{"title":"Pescetelli & Yeung (2019)","text":"In a world where ideas flow freely between people across multiple platforms, we often find ourselves relying on others’ information without an objective standard to judge whether those opinions are accurate. The present study tests an agreement-in-confidence hypothesis of advice perception, which holds that internal metacognitive evaluations of decision confidence play an important functional role - namely being a learning signal that allows to learn about the reliability of others in the absence of feedback - in the perception and use of social information, such as peers’ advice. We propose that confidence can be used, computationally, to estimate advisors’ trustworthiness and advice reliability. Specifically, these processes are hypothesized to be particularly important in situations where objective feedback is absent or difficult to acquire. Here, we use a judge-advisor system paradigm to precisely manipulate the profiles of virtual advisors whose opinions are provided to participants performing a perceptual decision making task. We find that when advisors’ and participants’ judgments are independent, people are able to discriminate subtle advice features, like confidence calibration, whether or not objective feedback is available. However, when observers’ judgments (and judgment errors) are correlated - as is the case in many social contexts - predictable distortions can be observed between feedback and feedback-free scenarios. A simple model of advice reliability estimation, endowed with metacognitive insight, is able to explain key patterns of results observed in the human data. Finally, we use agent-based modeling to explore implications of these individual-level decision strategies for network-level patterns of trust and belief formation.","link":"/opendata/pescetelli-yeung-2019/"},{"title":"Peterson et al. (2021)","text":"Predicting and understanding how people make decisions has been a long-standing goal in many fields, with quantitative models of human decision-making informing research in both the social sciences and engineering. We show how progress toward this goal can be accelerated by using large datasets to power machine-learning algorithms that are constrained to produce interpretable psychological theories. Conducting the largest experiment on risky choice to date and analyzing the results using gradient-based optimization of differentiable decision theories implemented through artificial neural networks, we were able to recapitulate historical discoveries, establish that there is room to improve on existing theories, and discover a new, more accurate model of human decision-making in a form that preserves the insights from centuries of research.","link":"/opendata/peterson-et-al-2021/"},{"title":"Petitet et al. (2022)","text":"Apathy and impulsivity are expressed in a wide range of neuropsychiatric disorders, and, to a less severe extent, in healthy people too. Although traditionally considered to be opposite extremes of a single motivational spectrum, recent epidemiological questionnaire-based data suggest that both traits can in fact co-exist within the same individual. Here, we sought to investigate the relationship between these constructs in healthy people within a controlled task environment that examines the ability to make a decision under temporal uncertainty and measures the vigour of the response. Sixty participants performed a new version of the Traffic Light Task (TLT) and completed self-report questionnaire measures of apathy and impulsivity. Although the two traits were positively correlated in questionnaire assessments, they were associated with distinct behavioural signatures on the task. Impulsivity was expressed as an inflexible tendency to generate rapid anticipatory responses, regardless of task context. Apathy, on the other hand, was associated with a blunted effect of reward on response vigour. These findings reveal how apathy and impulsivity are related to distinct dimensions of goal-directed behaviour, explaining how these traits might co-exist in the same individuals.","link":"/opendata/petitet-et-al-2022/"},{"title":"Pike et al. (2022)","text":"Affective biases are commonly seen in disorders such as depression and anxiety, where individuals may show attention towards and more rapid processing of negative or threatening stimuli. Affective biases have been shown to change with effective intervention: randomized controlled trials into these biases and the mechanisms that underpin them may allow greater understanding of how interventions can be improved and their success be maximized. For trials to be informative, we must have reliable ways of measuring affective bias over time, so we can detect how interventions are changing these biases. In particular, the test-retest reliability of our measures puts an upper bound on our ability to detect effects: thus, in this study, we examine the test-retest reliability of two behavioural tasks that examine affective bias. We recruited 58 individuals in an online study who completed these tasks twice, with at least 14 days in between sessions. We analysed reliability of both summary statistics and parameters from computational models using Pearson’s correlations and intra-class correlations. Standard summary statistic measures from these affective bias tasks had reliability ranging from 0.18 (poor) to 0.49 (moderate). Parameters from computational modelling of these tasks were in many cases less reliable than summary statistics. Embedding the covariance between sessions within the generative modelling framework resulted in higher stability estimates. In sum, measures from these affective bias tasks are moderately reliable, but further work to improve the reliability of these tasks would improve still further our ability to draw inferences in randomized trials.","link":"/opendata/pike-et-al-2022/"},{"title":"Pike et al. (2023)","text":"Catastrophizing, when an individual overestimates the probability of a severe negative outcome, is related to various aspects of mental ill-health. Here, we further characterize catastrophizing by investigating the extent to which self-reported catastrophizing is associated with risk-taking, using an online behavioural task and computational modelling. We performed two online studies: a pilot study (n = 69) and a main study (n = 263). In the pilot study, participants performed the Balloon Analogue Risk Task (BART), alongside two other tasks (reported in the Supplement), and completed mental health questionnaires. Based on the findings from the pilot, we explored risk-taking in more detail in the main study using two versions of the Balloon Analogue Risk task (BART), with either a high or low cost for bursting the balloon. In the main study, there was a significant negative relationship between self-report catastrophizing scores and risk-taking in the low (but not high) cost version of the BART. Computational modelling of the BART task revealed no relationship between any parameter and Catastrophizing scores in either version of the task. We show that increased self-reported catastrophizing may be associated with reduced behavioural measures of risk-taking, but were unable to identify a computational correlate of this effect.","link":"/opendata/pike-et-al-2023/"},{"title":"Piray et al. (2019)","text":"Learning and decision-making are modulated by socio-emotional processing and such modulation is implicated in clinically relevant personality traits of social anxiety. The present study elucidates the computational and neural mechanisms by which emotionally aversive cues disrupt learning in socially anxious human individuals. Healthy volunteers with low or high trait social anxiety performed a reversal learning task requiring learning actions in response to angry or happy face cues. Choice data were best captured by a computational model in which learning rate was adjusted according to the history of surprises. High trait socially anxious individuals used a less-dynamic strategy for adjusting their learning rate in trials started with angry face cues and unlike the low social anxiety group, their dorsal anterior cingulate cortex (dACC) activity did not covary with the learning rate. Our results demonstrate that trait social anxiety is accompanied by disruption of optimal learning and dACC activity in threatening situations.","link":"/opendata/piray-et-al-2019/"},{"title":"Pisauro et al. (2022)","text":"Social interactions evolve continuously. Sometimes we cooperate, sometimes we compete, while at other times we strategically position ourselves somewhere in between to account for the ever-changing social contexts around us. Research on social interactions often focuses on a binary dichotomy between competition and cooperation, ignoring peoples evolving shifts along a continuum. Here, we develop an economic game - the Space Dilemma - where two players change their degree of cooperativeness over time in cooperative and competitive contexts. Using computational modelling we show how social contexts bias choices and characterise how inferences about others intentions modulate cooperativeness. Consistent with the modelling predictions, brain regions previously linked to social cognition, including the temporo-parietal junction, dorso-medial prefrontal cortex and the anterior cingulate gyrus, encode social prediction errors and context-dependent signals, correlating with shifts along a cooperation-competition continuum. These results provide a comprehensive account of the computational and neural mechanisms underlying the continuous trade-off between cooperation and competition.","link":"/opendata/pisauro-et-al-2022/"},{"title":"Pleskac et al. (2019)","text":"Computational models of decision making typically assume as people deliberate between options they mentally simulate outcomes from each one and integrate valuations of these outcomes to form a preference. In two studies, we investigated this deliberation process using a task where participants make a series of decisions between a certain and an uncertain option, which were shown as dynamic visual samples that represented possible payoffs. We developed and validated a method of reverse correlational analysis for the task that measures how this time-varying signal was used to make a choice. The first study used this method to examine how information processing during deliberation differed from a perceptual analog of the task. We found participants were less sensitive to each sample of information during preferential choice. In a second study, we investigated how these different measures of deliberation were related to impulsivity and drug and alcohol use. We found that while properties of the deliberation process were not related to impulsivity, some aspects of the process may be related to substance use. In particular, alcohol abuse was related to diminished sensitivity to the payoff information and drug use was related to how the initial starting point of evidence accumulation. We synthesized our results with a rank-dependent sequential sampling model which suggests that participants allocated more attentional weight to larger potential payoffs during preferential choice.","link":"/opendata/pleskac-et-al-2019/"},{"title":"Poli et al. (2022)","text":"Exploration is curiosity-driven when it relies on the intrinsic motivation to know rather than on extrinsic rewards. Recent evidence shows that artificial agents perform better on a variety of tasks when their learning is curiosity-driven, and humans often engage in curiosity-driven learning when sampling information from the environment. However, which mechanisms underlie curiosity is still unclear. Here, we let participants freely explore different unknown environments that contained learnable sequences of events with varying degrees of noise and volatility. A hierarchical reinforcement learning model captured how participants were learning in these different kinds of unknown environments, and it also tracked the errors they expected to make and the learning opportunities they were planning to seek. With this computational approach, we show that participants exploratory behavior is guided by learning progress and perceptual novelty. Moreover, we demonstrate an overall tendency of participants to avoid extreme forms of uncertainty. These findings elucidate the cognitive mechanisms that underlie curiosity-driven exploration of unknown environments. Implications of this novel way of quantifying curiosity within a reinforcement learning framework are discussed.","link":"/opendata/poli-et-al-2022/"},{"title":"Pool et al. (2021)","text":"It has been suggested that there are two distinct and parallel mechanisms for controlling instrumental behavior in mammals: goal-directed actions and habits. To gain an understanding of how these two systems interact to control behavior, it is essential to characterize the mechanisms by which the balance between these systems is influenced by experience. Studies in rodents have shown that the amount of training governs the relative expression of these two systems: Behavior is goal-directed following moderate training, but the more extensively an instrumental action is trained, the more it becomes habitual. It is less clear whether humans exhibit similar training effects on the expression of goal-directed and habitual behavior, as human studies have reported contradictory findings. To tackle these contradictory findings, we formed a consortium, where four laboratories undertook a preregistered experimental induction of habits by manipulating the amount of training. There was no statistical evidence for a main effect of the amount of training on the formation and expression of habits. However, exploratory analyses suggest a moderating effect of the affective component of stress on the impact of training over habit expression. Participants who were lower in affective stress appeared to be initially goal-directed, but became habitual with increased training, whereas participants who were high in affective stress were already habitual even after moderate training, thereby manifesting insensitivity to overtraining effects. Our findings highlight the importance of the role of moderating variables such as individual differences in stress and anxiety when studying the experimental induction of habits in humans.","link":"/opendata/pool-et-al-2021/"},{"title":"Potter et al. (2017)","text":"Reinforcement learning theory distinguishes “model-free” learning, which fosters reflexive repetition of previously rewarded actions, from “model-based” learning, which recruits a mental model of the environment to flexibly select goal-directed actions. Whereas model-free learning is evident across development, recruitment of model-based learning appears to increase with age. However, the cognitive processes underlying the development of model-based learning remain poorly characterized. Here, we examined whether age-related differences in cognitive processes underlying the construction and flexible recruitment of mental models predict developmental increases in model-based choice. In a cohort of participants aged 9–25, we examined whether the abilities to infer sequential regularities in the environment (“statistical learning”), maintain information in an active state (“working memory”) and integrate distant concepts to solve problems (“fluid reasoning”) predicted age-related improvements in model-based choice. We found that age-related improvements in statistical learning performance did not mediate the relationship between age and model-based choice. Ceiling performance on our working memory assay prevented examination of its contribution to model-based learning. However, age-related improvements in fluid reasoning statistically mediated the developmental increase in the recruitment of a model-based strategy. These findings suggest that gradual development of fluid reasoning may be a critical component process underlying the emergence of model-based learning.","link":"/opendata/potter-et-al-2017/"},{"title":"Pronk et al. (2022)","text":"Research deployed via the internet and administered via smartphones could have access to more diverse samples than lab-based research. Diverse samples could have relatively high variation in their traits and so yield relatively reliable measurements of individual differences in these traits. Several cognitive tasks that originated from the experimental research tradition have been reported to yield relatively low reliabilities (Hedge et al., 2018) in samples with restricted variance (students). This issue could potentially be addressed by smartphone-mediated administration in diverse samples. We formulate several criteria to determine whether a cognitive task is suitable for individual differences research on commodity smartphones: no very brief or precise stimulus timing, relative response times (RTs), a maximum of two response options, and a small number of graphical stimuli. The flanker task meets these criteria. We compared the reliability of individual differences in the flanker effect across samples and devices in a preregistered study. We found no evidence that a more diverse sample yields higher reliabilities. We also found no evidence that commodity smartphones yield lower reliabilities than commodity laptops. Hence, diverse samples might not improve reliability above student samples, but smartphones may well measure individual differences with cognitive tasks reliably. Exploratively, we examined different reliability coefficients, split-half reliabilities, and the development of reliability estimates as a function of task length.","link":"/opendata/pronk-et-al-2022/"},{"title":"Pupillo et al. (2022)","text":"Predictive processing accounts propose that our brain constantly tries to match top-down internal representations with bottom-up incoming information from the environment. Predictions can lead to prediction errors of varying degrees depending on the extent to which the information encountered in the environment conforms with prior expectations. Theoretical and computational models assume that prediction errors have beneficial effects on learning and memory. However, while there is strong evidence on the effects of prediction error on learning, relatively less evidence is available regarding its effects on memory. Moreover, most of the studies available so far manipulated prediction error by using monetary rewards, whereas in everyday life learning does not always occur in the presence of explicit rewards. We used a task in which participants leaned context/object-category associations of different strength based on the outcomes of their predictions. After learning these associations, participants were presented with trial-unique objects that could match or violate their predictions. Finally, participants were asked to complete a surprise recognition memory test. We used a reinforcement learning model to derive subject-specific trial-to-trial estimates of prediction error at encoding and link it to subsequent recognition memory. Results showed that model-derived prediction errors at encoding influenced subsequent memory as a function of the outcome of participants’ predictions (correct vs incorrect). When participants correctly predicted the object category, stronger prediction errors (as a consequence of weak expectations) led to enhanced memory. In contrast, when participants incorrectly predicted the object category, stronger prediction errors (as a consequence of strong expectations) led to impaired memory. These results reveal a computationally specific influence of prediction error on memory formation, highlighting the important moderating role of choice outcome that may be related to interactions between the hippocampal and striatal dopaminergic systems.","link":"/opendata/pupillo-et-al-2022/"},{"title":"Qin et al. (2023)","text":"A large amount of literature demonstrates that social behaviour can be triggered by environmental cues. A long-standing debate involves the question of whether such stimuli trigger behaviour directly (i.e. habits) or whether these effects mediate goals. As studies on automatic goal pursuit typically use real-world cues that are already associated with the behaviour and potentially the goal, it is impossible to make strong claims about the nature of the effects. In the present paper, we use a paradigm inspired by the Pavlovian-to-instrumental transfer (PIT) literature to examine how the environment can trigger goal-directed behaviour. Building on the essence of pro-self and pro-social motives in humans, two experiments explored the PIT effect when the outcomes were framed in terms of self- versus other-interest. Participants performed actions to earn money for themselves or a charity. Each outcome was linked to a different cue. The results showed that a cue predictive of self-interest outcomes facilitated responses instrumental in gaining the outcome, while such specific PIT effect for other-interest outcomes only emerged when participants were free to donate the money. We briefly discuss these findings reflecting on whether the PIT effect in our paradigm is indeed sensitive to the value of social goals.","link":"/opendata/qin-et-al-2023/"},{"title":"Raab & Hartley (2020)","text":"Multiple learning systems allow individuals to flexibly respond to opportunities and challenges present in the environment. An evolutionarily conserved Pavlovian learning mechanism couples valence and action, promoting a tendency to approach cues associated with reward and to inhibit action in the face of anticipated punishment. Although this default response system may be adaptive, these hard-wired reactions can hinder the ability to learn flexible instrumental actions in pursuit of a goal. Such constraints on behavioral flexibility have been studied extensively in adults. However, the extent to which these valence-specific response tendencies bias instrumental learning across development remains poorly characterized. Here, we show that while Pavlovian response biases constrain flexible action learning in children and adults, these biases are attenuated in adolescents. This adolescent-specific reduction in Pavlovian bias may promote unbiased exploration of approach and avoidance responses, facilitating the discovery of rewarding behavior in the many novel contexts that adolescents encounter.","link":"/opendata/raab-hartley-2020/"},{"title":"Raab et al. (2022)","text":"Accurate assessment of environmental controllability enables individuals to adaptively adjust their behavior-exploiting rewards when desirable outcomes are contingent upon their actions and minimizing costly deliberation when their actions are inconsequential. However, it remains unclear how estimation of environmental controllability changes from childhood to adulthood. Ninety participants (ages 8-25) completed a task that covertly alternated between controllable and uncontrollable conditions, requiring them to explore different actions to discover the current degree of environmental controllability. We found that while children were able to distinguish controllable and uncontrollable conditions, accuracy of controllability assessments improved with age. Computational modeling revealed that whereas younger participants controllability assessments relied on evidence gleaned through random exploration, older participants more effectively recruited their task structure knowledge to make highly informative interventions. Age-related improvements in working memory mediated this qualitative shift toward increased use of an inferential strategy. Collectively, these findings reveal an age-related shift in the cognitive processes engaged to assess environmental controllability. Improved detection of environmental controllability may foster increasingly adaptive behavior over development by revealing when actions can be leveraged for ones benefit.","link":"/opendata/raab-et-al-2022/"},{"title":"Radulescu et al. (2020)","text":"There are a number of well-accepted ways to measure risk sensitivity, with researchers often making conclusions about individual differences based on a single task. Even though long-standing observations suggest that how risky outcomes are presented changes peoples behavior, it is unclear whether risk sensitivity is a unitary trait that can be measured by any one of these instruments. To directly answer this question, we administered three tasks commonly used to elicit risk sensitivity within-subject to a large sample of participants on Amazon Mechanical Turk. Our findings revealed high individual variability in each measure, with little evidence of consistency among different tasks: many participants who were classified as risk-averse in one task were risk-seeking in another, and we observed no significant correlations between continuous measures of risk sensitivity as measured in each of the tasks. Our results cast doubt on the pervasive assumption that risk paradigms measure a single underlying trait, and suggest instead that behavior in risky situations is the result of heterogeneous, interacting, and possibly task-dependent cognitive mechanisms.","link":"/opendata/radulescu-et-al-2020/"},{"title":"Rahnev et al. (2020)","text":"Understanding how people rate their confidence is critical for the characterization of a wide range of perceptual, memory, motor and cognitive processes. To enable the continued exploration of these processes, we created a large database of confidence studies spanning a broad set of paradigms, participant populations and fields of study. The data from each study are structured in a common, easy-to-use format that can be easily imported and analysed using multiple software packages. Each dataset is accompanied by an explanation regarding the nature of the collected data. At the time of publication, the Confidence Database (which is available at https://osf.io/s46pr/) contained 145 datasets with data from more than 8,700 participants and almost 4 million trials. The database will remain open for new submissions indefinitely and is expected to continue to grow. Here we show the usefulness of this large collection of datasets in four different analyses that provide precise estimations of several foundational confidence-related effects.’","link":"/opendata/rahnev-et-al-2020/"},{"title":"Rao & Hastie (2023)","text":"Beliefs like the Gamblers Fallacy and the Hot Hand have interested cognitive scientists, economists, and philosophers for centuries. We propose that these judgment patterns arise from the observers mental models of the sequence-generating mechanism, moderated by the strength of belief in an a priori base rate. In six behavioral experiments, participants observed one of three mechanisms generating sequences of eight binary events: a random mechanical device, an intentional goal-directed actor, and a financial market. We systematically manipulated participants beliefs about the base rate probabilities at which different outcomes were generated by each mechanism. Participants judged 18 sequences of outcomes produced by a mechanism with either an unknown base rate, a specified distribution of three equiprobable base rates, or a precise, fixed base rate. Six target sequences ended in streaks of between two and seven identical outcomes. The most common predictions for subsequent events were best described as pragmatic belief updating, expressed as an increasingly strong expectation that a streak of identical signals would repeat as the length of that streak increased. The exception to this pattern was for sequences generated by a random mechanical device with a fixed base rate of .50. Under this specific condition, participants exhibited a bias toward reversal of streaks, and this bias was larger when participants were asked to make a dichotomous choice versus a numerical probability rating. We review alternate accounts for the anomalous judgments of sequences and conclude with our favored interpretation that is based on Rabins version of Tversky &amp; Kahnemans Law of Small Numbers.","link":"/opendata/rao-hastie-2023/"},{"title":"Raphaël et al. (2022)","text":"Humans procrastinate despite being aware of potential adverse consequences. Yet, the neuro-computational mechanisms underlying procrastination remain poorly understood. Here, we use fMRI during intertemporal choice to inform a computational model that predicts procrastination behavior in independent tests. Procrastination is assessed in the laboratory as the preference for performing an effortful task on the next day as opposed to immediately, and at home as the delay taken in returning completed administrative forms. These procrastination behaviors are respectively modeled as unitary and repeated decisions to postpone a task until the next time step, based on a net expected value that integrates reward and effort attributes, both discounted with delay. The key feature that is associated with procrastination behavior across individuals (both in-lab and at-home) is the extent to which the expected effort cost (signaled by the dorsomedial prefrontal cortex) is attenuated by the delay before task completion. Thus, procrastination might stem from a cognitive bias that would make doing a task later (compared to now) appear as much less effortful but not much less rewarding.","link":"/opendata/raphael-et-al-2022/"},{"title":"Reed et al. (2020)","text":"Paranoia is the belief that harm is intended by others. It may arise from selective pressures to infer and avoid social threats, particularly in ambiguous or changing circumstances. We propose that uncertainty may be sufficient to elicit learning differences in paranoid individuals, without social threat. We used reversal learning behavior and computational modeling to estimate belief updating across individuals with and without mental illness, online participants, and rats chronically exposed to methamphetamine, an elicitor of paranoia in humans. Paranoia is associated with a stronger prior on volatility, accompanied by elevated sensitivity to perceived changes in the task environment. Methamphetamine exposure in rats recapitulates this impaired uncertainty-driven belief updating and rigid anticipation of a volatile environment. Our work provides evidence of fundamental, domain-general learning differences in paranoid individuals. This paradigm enables further assessment of the interplay between uncertainty and belief-updating across individuals and species.","link":"/opendata/reed-et-al-2020/"},{"title":"Reiter et al. (2021)","text":"Adolescents are prone to social influence from peers, with implications for development, both adaptive and maladaptive. Here, using a computer-based paradigm, we replicate a cross-sectional effect of more susceptibility to peer influence in a large dataset of adolescents 14 to 24 years old. Crucially, we extend this finding by adopting a longitudinal perspective, showing that a within-person susceptibility to social influence decreases over a 1.5 year follow-up time period. Exploiting this longitudinal design, we show that susceptibility to social influences at baseline predicts an improvement in peer relations over the follow-up period. Using a Bayesian computational model, we demonstrate that in younger adolescents a greater tendency to adopt others preferences arises out of a higher uncertainty about their own preferences in the paradigmatic case of delay discounting (a phenomenon called preference uncertainty). This preference uncertainty decreases over time and, in turn, leads to a reduced susceptibility of ones own behaviour to an influence from others. Neuro-developmentally, we show that a measure of myelination within medial prefrontal cortex, estimated at baseline, predicts a developmental decrease in preference uncertainty at follow-up. Thus, using computational and neural evidence, we reveal adaptive mechanisms underpinning susceptibility to social influence during adolescence.","link":"/opendata/reiter-et-al-2021/"},{"title":"Rischall et al. (2022)","text":"In natural settings, people decide not only when to request information, but also which attribute of a situation to inquire about. Little is known about how participants prioritize inquiries about task-relevant features. We show that, in a new task of information demand, participants inefficiently inquired about attributes that had high individual value but were less informative about a total payoff, and these inefficiencies persisted in instrumental conditions in which they entailed significantly lower rewards. Factors contributing to inefficient information demand included a form of anticipatory utility motivated by high value individual attributes rather than the total reward, and difficulty identifying the most informative observations. Across participants, more efficient inquiries were associated with personality traits, including lower extraversion and reward sensitivity scores and higher stress tolerance and need for cognition. The results highlight new affective, cognitive and personality factors involved in prioritizing sources of information.","link":"/opendata/rischall-et-al-2022/"},{"title":"Rmus et al. (2023)","text":"In reinforcement learning (RL) experiments, participants learn to make rewarding choices in response to different stimuli; RL models use outcomes to estimate stimulus–response values that change incrementally. RL models consider any response type indiscriminately, ranging from more concretely defined motor choices (pressing a key with the index finger), to more general choices that can be executed in a number of ways (selecting dinner at the restaurant). However, does the learning process vary as a function of the choice type? In Experiment 1, we show that it does: Participants were slower and less accurate in learning correct choices of a general format compared with learning more concrete motor actions. Using computational modeling, we show that two mechanisms contribute to this. First, there was evidence of irrelevant credit assignment: The values of motor actions interfered with the values of other choice dimensions, resulting in more incorrect choices when the correct response was not defined by a single motor action; second, information integration for relevant general choices was slower. In Experiment 2, we replicated and further extended the findings from Experiment 1 by showing that slowed learning was attributable to weaker working memory use, rather than slowed RL. In both experiments, we ruled out the explanation that the difference in performance between two condition types was driven by difficulty/different levels of complexity. We conclude that defining a more abstract choice space used by multiple learning systems for credit assignment recruits executive resources, limiting how much such processes then contribute to fast learning.","link":"/opendata/rmus-et-al-2023/"},{"title":"Roberts et al. (2022)","text":"Decades of research have established the ubiquity and importance of choice biases, such as the framing effect, yet why these seemingly irrational behaviors occur remains unknown. A prominent dual-system account maintains that alternate framings bias choices because of the unchecked influence of quick, affective processes, and findings that time pressure increases the framing effect have provided compelling support. Here, we present a novel alternative account of magnified framing biases under time pressure that emphasizes shifts in early visual attention and strategic adaptations in the decision-making process. In a preregistered direct replication (N = 40 adult undergraduates), we found that time constraints produced strong shifts in visual attention toward reward-predictive cues that, when combined with truncated information search, amplified the framing effect. Our results suggest that an attention-guided, strategic information-sampling process may be sufficient to explain prior results and raise challenges for using time pressure to support some dual-system accounts.","link":"/opendata/roberts-et-al-2022/"},{"title":"Robison & Nguyen (2023)","text":"Across four experiments, we manipulated features of a simple reaction time (RT) task to examine the effects of such features on vigilance. In Experiment 1, we created simple reaction time “game” that pitted participants against two computerized avatars. In one condition, participants were awarded points, while the other condition did not receive points. Performance in the two conditions did not differ, but both conditions showed faster RTs and shallower time-on-task performance decrements compared to a standard psychomotor vigilance task. In Experiment 2, we removed the competitive feature but retained the point system. In this case, participants without a point system showed a steeper performance decrement than those with a point system. Experiments 3 and 4 replicated these effects and corroborated their findings with pupillometry. Participants in both conditions of Experiment 3 (competitive task) and the points condition of Experiment 4 showed larger task-evoked pupillary responses than participants in the no-points condition of Experiment 4. These findings challenge the notion that time-on-task performance decrements are caused by resource depletion (Smit et al., 2004), and are better explained by motivational control (Hockey, 2011) or cost-benefit theories (Boksem &amp; Tops, 2008; Kurzban et al., 2013) of mental effort and cognitive fatigue.","link":"/opendata/robison-nguyen-2023/"},{"title":"Rodman et al. (2023)","text":"Peer relationships and social belonging are particularly important during adolescence. Using a willingness-to-work paradigm to quantify incentive motivation, we examined whether evaluative information holds unique value for adolescents. Participants (N = 102; 12-23 years old) rated peers, predicted how peers rated them, and exerted physical effort to view each peer’s rating. We measured grip force, speed, and opt-out behavior to examine the motivational value of peer feedback, relative to money in a control condition, and to assess how peer desirability and participants’ expectations modulated motivated effort across age. Overall, when compared with adolescents, adults were relatively less motivated for feedback than money. Whereas adults exerted less force and speed for feedback when expecting rejection, adolescents exerted greater force and speed when expecting to be more strongly liked or disliked. These findings suggest that the transition into adulthood is accompanied by a self-protective focus, whereas adolescents are motivated to consume highly informative feedback, even if negative.","link":"/opendata/rodman-et-al-2023/"},{"title":"Romero-Verdugo et al. (2023)","text":"In our connected era, we spend significant time and effort satisfying our curiosity. Often, we choose which information we seek, but sometimes the selection is made for us. We hypothesized that humans exhibit enhanced curiosity in the context of choice. We designed a task in which healthy participants saw two lotteries on each trial. On some trials, participants chose which lottery to play. On other trials, the lottery was selected for them. Participants then indicated their curiosity about the outcome of the to-be-played lottery via self-report ratings (Experiment 1, N = 34) or willingness-to-wait decisions (Experiment 2, N = 34). We found that participants exhibited higher curiosity ratings and greater willingness to wait for the outcome of lotteries they had chosen than for lotteries that had been selected for them (controlling for initial preference). This demonstrates that choice boosts curiosity, which may have implications for boosting learning, memory, and motivation.","link":"/opendata/romero-verdugo-et-al-2023/"},{"title":"Rosenbaum et al. (2022)","text":"As individuals learn through trial and error, some are more influenced by good outcomes, while others weight bad outcomes more heavily. Such valence biases may also influence memory for past experiences. Here, we examined whether valence asymmetries in reinforcement learning change across adolescence, and whether individual learning asymmetries bias the content of subsequent memory. Participants ages 8-27 learned the values of point machines, after which their memory for trial-unique images presented with choice outcomes was assessed. Relative to children and adults, adolescents overweighted worse-than-expected outcomes during learning. Individuals valence biases modulated incidental memory, such that those who prioritized worse- (or better-) than-expected outcomes during learning were also more likely to remember images paired with these outcomes, an effect reproduced in an independent dataset. Collectively, these results highlight age-related changes in the computation of subjective value and demonstrate that a valence-asymmetric valuation process influences how information is prioritized in episodic memory.","link":"/opendata/rosenbaum-et-al-2022/"},{"title":"Rossi-Goldthorpe et al. (2021)","text":"Self-deception, paranoia, and overconfidence involve misbeliefs about the self, others, and world. They are often considered mistaken. Here we explore whether they might be adaptive, and further, whether they might be explicable in Bayesian terms. We administered a difficult perceptual judgment task with and without social influence (suggestions from a cooperating or competing partner). Crucially, the social influence was uninformative. We found that participants heeded the suggestions most under the most uncertain conditions and that they did so with high confidence, particularly if they were more paranoid. Model fitting to participant behavior revealed that their prior beliefs changed depending on whether the partner was a collaborator or competitor, however, those beliefs did not differ as a function of paranoia. Instead, paranoia, self-deception, and overconfidence were associated with participants perceived instability of their own performance. These data are consistent with the idea that self-deception, paranoia, and overconfidence flourish under uncertainty, and have their roots in low self-esteem, rather than excessive social concern. The model suggests that spurious beliefs can have value-self-deception is irrational yet can facilitate optimal behavior. This occurs even at the expense of monetary rewards, perhaps explaining why self-deception and paranoia contribute to costly decisions which can spark financial crashes and devastating wars.","link":"/opendata/rossi-goldthorpe-et-al-2021/"},{"title":"Rouhani et al. (2018)","text":"Reward-prediction errors track the extent to which rewards deviate from expectations, and aid in learning. How do such errors in prediction interact with memory for the rewarding episode? Existing findings point to both cooperative and competitive interactions between learning and memory mechanisms. Here, we investigated whether learning about rewards in a high-risk context, with frequent, large prediction errors, would give rise to higher fidelity memory traces for rewarding events than learning in a low-risk context. Experiment 1 showed that recognition was better for items associated with larger absolute prediction errors during reward learning. Larger prediction errors also led to higher rates of learning about rewards. Interestingly we did not find a relationship between learning rate for reward and recognition-memory accuracy for items, suggesting that these two effects of prediction errors were caused by separate underlying mechanisms. In Experiment 2, we replicated these results with a longer task that posed stronger memory demands and allowed for more learning. We also showed improved source and sequence memory for items within the high-risk context. In Experiment 3, we controlled for the difficulty of reward learning in the risk environments, again replicating the previous results. Moreover, this control revealed that the high-risk context enhanced item-recognition memory beyond the effect of prediction errors. In summary, our results show that prediction errors boost both episodic item memory and incremental reward learning, but the two effects are likely mediated by distinct underlying systems.","link":"/opendata/rouhani-et-al-2018/"},{"title":"Rouhani & Niv (2021)","text":"Memory helps guide behavior, but which experiences from the past are prioritized? Classic models of learning posit that events associated with unpredictable outcomes as well as, paradoxically, predictable outcomes, deploy more attention and learning for those events. Here, we test reinforcement learning and subsequent memory for those events, and treat signed and unsigned reward prediction errors (RPEs), experienced at the reward-predictive cue or reward outcome, as drivers of these two seemingly contradictory signals. By fitting reinforcement learning models to behavior, we find that both RPEs contribute to learning by modulating a dynamically changing learning rate. We further characterize the effects of these RPE signals on memory and show that both signed and unsigned RPEs enhance memory, in line with midbrain dopamine and locus-coeruleus modulation of hippocampal plasticity, thereby reconciling separate findings in the literature.","link":"/opendata/rouhani-niv-2021/"},{"title":"Ruggeri et al. (2022)","text":"Economic inequality is associated with preferences for smaller, immediate gains over larger, delayed ones. Such temporal discounting may feed into rising global inequality, yet it is unclear whether it is a function of choice preferences or norms, or rather the absence of sufficient resources for immediate needs. It is also not clear whether these reflect true differences in choice patterns between income groups. We tested temporal discounting and five intertemporal choice anomalies using local currencies and value standards in 61 countries (N = 13,629). Across a diverse sample, we found consistent, robust rates of choice anomalies. Lower-income groups were not significantly different, but economic inequality and broader financial circumstances were clearly correlated with population choice patterns.","link":"/opendata/ruggeri-et-al-2022/"},{"title":"Rutledge et al. (2021)","text":"The subjective well-being or happiness of individuals is an important metric for societies. Although happiness is influenced by life circumstances and population demographics such as wealth, we know little about how the cumulative influence of daily life events are aggregated into subjective feelings. Using computational modeling, we show that emotional reactivity in the form of momentary happiness in response to outcomes of a probabilistic reward task is explained not by current task earnings, but by the combined influence of recent reward expectations and prediction errors arising from those expectations. The robustness of this account was evident in a large-scale replication involving 18,420 participants. Using functional MRI, we show that the very same influences account for task-dependent striatal activity in a manner akin to the influences underpinning changes in happiness.","link":"/opendata/rutledge-et-al-2021/"},{"title":"Rybicki et al. (2022)","text":"Some theories of human cultural evolution posit that humans have social-specific learning mechanisms that are adaptive specialisations moulded by natural selection to cope with the pressures of group living. However, the existence of neurochemical pathways that are specialised for learning from social information and individual experience is widely debated. Cognitive neuroscientific studies present mixed evidence for social-specific learning mechanisms: some studies find dissociable neural correlates for social and individual learning, whereas others find the same brain areas and, dopamine-mediated, computations involved in both. Here, we demonstrate that, like individual learning, social learning is modulated by the dopamine D2 receptor antagonist haloperidol when social information is the primary learning source, but not when it comprises a secondary, additional element. Two groups (total N = 43) completed a decision-making task which required primary learning, from own experience, and secondary learning from an additional source. For one group, the primary source was social, and secondary was individual; for the other group this was reversed. Haloperidol affected primary learning irrespective of social/individual nature, with no effect on learning from the secondary source. Thus, we illustrate that dopaminergic mechanisms underpinning learning can be dissociated along a primary-secondary but not a social-individual axis. These results resolve conflict in the literature and support an expanding field showing that, rather than being specialised for particular inputs, neurochemical pathways in the human brain can process both social and non-social cues and arbitrate between the two depending upon which cue is primarily relevant for the task at hand.","link":"/opendata/rybicki-et-al-2022/"},{"title":"Safra et al. (2019)","text":"Depression is characterized by a marked decrease in social interactions and blunted sensitivity to rewards. Surprisingly, despite the importance of social deficits in depression, non-social aspects have been disproportionally investigated. As a consequence, the cognitive mechanisms underlying atypical decision-making in social contexts in depression are poorly understood. In the present study, we investigate whether deficits in reward processing interact with the social context and how this interaction is affected by self-reported depression and anxiety symptoms in the general population. Two cohorts of subjects (discovery and replication sample: N = 50 each) took part in an experiment involving reward learning in contexts with different levels of social information (absent, partial and complete). Behavioral analyses revealed a specific detrimental effect of depressive symptoms-but not anxiety-on behavioral performance in the presence of social information, i.e. when participants were informed about the choices of another player. Model-based analyses further characterized the computational nature of this deficit as a negative audience effect, rather than a deficit in the way others choices and rewards are integrated in decision making. To conclude, our results shed light on the cognitive and computational mechanisms underlying the interaction between social cognition, reward learning and decision-making in depressive disorders.","link":"/opendata/safra-et-al-2019/"},{"title":"Salomon et al. (2022)","text":"Although research about preference formation and modification has classically focused on the role of external reinforcements, there is also increasing evidence for a key role of non-externally reinforced cognitive mechanisms such as attention and memory in preference modification. In a novel paradigm for behavioral change called the Cue-Approach training (CAT) task, preferences are modified via the mere association of images of stimuli with a neutral cue and a rapid motor response, without external reinforcements. The procedure’s efficacy has been replicated across dozens of studies, and the net behavioral change was linked with increased activity in a frontal value-based decision-making brain region during the post-training probe choice phase. However, the cognitive mechanisms during the training phase itself have not been elucidated. Based on the structure of the task alongside recent findings of the involvement of striatal and supplementary motor regions during training, we hypothesized that a motor-related learning process could be a prospective candidate. To test this hypothesis, we developed a computational model of the motor response pattern during training in a large corpus of data collected from 864 participants across 29 different CAT experiments. Using Bayesian modeling of the meta-analysis data, we developed a computational marker for individualized learning in the training task, which was found to be associated with the preference modification effect in the subsequent probe task, both at the participant-level as well as in the more granular individual-item level. Following the conclusions of the meta-analysis, in two additional experiments (a pilot study and a larger preregistered replication study) we aimed to affect learning efficacy by manipulating the training procedure difficulty. As hypothesized and preregistered, training difficulty was captured by the new computational marker identified on the previously collected samples. Manipulation of the training difficulty also resulted in a differential preference modification effect, suggesting a causal relationship between the motor learning captured by the computational model and the post-training behavioral change effect. Our work highlights a novel non-reinforced preference modification pathway, suggesting that attention and motor learning are linked to preference formation, and provides a computational framework to identify individualized training markers which could predict future behavioral change effects.","link":"/opendata/salomon-et-al-2022/"},{"title":"Schaaf et al. (2023)","text":"Recently it has been suggested that parameters estimates of computational models can be used to understand individual differences at the process level. One area of research in which this approach, called computational phenotyping, took hold is computational psychiatry, but it is also used to understand differences in age and personality. One requirement for successful computational phenotyping is that behavior and parameters are stable over time. Surprisingly, the test-retest reliability of behavior and model parameters remains unknown for most experimental tasks and models. The present study seeks to close this gap by investigating the test-retest reliability of canonical reinforcement learning models in the context of two often-used learning paradigms: a two-armed bandit and a reversal learning task. We tested independent cohorts for the two tasks (N=142 and N=154) via an online testing platform with a between-test interval of five weeks. Whereas reliability was high for personality and cognitive measures, it was generally poor for the parameter estimates of the reinforcement learning models. Given that simulations indicated that our procedures could detect high test-retest reliability, this suggests that a significant proportion of the variability must be ascribed to the participants themselves. In support of that hypothesis, we show that mood (stress and happiness) can partly explain within-subject variability. Taken together, these results are critical for current practices in computational phenotyping and suggest that individual variability should be taken into account in the future development of the field.","link":"/opendata/schaaf-et-al-2023/"},{"title":"Schöbel et al. (2016)","text":"People often make decisions in a social environment. The present work examines social influence on peoples decisions in a sequential decision-making situation. In the first experimental study, we implemented an information cascade paradigm, illustrating that people infer information from decisions of others and use this information to make their own decisions. We followed a cognitive modeling approach to elicit the weight people give to social as compared to private individual information. The proposed social influence model shows that participants overweight their own private information relative to social information, contrary to the normative Bayesian account. In our second study, we embedded the abstract decision problem of Study 1 in a medical decision-making problem. We examined whether in a medical situation people also take others authority into account in addition to the information that their decisions convey. The social influence model illustrates that people weight social information differentially according to the authority of other decision makers. The influence of authority was strongest when an authoritys decision contrasted with private information. Both studies illustrate how the social environment provides sources of information that people integrate differently for their decisions.","link":"/opendata/schobel-et-al-2016/"},{"title":"Scholl et al. (2022)","text":"Real-life decision-making often comprises sequences of successive decisions about whether to take opportunities as they are encountered or keep searching for better ones instead. We investigated individual differences related to such sequential decision-making and link them especially to apathy and compulsivity in a large online sample (discovery sample: n = 449 and confirmation sample: n = 756). Our cognitive model revealed distinct changes in the way participants evaluated their environments and planned their own future behaviour. Apathy was linked to decision inertia, i.e., automatically persisting with a sequence of searches for longer than appropriate given the value of searching. Thus, despite being less motivated, they did not avoid the effort associated with longer searches. In contrast, compulsivity was linked to self-reported insensitivity to the cost of continuing with a sequence of searches. The objective measures of behavioural cost insensitivity were clearly linked to compulsivity only in the discovery sample. While the confirmation sample showed a similar effect, it did not reach significance. Nevertheless, in both samples, participants reported awareness of such bias (experienced as overchasing). In addition, this awareness made them report preemptively avoiding situations related to the bias. However, we found no evidence of them actually preempting more in the task, which might mean a misalignment of their metacognitive beliefs or that our behavioural measures were incomplete. In summary, individual variation in distinct, fundamental aspects of sequential decision-making can be linked to variation in 2 measures of behavioural traits associated with psychological illness in the normal population.","link":"/opendata/scholl-et-al-2022/"},{"title":"Schubert et al. (2023)","text":"The rise of large-scale collaborative panel studies in educational psychology and cognitive neuroscience has generated a need for fast, reliable, and valid assessments of cognitive abilities. In these studies, a detailed characterization of participants’ cognitive abilities is often unnecessary. Tests are chosen based on their ease of use and the duration and feasibility of their administration. These demands often result in the use of abbreviated measures or even related proxies, potentially compromising the reliabilities and validities of those measures. The present study evaluates the usefulness of the mini-q (Baudson &amp; Preckel, 2016), a three-minute speeded reasoning test, as a brief assessment of general cognitive abilities in large-scale panel studies in a sample of 140 participants from diverse educational and occupational backgrounds. Participants’ test performance showed an excellent reliability and was substantially related (r = .57) to their general cognitive abilities measured with a broad test battery, supporting the test’s potential as a short screening of cognitive abilities. The largest share (54 %) of the relationship between test performance and general cognitive abilities was accounted for by participants’ working memory capacity, whereas individual differences in processing speed did not account for any part of the relationship between the two measures. Overall, our results support the notion that the mini-q can be used as a brief, reliable, and valid assessment of general cognitive abilities. However, possible disadvantages of participants with different native languages should be carefully considered due to the test’s reliance on verbal abilities.","link":"/opendata/schubert-et-al-2023/"},{"title":"Schultz et al. (2023)","text":"Reward improves memory through both encoding and consolidation processes. In this pre-registered study, we tested whether reward effects on memory generalize from rewarded items to unrewarded but episodically-related items. 59 human volunteers incidentally encoded associations between unique objects and repeated scenes. Some scenes typically yielded high reward, whereas others typically yielded low reward. Memory was tested immediately after encoding (n=29) or the next day (n=30). Overall, reward had only a limited influence on memory. It neither enhanced consolidation, nor did its effect generalize to episodically related stimuli. We thus contribute to understanding the boundary conditions of reward effects on memory.","link":"/opendata/schultz-et-al-2023/"},{"title":"Schulz et al. (2019)","text":"How do children and adults differ in their search for rewards? We considered three different hypotheses that attribute developmental differences to (a) children’s increased random sampling, (b) more directed exploration toward uncertain options, or (c) narrower generalization. Using a search task in which noisy rewards were spatially correlated on a grid, we compared the ability of 55 younger children (ages 7 and 8 years), 55 older children (ages 9-11 years), and 50 adults (ages 19-55 years) to successfully generalize about unobserved outcomes and balance the exploration-exploitation dilemma. Our results show that children explore more eagerly than adults but obtain lower rewards. We built a predictive model of search to disentangle the unique contributions of the three hypotheses of developmental differences and found robust and recoverable parameter estimates indicating that children generalize less and rely on directed exploration more than adults. We did not, however, find reliable differences in terms of random sampling.","link":"/opendata/schulz-et-al-2019/"},{"title":"Sedlinská et al. (2022)","text":"Pavlovian bias is an innate motivational tendency to approach rewards and remain passive in the face of punishment. The relative reliance on Pavlovian valuation has been found to increase when the perceived control over environmental reinforcers is compromised, leading to behavior resembling learned helplessness (LH). In our study, we used a version of an orthogonalized Go-NoGo reinforcement learning task to examine the relative reliance on Pavlovian and instrumental valuation during and after an intermittent loss of control over rewards and losses. Sixty healthy young adults underwent the task and received anodal high-definition transcranial direct current stimulation (HD-tDCS) over the medial prefrontal/ dorsal anterior cingulate cortex in a randomized, double-blind, sham-controlled study. Furthermore, we evaluated changes in cue-locked mid-frontal theta power derived from electroencephalography. We hypothesized that active stimulation would reduce Pavlovian bias during manipulation of outcome controllability, and the effect would be accompanied by stronger mid-frontal theta activity, representing arbitration between choice strategies in favor of instrumental relative to Pavlovian valuation. We found a progressive decrease in Pavlovian bias during and after the loss of control over feedback. Active HD-tDCS counteracted this effect while not affecting the mid-frontal theta signal. The results were at odds with our hypotheses but also with previous findings reporting LH-like patterns during and after the loss of control without brain stimulation. The discrepancy may be related to different protocols for the controllability manipulation. We argue that the subjective evaluation of task controllability is crucial in mediating the balance between Pavlovian and instrumental valuation during reinforcement learning and that the medial prefrontal/dorsal anterior cingulate cortex is a key region in this respect. These findings have implications for understanding the behavioral and neural underpinnings of LH in humans.","link":"/opendata/sedlinska-et-al-2022/"},{"title":"Seow et al. (2020)","text":"Alterations in error processing are implicated in a range of DSM-defined psychiatric disorders. For instance, obsessive-compulsive disorder (OCD) and generalised anxiety disorder show enhanced electrophysiological responses to errors-i.e. error-related negativity (ERN)-while others like schizophrenia have an attenuated ERN. However, as diagnostic categories in psychiatry are heterogeneous and also highly intercorrelated, the precise mapping of ERN enhancements/impairments is unclear. To address this, we recorded electroencephalograms (EEG) from 196 participants who performed the Flanker task and collected scores on 9 questionnaires assessing psychiatric symptoms to test if a dimensional framework could reveal specific transdiagnostic clinical manifestations of error processing dysfunctions. Contrary to our hypothesis, we found non-significant associations between ERN amplitude and symptom severity of OCD, trait anxiety, depression, social anxiety, impulsivity, eating disorders, alcohol addiction, schizotypy and apathy. A transdiagnostic approach did nothing to improve signal; there were non-significant associations between all three transdiagnostic dimensions (anxious-depression, compulsive behaviour and intrusive thought, and social withdrawal) and ERN magnitude. In these same individuals, we replicated a previously published transdiagnostic association between goal-directed learning and compulsive behaviour and intrusive thought. Possible explanations discussed are (i) that associations between the ERN and psychopathology might be smaller than previously assumed, (ii) that these associations might depend on a greater level of symptom severity than other transdiagnostic cognitive biomarkers, or (iii) that task parameters, such as the ratio of compatible to incompatible trials, might be crucial for ensuring the sensitivity of the ERN to clinical phenomena.","link":"/opendata/seow-et-al-2020/"},{"title":"Seow et al. (2021)","text":"Compulsive individuals have deficits in model-based planning, but the mechanisms that drive this have not been established. We examined two candidates-that compulsivity is linked to (1) an impaired model of the task environment and/or (2) an inability to engage cognitive control when making choices. To test this, 192 participants performed a two-step reinforcement learning task with concurrent EEG recordings, and we related the neural and behavioral data to their scores on a self-reported transdiagnostic dimension of compulsivity. To examine subjects’ internal model of the task, we used established behavioral and neural responses to unexpected events [reaction time (RT) slowing, P300 wave, and parietal-occipital alpha band power] measured when an unexpected transition occurred. To assess cognitive control, we probed theta power at the time of initial choice. As expected, model-based planning was linked to greater behavioral (RT) and neural (alpha power, but not P300) sensitivity to rare transitions. Critically, the sensitivities of both RT and alpha to task structure were weaker in those high in compulsivity. This RT-compulsivity effect was tested and replicated in an independent pre-existing dataset (N = 1413). We also found that mid-frontal theta power at the time of choice was reduced in highly compulsive individuals though its relation to model-based planning was less pronounced. These data suggest that model-based planning deficits in compulsive individuals may arise, at least in part, from having an impaired representation of the environment, specifically how actions lead to future states.","link":"/opendata/seow-et-al-2021/"},{"title":"Shahar et al. (2019)","text":"A well-established notion in cognitive neuroscience proposes that multiple brain systems contribute to choice behaviour. These include: (1) a model-free system that uses values cached from the outcome history of alternative actions, and (2) a model-based system that considers action outcomes and the transition structure of the environment. The widespread use of this distinction, across a range of applications, renders it important to index their distinct influences with high reliability. Here we consider the two-stage task, widely considered as a gold standard measure for the contribution of model-based and model-free systems to human choice. We tested the internal/temporal stability of measures from this task, including those estimated via an established computational model, as well as an extended model using drift-diffusion. Drift-diffusion modeling suggested that both choice in the first stage, and RTs in the second stage, are directly affected by a model-based/free trade-off parameter. Both parameter recovery and the stability of model-based estimates were poor but improved substantially when both choice and RT were used (compared to choice only), and when more trials (than conventionally used in research practice) were included in our analysis. The findings have implications for interpretation of past and future studies based on the use of the two-stage task, as well as for characterising the contribution of model-based processes to choice behaviour.","link":"/opendata/shahar-et-al-2019/"},{"title":"Sharp et al. (2022)","text":"Managing multiple goals is essential to adaptation, yet we are only beginning to understand computations by which we navigate the resource demands entailed in so doing. Here, we sought to elucidate how humans balance reward seeking and punishment avoidance goals, and relate this to variation in its expression within anxious individuals. To do so, we developed a novel multigoal pursuit task that includes trial-specific instructed goals to either pursue reward (without risk of punishment) or avoid punishment (without the opportunity for reward). We constructed a computational model of multigoal pursuit to quantify the degree to which participants could disengage from the pursuit goals when instructed to, as well as devote less model-based resources toward goals that were less abundant. In general, participants (n = 192) were less flexible in avoiding punishment than in pursuing reward. Thus, when instructed to pursue reward, participants often persisted in avoiding features that had previously been associated with punishment, even though at decision time these features were unambiguously benign. In a similar vein, participants showed no significant downregulation of avoidance when punishment avoidance goals were less abundant in the task. Importantly, we show preliminary evidence that individuals with chronic worry may have difficulty disengaging from punishment avoidance when instructed to seek reward. Taken together, the findings demonstrate that people avoid punishment less flexibly than they pursue reward. Future studies should test in larger samples whether a difficulty to disengage from punishment avoidance contributes to chronic worry.","link":"/opendata/sharp-et-al-2022/"},{"title":"Shin & Niv (2021)","text":"How do we evaluate a group of people after a few negative experiences with some members but mostly positive experiences otherwise? How do rare experiences influence our overall impression? We show that rare events may be overweighted due to normative inference of the hidden causes that are believed to generate the observed events. We propose a Bayesian inference model that organizes environmental statistics by combining similar events and separating outlying observations. Relying on the models inferred latent causes for group evaluation overweights rare or variable events. We tested the models predictions in eight experiments where participants observed a sequence of social or non-social behaviours and estimated their average. As predicted, estimates were biased toward sparse events when estimating after seeing all observations, but not when tracking a summary value as observations accrued. Our results suggest that biases in evaluation may arise from inferring the hidden causes of group members behaviours.","link":"/opendata/shin-niv-2021/"},{"title":"Sidarus et al. (2019)","text":"Value-based decision-making involves trading off the cost associated with an action against its expected reward. Research has shown that both physical and mental effort constitute such subjective costs, biasing choices away from effortful actions, and discounting the value of obtained rewards. Facing conflicts between competing action alternatives is considered aversive, as recruiting cognitive control to overcome conflict is effortful. Moreover, engaging control to proactively suppress irrelevant information that could conflict with task-relevant information would presumably also be cognitively costly. Yet, it remains unclear whether the cognitive control demands involved in preventing and resolving conflict also constitute costs in value-based decisions. The present study investigated this question by embedding irrelevant distractors (flanker arrows) within a reversal-learning task, with intermixed free and instructed trials. Results showed that participants learned to adapt their free choices to maximize rewards, but were nevertheless biased to follow the suggestions of irrelevant distractors. Thus, the perceived cost of investing cognitive control to suppress an external suggestion could sometimes trump internal value representations. By adapting computational models of reinforcement learning, we assessed the influence of conflict at both the decision and learning stages. Modelling the decision showed that free choices were more biased when participants were less sure about which action was more rewarding. This supports the hypothesis that the costs linked to conflict management were traded off against expected rewards. During the learning phase, we found that learning rates were reduced in instructed, relative to free, choices. Learning rates were further reduced by conflict between an instruction and subjective action values, whereas learning was not robustly influenced by conflict between ones actions and external distractors. Our results show that the subjective cognitive control costs linked to conflict factor into value-based decision-making, and highlight that different types of conflict may have different effects on learning about action outcomes.","link":"/opendata/sidarus-et-al-2019/"},{"title":"Simon-Kutscher et al. (2019)","text":"During a threatening encounter, people can learn to associate the aversive event with a discrete preceding cue or with the context in which the event took place, corresponding to cue-dependent and context-dependent fear conditioning, respectively. Which of these forms of fear learning prevails has critical implications for fear-related psychopathology. We tested here whether acute stress may modulate the balance of cue-dependent and contextual fear learning. Participants (N = 72) underwent a stress or control manipulation 30 min before they completed a fear-learning task in a virtual environment that allowed both cued and contextual fear learning. Results showed equally strong cue- and context-dependent fear conditioning in the control group. Stress, however, abolished contextual fear learning, which was directly correlated with the activity of the stress hormone cortisol, and made cue-dependent fear more resistant to extinction. These results are the first to show that stress favors cue-dependent over contextual fear learning.","link":"/opendata/simon-kutscher-et-al-2019/"},{"title":"Smid et al. (2022)","text":"Human decision-making is underpinned by distinct systems that differ in flexibility and associated cognitive cost. A widely accepted dichotomy distinguishes between a cheap but rigid model-free system and a flexible but costly model-based system. Typically, humans use a hybrid of both types of decision-making depending on environmental demands. However, childrens use of a model-based system during decision-making has not yet been shown. While prior developmental work has identified simple building blocks of model-based reasoning in young children (1-4 years old), there has been little evidence of this complex cognitive system influencing behavior before adolescence. Here, by using a modified task to make engagement in cognitively costly strategies more rewarding, we show that children aged 5-11-years (N = 85), including the youngest children, displayed multiple indicators of model-based decision making, and that the degree of its use increased throughout childhood. Unlike adults (N = 24), however, children did not display adaptive arbitration between model-free and model-based decision-making. Our results demonstrate that throughout childhood, children can engage in highly sophisticated and costly decision-making strategies. However, the flexible arbitration between decision-making strategies might be a critically late-developing component in human development.","link":"/opendata/smid-et-al-2022/"},{"title":"Smith & Pollak (2022)","text":"To effectively navigate their environments, infants and children learn how to recognize events predict salient outcomes, such as rewards or punishments. Relatively little is known about how children acquire this ability to attach value to the stimuli they encounter. Studies often examine childrens ability to learn about rewards and threats using either classical conditioning or behavioral choice paradigms. Here, we assess both approaches and find that they yield different outcomes in terms of which individuals had efficiently learned the value of information presented to them. The findings offer new insights into understanding how to assess different facets of value learning in children.","link":"/opendata/smith-pollak-2022/"},{"title":"Snijder et al. (2022)","text":"The domain of cognitive control has been a major focus of experimental, neuroscience, and individual differences research. Currently, however, no theory of cognitive control successfully unifies both experimental and individual differences findings. Some perspectives deny that there even exists a unified psychometric cognitive control construct to be measured at all. These shortcomings of the current literature may reflect the fact that current cognitive control paradigms are optimized for the detection of within-subject experimental effects rather than individual differences. In the current study, we examine the psychometric properties of the Dual Mechanisms of Cognitive Control (DMCC) task battery, which was designed in accordance with a theoretical framework that postulates common sources of within-subject and individual differences variation. We evaluated both internal consistency and test-retest reliability, and for the latter, utilized both classical test theory measures (i.e., split-half methods, intraclass correlation) and newer hierarchical Bayesian estimation of generative models. Although traditional psychometric measures suggested poor reliability, the hierarchical Bayesian models indicated a different pattern, with good to excellent test-retest reliability in almost all tasks and conditions examined. Moreover, within-task, between-condition correlations were generally increased when using the Bayesian model derived estimates, and these higher correlations appeared to be directly linked to the higher reliability of the measures. In contrast, between-task correlations remained low regardless of theoretical manipulations or estimation approach. Together, these findings highlight the advantages of Bayesian estimation methods, while also pointing to the important role of reliability in the search for a unified theory of cognitive control.","link":"/opendata/snijder-et-al-2022/"},{"title":"Solomyak et al. (2022)","text":"Many decision-making studies have demonstrated that humans learn either expected values or relative preferences among choice options, yet little is known about what environmental conditions promote one strategy over the other. Here, we test the novel hypothesis that humans adapt the degree to which they form absolute values to the diversity of the learning environment. Since absolute values generalize better to new sets of options, we predicted that the more options a person learns about the more likely they would be to form absolute values. To test this, we designed a multi-day learning experiment comprising twenty learning sessions in which subjects chose among pairs of images each associated with a different probability of reward. We assessed the degree to which subjects formed absolute values and relative preferences by asking them to choose between images they learned about in separate sessions. We found that concurrently learning about more images within a session enhanced absolute-value, and suppressed relative-preference, learning. Conversely, cumulatively pitting each image against a larger number of other images across multiple sessions did not impact the form of learning. These results show that the way humans encode preferences is adapted to the diversity of experiences offered by the immediate learning context.","link":"/opendata/solomyak-et-al-2022/"},{"title":"Song et al. (2022)","text":"Realistic and complex decision tasks often allow for many possible solutions. How do we find the correct one? Introspection suggests a process of trying out solutions one after the other until success. However, such methodical serial testing may be too slow, especially in environments with noisy feedback. Alternatively, the underlying learning process may involve implicit reinforcement learning that learns about many possibilities in parallel. Here we designed a multi-dimensional probabilistic active-learning task tailored to study how people learn to solve such complex problems. Participants configured three-dimensional stimuli by selecting features for each dimension and received probabilistic reward feedback. We manipulated task complexity by changing how many feature dimensions were relevant to maximizing reward, as well as whether this information was provided to the participants. To investigate how participants learn the task, we examined models of serial hypothesis testing, feature-based reinforcement learning, and combinations of the two strategies. Model comparison revealed evidence for hypothesis testing that relies on reinforcement-learning when selecting what hypothesis to test. The extent to which participants engaged in hypothesis testing depended on the instructed task complexity: people tended to serially test hypotheses when instructed that there were fewer relevant dimensions, and relied more on gradual and parallel learning of feature values when the task was more complex. This demonstrates a strategic use of task information to balance the costs and benefits of the two methods of learning.","link":"/opendata/song-et-al-2022/"},{"title":"Soutscheck et al. (2022)","text":"Deciding whether to engage in strenuous mental activities requires trading-off the potential benefits against the costs of mental effort, but it is unknown which brain rhythms are causally involved in such cost-benefit calculations. We show that brain stimulation targeting midfrontal theta oscillations increases the engagement in goal-directed mental effort. Participants received transcranial alternating current stimulation over dorsomedial prefrontal cortex while deciding whether they are willing to perform a demanding working memory task for monetary rewards. Midfrontal theta tACS increased the willingness to exert mental effort for rewards while leaving working memory performance unchanged. Computational modelling using a hierarchical Bayesian drift diffusion model suggests that theta tACS shifts the starting bias before evidence accumulation towards high reward-high effort options without affecting the velocity of the evidence accumulation process. Our findings suggest that the motivation to engage in goal-directed mental effort can be increased via midfrontal tACS.","link":"/opendata/soutscheck-et-al-2022/"},{"title":"Spektor et al. (2022)","text":"People rely on the choice context to guide their decisions, violating fundamental principles of rational choice theory and exhibiting phenomena called context effects. Recent research has uncovered that dominance relationships can both increase or decrease the choice share of the dominating option, marking the two ends of an attraction-repulsion continuum. However, empirical links between the two opposing effects are scarce and theoretical accounts are missing altogether. The present study (N = 55) used eye tracking alongside a within-subject design that contrasts a perceptual task and a preferential-choice analog in order to bridge this gap and uncover the underlying information-search processes. Although individuals differed in their perceptual and preferential choices, they generally engaged in alternative-wise comparisons and a repulsion effect was present in both conditions that became weaker the more predominant the attribute-wise comparisons were. Altogether, our study corroborates the notion that repulsion effects are a robust and general phenomenon that theoretical accounts need to take seriously.","link":"/opendata/spektor-et-al-2022/"},{"title":"Spicer et al. (2022)","text":"One of the most robust effects in cognitive psychology is anchoring, in which judgments show a bias toward previously viewed values. However, in what is essentially the same task as used in anchoring research, a perceptual illusion demonstrates the opposite effect of repulsion. Here, we united these two literatures, testing in two experiments with adults (total N = 200) whether prior comparative decisions bias cognitive and perceptual judgments in opposing directions or whether anchoring and repulsion are two domain-general biases whose co-occurrence has so far gone undetected. We found that in both perceptual and cognitive tasks, anchoring and repulsion co-occur. Further, the direction of the bias depends on the comparison value: Distant values attract judgments, whereas nearby values repulse judgments. Because none of the leading theories for either effect account for both biases, theoretical integration is needed. As a starting point, we describe one such joint theory based on sampling models of cognition.","link":"/opendata/spicer-et-al-2022/"},{"title":"Steiner & Frey (2021)","text":"Representative design refers to the idea that experimental stimuli should be sampled or designed such that they represent the environments to which measured constructs are supposed to generalize. In this article we investigate the role of representative design in achieving valid and reliable psychological assessments, by focusing on a widely used behavioral measure of risk taking-the Balloon Analogue Risk Task (BART). Specifically, we demonstrate that the typical implementation of this task violates the principle of representative design, thus conflicting with the expectations people likely form from real balloons. This observation may provide an explanation for the previously observed limitations in some of the BARTs psychometric properties (e.g., convergent validity with other measures of risk taking). To experimentally test the effects of improved representative designs, we conducted two extensive empirical studies (N = 772 and N = 632), finding that participants acquired more accurate beliefs about the optimal behavior in the BART because of these task adaptions. Yet, improving the tasks representativeness proved to be insufficient to enhance the BARTs psychometric properties. It follows that for the development of valid behavioral measurement instruments-as are needed, for instance, in functional neuroimaging studies-our field has to overcome the philosophy of the repair program (i.e., fixing existing tasks). Instead, we suggest that the development of valid task designs requires novel ecological assessments, aimed at identifying those real-life behaviors and associated psychological processes that lab tasks are supposed to capture and generalize to.","link":"/opendata/steiner-frey-2021/"},{"title":"Stevenson et al. (2022)","text":"Decision-making behavior is often understood using the framework of evidence accumulation models (EAMs). Nowadays, EAMs are applied to various domains of decision-making with the underlying assumption that the latent cognitive constructs proposed by EAMs are consistent across these domains. In this study we investigate both the extent to which the parameters of EAMs are related between four different decision-making domains and across different time points. To that end, we make use of the novel joint modelling approach, that explicitly includes relationships between parameters, such as covariances or underlying factors, in one combined joint model. Consequently, this joint model also accounts for measurement error and uncertainty within the estimation of these relations. We found that EAM parameters were consistent between time points on three of the four decision-making tasks. For our between-task analysis we constructed a joint model with a factor analysis on the parameters of the different tasks. Our two factor joint model indicated that information processing ability was related between the different decision-making domains. However, other cognitive constructs such as the degree of response caution and urgency were only comparable on some domains.","link":"/opendata/stevenson-et-al-2022/"},{"title":"Stojić et al. (2020)","text":"Uncertainty plays a critical role in reinforcement learning and decision making. However, exactly how it influences behavior remains unclear. Multiarmed-bandit tasks offer an ideal test bed, since computational tools such as approximate Kalman filters can closely characterize the interplay between trial-by-trial values, uncertainty, learning, and choice. To gain additional insight into learning and choice processes, we obtained data from subjects overt allocation of gaze. The estimated value and estimation uncertainty of options influenced what subjects looked at before choosing; these same quantities also influenced choice, as additionally did fixation itself. A momentary measure of uncertainty in the form of absolute prediction errors determined how long participants looked at the obtained outcomes. These findings affirm the importance of uncertainty in multiple facets of behavior and help delineate its effects on decision making.","link":"/opendata/stojic-et-al-2020/"},{"title":"Stuppy-Sullivan et al. (2020)","text":"Aberrant cost–benefit decision making is a key factor related to individual differences in the expression of substance use disorders (SUDs). Previous research highlights how delay-cost sensitivity affects variability in SUDs; however, other forms of cost–benefit decision making—effort-based choice—have received less attention. We administered the Effort Expenditure for Rewards Task (EEfRT) in an SUD-enriched community sample (N = 80). Individuals with more severe SUDs were less likely to use information about expected value when deciding between high-effort, high-reward and low-effort, low-reward options. Furthermore, individuals whose severity of use was primarily related to avoiding aversive affective states and individuals with heightened sensitivity to delay costs during intertemporal decision making were the least sensitive to expected value signals when making decisions to engage in effortful behavior. Together, these findings suggest that individuals with more severe SUDs have difficulty integrating multiple decision variables to guide behavior during effort-based decision making.","link":"/opendata/stuppy-sullivan-et-al-2020/"},{"title":"Sugawara & Katahira (2021)","text":"The learning rate is a key parameter in reinforcement learning that determines the extent to which novel information (outcome) is incorporated in guiding subsequent actions. Numerous studies have reported that the magnitude of the learning rate in human reinforcement learning is biased depending on the sign of the reward prediction error. However, this asymmetry can be observed as a statistical bias if the fitted model ignores the choice autocorrelation (perseverance), which is independent of the outcomes. Therefore, to investigate the genuine process underlying human choice behavior using empirical data, one should dissociate asymmetry in learning and perseverance from choice behavior. The present study addresses this issue by using a Hybrid model incorporating asymmetric learning rates and perseverance. First, by conducting simulations, we demonstrate that the Hybrid model can identify the true underlying process. Second, using the Hybrid model, we show that empirical data collected from a web-based experiment are governed by perseverance rather than asymmetric learning. Finally, we apply the Hybrid model to two open datasets in which asymmetric learning was reported. As a result, the asymmetric learning rate was validated in one dataset but not another.","link":"/opendata/sugawara-katahira-2021/"},{"title":"Suthaharan et al. (2021)","text":"The COVID-19 pandemic has made the world seem less predictable. Such crises can lead people to feel that others are a threat. Here, we show that the initial phase of the pandemic in 2020 increased individuals paranoia and made their belief updating more erratic. A proactive lockdown made peoples belief updating less capricious. However, state-mandated mask-wearing increased paranoia and induced more erratic behaviour. This was most evident in states where adherence to mask-wearing rules was poor but where rule following is typically more common. Computational analyses of participant behaviour suggested that people with higher paranoia expected the task to be more unstable. People who were more paranoid endorsed conspiracies about mask-wearing and potential vaccines and the QAnon conspiracy theories. These beliefs were associated with erratic task behaviour and changed priors. Taken together, we found that real-world uncertainty increases paranoia and influences laboratory task behaviour.","link":"/opendata/suthaharan-et-al-2021/"},{"title":"Swart et al. (2017)","text":"Catecholamines modulate the impact of motivational cues on action. Such motivational biases have been proposed to reflect cue-based, Pavlovian effects. Here, we assess whether motivational biases may also arise from asymmetrical instrumental learning of active and passive responses following reward and punishment outcomes. We present a novel paradigm, allowing us to disentangle the impact of reward and punishment on instrumental learning from Pavlovian response biasing. Computational analyses showed that motivational biases reflect both Pavlovian and instrumental effects: reward and punishment cues promoted generalized (in)action in a Pavlovian manner, whereas outcomes enhanced instrumental (un)learning of chosen actions. These cue- and outcome-based biases were altered independently by the catecholamine enhancer melthylphenidate. Methylphenidates effect varied across individuals with a putative proxy of baseline dopamine synthesis capacity, working memory span. Our study uncovers two distinct mechanisms by which motivation impacts behaviour, and helps refine current models of catecholaminergic modulation of motivated action.","link":"/opendata/swart-et-al-2017/"},{"title":"Swart et al. (2018)","text":"Motivation exerts control over behavior by eliciting Pavlovian responses, which can either match or conflict with instrumental action. We can overcome maladaptive motivational influences putatively through frontal cognitive control. However, the neurocomputational mechanisms subserving this control are unclear; does control entail up-regulating instrumental systems, down-regulating Pavlovian systems, or both? We combined electroencephalography (EEG) recordings with a motivational Go/NoGo learning task (N = 34), in which multiple Go options enabled us to disentangle selective action learning from nonselective Pavlovian responses. Midfrontal theta-band (4 Hz-8 Hz) activity covaried with the level of Pavlovian conflict and was associated with reduced Pavlovian biases rather than reduced instrumental learning biases. Motor and lateral prefrontal regions synchronized to the midfrontal cortex, and these network dynamics predicted the reduction of Pavlovian biases over and above local, midfrontal theta activity. This work links midfrontal processing to detecting Pavlovian conflict and highlights the importance of network processing in reducing the impact of maladaptive, Pavlovian biases.","link":"/opendata/swart-et-al-2018/"},{"title":"Szücs et al. (2022)","text":"Rivalry and admiration-seeking are two distinct strategies humans use to gain status in social competition. However in vivo data is lacking about whether these behavioral manifestations of status pursuit are driven by distinct rivalry and admiration-seeking traits, as outlined by the Narcissistic Admiration and Rivalry Concept (NARC), whether NARC traits interact with environmental cues as suggested by the Status Pursuit In Narcissism (SPIN) model, and whether these interactions primarily occur with trait-relevant cues (defeat in the case of trait rivalry and victory in the case of trait admiration-seeking) as proposed by Trait activation theory (TAT). We used a rigged video game tournament with three randomized blocks with defeat manipulations of varying intensity: defeats to victory ratios of 1:1 (neutral), 2:1 (moderate losing), and 3:1 (extreme losing), measuring behavioral rivalry (stealing points from opponents) and admiration-seeking (paying to boost rank in the tournament) in a sample of 434 undergraduates assessed for trait rivalry and trait admiration-seeking with the Narcissistic Admiration and Rivalry Questionnaire. We found evidence for trait-congruent main and interaction effects: whereas behavioral rivalry scaled with trait rivalry and behavioral admiration-seeking with trait admiration-seeking, trait rivalry primarily increased status-pursuit behaviors following defeats and trait admiration-seeking following victories. These results corroborate the NARC’s two-dimensional conceptualization of narcissistic grandiosity, support the SPIN model’s interactionist view of status pursuit, and extend these frameworks by outlining trait-specific environmental effects consistent with TAT.","link":"/opendata/szucs-et-al-2022/"},{"title":"Tarantola et al. (2017)","text":"Our personal preferences affect a broad array of social behaviors. This includes the way we learn the preferences of others, an ability that often relies on limited or ambiguous information. Here we report an egocentric influence on this type of social learning that is reflected in both performance and response times. Using computational models that combine inter-trial learning and intra-trial choice, we find transient effects of participants preferences on the learning process, through the influence of priors, and persistent effects on the choice process. A second experiment shows that these effects generalize to non-social learning, though participants in the social learning experiment appeared to additionally benefit by using their knowledge about the popularity of certain preferences. We further find that the domain-general egocentric influences we identify can yield performance advantages in uncertain environments.People often assume that other people share their preferences, but how exactly this bias manifests itself in learning and decision-making is unclear. Here, authors show that a persons own preferences influence learning in both social and non-social situations, and that this bias improves performance.","link":"/opendata/tarantola-et-al-2017/"},{"title":"Tashjian et al. (2022)","text":"Protection often involves the capacity to prospectively plan the actions needed to mitigate harm. The computational architecture of decisions involving protection remains unclear, as well as whether these decisions differ from other beneficial prospective actions such as reward acquisition. Here we compare protection acquisition to reward acquisition and punishment avoidance to examine overlapping and distinct features across the three action types. Protection acquisition is positively valenced similar to reward. For both protection and reward, the more the actor gains, the more benefit. However, reward and protection occur in different contexts, with protection existing in aversive contexts. Punishment avoidance also occurs in aversive contexts, but differs from protection because punishment is negatively valenced and motivates avoidance. Across three independent studies (Total N = 600) we applied computational modeling to examine model-based reinforcement learning for protection, reward, and punishment in humans. Decisions motivated by acquiring protection evoked a higher degree of model-based control than acquiring reward or avoiding punishment, with no significant differences in learning rate. The context-valence asymmetry characteristic of protection increased deployment of flexible decision strategies, suggesting model-based control depends on the context in which outcomes are encountered as well as the valence of the outcome.","link":"/opendata/tashjian-et-al-2022/"},{"title":"Tavoni et al. (2022)","text":"We must often infer latent properties of the world from noisy and changing observations. Complex, probabilistic approaches to this challenge such as Bayesian inference are accurate but cognitively demanding, relying on extensive working memory and adaptive processing. Simple heuristics are easy to implement but may be less accurate. What is the appropriate balance between complexity and accuracy? Here we model a hierarchy of strategies of variable complexity and find a power law of diminishing returns: increasing complexity gives progressively smaller gains in accuracy. The rate of diminishing returns depends systematically on the statistical uncertainty in the world, such that complex strategies do not provide substantial benefits over simple ones when uncertainty is either too high or too low. In between, there is a complexity dividend. In two psychophysical experiments, we confirm specific model predictions about how working memory and adaptivity should be modulated by uncertainty.","link":"/opendata/tavoni-et-al-2022/"},{"title":"Teicher & Parigger (2015)","text":"There is increasing interest in childhood maltreatment as a potent stimulus that may alter trajectories of brain development, induce epigenetic modifications and enhance risk for medical and psychiatric disorders. Although a number of useful scales exist for retrospective assessment of abuse and neglect they have significant limitations. Moreover, they fail to provide detailed information on timing of exposure, which is critical for delineation of sensitive periods. The Maltreatment and Abuse Chronology of Exposure (MACE) scale was developed in a sample of 1051 participants using item response theory to gauge severity of exposure to ten types of maltreatment (emotional neglect, non-verbal emotional abuse, parental physical maltreatment, parental verbal abuse, peer emotional abuse, peer physical bullying, physical neglect, sexual abuse, witnessing interparental violence and witnessing violence to siblings) during each year of childhood. Items included in the subscales had acceptable psychometric properties based on infit and outfit mean square statistics, and each subscale passed Andersen’s Likelihood ratio test. The MACE provides an overall severity score and multiplicity score (number of types of maltreatment experienced) with excellent test-retest reliability. Each type of maltreatment showed good reliability as did severity of exposure across each year of childhood. MACE Severity correlated 0.738 with Childhood Trauma Questionnaire (CTQ) score and MACE Multiplicity correlated 0.698 with the Adverse Childhood Experiences scale (ACE). However, MACE accounted for 2.00- and 2.07-fold more of the variance, on average, in psychiatric symptom ratings than CTQ or ACE, respectively, based on variance decomposition. Different types of maltreatment had distinct and often unique developmental patterns. The 52-item MACE, a simpler Maltreatment Abuse and Exposure Scale (MAES) that only assesses overall exposure and the original test instrument (MACE-X) with several additional items plus spreadsheets and R code for scoring are provided to facilitate use and to spur further development.","link":"/opendata/teicher-parigger-2015/"},{"title":"Teoh & Hutcherson (2022)","text":"Time pressure is a powerful experimental manipulation frequently used to arbitrate between competing dual-process models of prosocial decision-making, which typically assume that automatic responses yield to deliberation over time. However, the use of time pressure has led to conflicting conclusions about the psychological dynamics of prosociality. Here, we proposed that flexible, context-sensitive information search, rather than automatic responses, underlies these divergent effects of time pressure on prosociality. We demonstrated in two preregistered studies (N = 304 adults from the United States and Canada; Prolific Academic) that different prosocial contexts (i.e., pure altruism vs. cooperation) have distinct effects on information search, driving people to prioritize information differently, particularly under time pressure. Furthermore, these information priorities subsequently influence prosocial choices, accounting for the different effects of time pressure in altruistic and cooperative contexts. These findings help explain existing inconsistencies in the field by emphasizing the role of dynamic context-sensitive information search during social decision-making, particularly under time pressure.","link":"/opendata/teoh-hutcherson-2022/"},{"title":"Thomas et al. (2019)","text":"How do we make simple choices such as deciding between an apple and an orange? Recent empirical evidence suggests that choice behaviour and gaze allocation are closely linked at the group level, whereby items looked at longer during the decision-making process are more likely to be chosen. However, it is unclear how variable this gaze bias effect is between individuals. Here we investigate this question across four different simple choice experiments and using a computational model that can be easily applied to individuals. We show that an association between gaze and choice is present for most individuals, but differs considerably in strength. Generally, individuals with a strong association between gaze and choice behaviour are worse at choosing the best item from a choice set compared with individuals with a weak association. Accounting for individuals variability in gaze bias in the model can explain and accurately predict individual differences in choice behaviour.","link":"/opendata/thomas-et-al-2019/"},{"title":"Thyer et al. (2022)","text":"Past work has shown that storage in working memory elicits stimulus-specific neural activity that tracks the stored content. Here, we present evidence for a distinct class of load-sensitive neural activity that indexes items without representing their contents per se. We recorded electroencephalogram (EEG) activity while adult human subjects stored varying numbers of items in visual working memory. Multivariate analysis of the scalp topography of EEG voltage enabled precise tracking of the number of individuated items stored and robustly predicted individual differences in working memory capacity. Critically, this signature of working memory load generalized across variations in both the type and number of visual features stored about each item, suggesting that it tracked the number of individuated memory representations and not the content of those memories. We hypothesize that these findings reflect the operation of a capacity-limited pointer system that supports on-line storage and attentive tracking.","link":"/opendata/thyer-et-al-2022/"},{"title":"Tomov et al. (2021)","text":"The ability to transfer knowledge across tasks and generalize to novel ones is an important hallmark of human intelligence. Yet not much is known about human multitask reinforcement learning. We study participants behaviour in a two-step decision-making task with multiple features and changing reward functions. We compare their behaviour with two algorithms for multitask reinforcement learning, one that maps previous policies and encountered features to new reward functions and one that approximates value functions across tasks, as well as to standard model-based and model-free algorithms. Across three exploratory experiments and a large preregistered confirmatory experiment, our results provide evidence that participants who are able to learn the task use a strategy that maps previously learned policies to novel scenarios. These results enrich our understanding of human reinforcement learning in complex environments with changing task demands.","link":"/opendata/tomov-et-al-2021/"},{"title":"Turan et al. (2023)","text":"Generating predictions about environmental regularities, relying on these predictions, and updating these predictions when there is a violation from incoming sensory evidence are considered crucial functions of our cognitive system for being adaptive in the future. The violation of a prediction can result in a prediction error (PE) which affects subsequent memory processing. In our preregistered studies, we examined the effects of different levels of PE on episodic memory. Participants were asked to generate predictions about the associations between sequentially presented cue-target pairs, which were violated later with individual items in three PE levels, namely low, medium, and high PE. Hereafter, participants were asked to provide old/new judgments on the items with confidence ratings, and to retrieve the paired cues. Our results indicated a better recognition memory for low PE than medium and high PE levels, suggesting a memory congruency effect. On the other hand, there was no evidence of memory benefit for high PE level. Together, these novel and coherent findings strongly suggest that high PE does not guarantee better memory.","link":"/opendata/turan-et-al-2023/"},{"title":"Turi et al. (2017)","text":"According to the placebo-reward hypothesis, placebo is a reward-anticipation process that increases midbrain dopamine (DA) levels. Reward-based learning processes, such as reinforcement learning, involves a large part of the DA-ergic network that is also activated by the placebo intervention. Given the neurochemical overlap between placebo and reward learning, we investigated whether verbal instructions in conjunction with a placebo intervention are capable of enhancing reward learning in healthy individuals by using a monetary reward-based reinforcement-learning task. Placebo intervention was performed with non-invasive brain stimulation techniques. In a randomized, triple-blind, cross-over study we investigated this cognitive placebo effect in healthy individuals by manipulating the participants perceived uncertainty about the interventions efficacy. Volunteers in the purportedly low- and high-uncertainty conditions earned more money, responded more quickly and had a higher learning rate from monetary rewards relative to baseline. Participants in the purportedly high-uncertainty conditions showed enhanced reward learning, and a model-free computational analysis revealed a higher learning rate from monetary rewards compared to the purportedly low-uncertainty and baseline conditions. Our results indicate that the placebo response is able to enhance reward learning in healthy individuals, opening up exciting avenues for future research in placebo effects on other cognitive functions.","link":"/opendata/turi-et-al-2017/"},{"title":"Unger & Sloutsky (2022)","text":"Our knowledge of the world is populated with categories such as dogs, cups, and chairs. Such categories shape how we perceive, remember, and reason about their members. Much of our exposure to the entities we come to categorize occurs incidentally as we experience and interact with them in our everyday lives, with limited access to explicit teaching. This research investigated whether incidental exposure contributes to building category knowledge by rendering people “ready to learn”-allowing them to rapidly capitalize on brief access to explicit teaching. Across five experiments (N = 438 adults), we found that incidental exposure did produce a ready-to-learn effect, even when learners showed no evidence of robust category learning during exposure. Importantly, this readiness to learn occurred only when categories possessed a rich structure in which many features were correlated within categories. These findings offer a window into how our everyday experiences may contribute to building category knowledge.","link":"/opendata/unger-sloutsky-2022/"},{"title":"Urai et al. (2017)","text":"While judging their sensory environments, decision-makers seem to use the uncertainty about their choices to guide adjustments of their subsequent behaviour. One possible source of these behavioural adjustments is arousal: decision uncertainty might drive the brains arousal systems, which control global brain state and might thereby shape subsequent decision-making. Here, we measure pupil diameter, a proxy for central arousal state, in human observers performing a perceptual choice task of varying difficulty. Pupil dilation, after choice but before external feedback, reflects three hallmark signatures of decision uncertainty derived from a computational model. This increase in pupil-linked arousal boosts observers tendency to alternate their choice on the subsequent trial. We conclude that decision uncertainty drives rapid changes in pupil-linked arousal state, which shape the serial correlation structure of ongoing choice behaviour.","link":"/opendata/urai-et-al-2017/"},{"title":"van Baar et al. (2021)","text":"Predicting the behaviour of others is an essential part of social cognition. Despite its ubiquity, social prediction poses a poorly understood generalization problem: we cannot assume that others will repeat past behaviour in new settings or that their future actions are entirely unrelated to the past. We demonstrate that humans solve this challenge using a structure learning mechanism that uncovers other peoples latent, unobservable motives, such as greed and risk aversion. In four studies, participants (N = 501) predicted other players decisions across four economic games, each with different social tensions (for example, Prisoners Dilemma and Stag Hunt). Participants achieved accurate social prediction by learning the stable motivational structure underlying a players changing actions across games. This motive-based abstraction enabled participants to attend to information diagnostic of the players next move and disregard irrelevant contextual cues. Participants who successfully learned anothers motives were more strategic in a subsequent competitive interaction with that player in entirely new contexts, reflecting that social structure learning supports adaptive social behaviour.","link":"/opendata/van-baar-et-al-2021/"},{"title":"Vandendriessche et al. (2022)","text":"Value-based decision-making impairment in depression is a complex phenomenon: while some studies did find evidence of blunted reward learning and reward-related signals in the brain, others indicate no effect. Here we test whether such reward sensitivity deficits are dependent on the overall value of the decision problem. We used a two-armed bandit task with two different contexts: one rich, one poor where both options were associated with an overall positive, negative expected value, respectively. We tested patients (N = 30) undergoing a major depressive episode and age, gender and socio-economically matched controls (N = 26). Learning performance followed by a transfer phase, without feedback, were analyzed to distangle between a decision or a value-update process mechanism. Finally, we used computational model simulation and fitting to link behavioral patterns to learning biases. Control subjects showed similar learning performance in the rich and the poor contexts, while patients displayed reduced learning in the poor context. Analysis of the transfer phase showed that the context-dependent impairment in patients generalized, suggesting that the effect of depression has to be traced to the outcome encoding. Computational model-based results showed that patients displayed a higher learning rate for negative compared to positive outcomes (the opposite was true in controls). Our results illustrate that reinforcement learning performances in depression depend on the value of the context. We show that depressive patients have a specific trouble in contexts with an overall negative state value, which in our task is consistent with a negativity bias at the learning rates level.","link":"/opendata/vandendriessche-et-al-2022/"},{"title":"van Timmeren et al. (2022)","text":"Despite our familiarity with the concept of habits, eliciting and measuring habits experimentally in humans has proven to be difficult. A possible explanation is that participants in psychological experiments actively recruit goal-directed control and therefore make few habitual slips-of-action in the presence of stimuli signalling devalued outcomes. In the current experiment we used the symmetrical outcome-revaluation task in combination with a working memory load in an attempt to tip the balance from goal-directed control to stimulus-response habit. During the instrumental learning phase, participants learned to make a Go response to stimuli signalling valuable outcomes (and points) while not responding (NoGo) to stimuli signalling not-valuable outcomes. During the subsequent test phase, the outcomes signalled by the stimuli were either value-congruent with training (still-valuable and still-not-valuable), or value-incongruent (devalued and upvalued). Participants had to flexibly adjust their behaviour on value-incongruent trials where the stimulus-response association learned during training was no longer appropriate. For half the participants, a concurrent working memory load was imposed during the test phase. In line with our preregistered hypotheses, participants showed evidence for habitual slips-of-action but those under working memory load showed increased habit tendencies (specifically failures to inhibit prepotent Go responses in the presence of stimuli signalling devalued outcomes). This central finding suggests that a working memory load can be used to reveal habits in humans.","link":"/opendata/van-timmeren-et-al-2022/"},{"title":"Verdejo-Garcia et al. (2021)","text":"Impulsive behaviours are a major contributor to the global burden of disease, but existing measures of cognitive impulsivity have suboptimal reliability and validity. Here, we introduce the Cognitive Impulsivity Suite, comprising three computerized/online tasks using a gamified interface. We conceptualize rapid-response impulsive behaviours (disinhibition) as arising from the failure of three distinct cognitive mechanisms: attentional control, information gathering and monitoring/shifting. We demonstrate the construct and criterion validity of the Cognitive Impulsivity Suite in an online community sample (N = 1,056), show test-retest reliability and between-subjects variability in a face-to-face community sample (N = 63), and replicate the results in a community and clinical sample (N = 578). The results support the theoretical architecture of the attentional control, information gathering and monitoring/shifting constructs. The Cognitive Impulsivity Suite demonstrated incremental criterion validity for prediction of real-world, addiction-related problems and is a promising tool for large-scale research on cognitive impulsivity.","link":"/opendata/verdejo-garcia-et-al-2021/"},{"title":"Vieira & Olsson (2022)","text":"Empathy for others distress has long been considered the driving force of helping. However, when deciding to help others in danger, one must consider not only their distress, but also the risk to oneself. Whereas the role of self-defense in helping has been overlooked in human research, studies in other animals indicate defensive responses are necessary for the protection of conspecifics. In this pre-registered study (N=49), we demonstrate that human defensive neural circuits are implicated in helping others under threat. Participants underwent fMRI scanning while deciding whether to help another participant avoid aversive electrical shocks, at the risk of also being shocked. We found that higher engagement of neural circuits that coordinate fast escape from self-directed danger (including the insula, PAG, and ACC) facilitated decisions to help others. Importantly, using representational similarity analysis, we found that the strength with which the amygdala and insula uniquely represented the threat to oneself (and not the others distress) predicted helping. Our findings indicate that in humans, as other mammals, defensive mechanisms play a greater role in helping behavior than previously understood.","link":"/opendata/vieira-olsson-2022/"},{"title":"Vilgis et al. (2022)","text":"Working memory deficits are common in attention-deficit/hyperactivity disorder (ADHD) and depression-two common neurodevelopmental disorders with overlapping cognitive profiles but distinct clinical presentation. Multivariate techniques have previously been utilized to understand working memory processes in functional brain networks in healthy adults but have not yet been applied to investigate how working memory processes within the same networks differ within typical and atypical developing populations. We used multivariate pattern analysis (MVPA) to identify whether brain networks discriminated between spatial versus verbal working memory processes in ADHD and Persistent Depressive Disorder (PDD). Thirty-six male clinical participants and 19 typically developing (TD) boys participated in a fMRI scan while completing a verbal and a spatial working memory task. Within a priori functional brain networks (frontoparietal, default mode, salience), the TD group demonstrated differential response patterns to verbal and spatial working memory. The PDD group showed weaker differentiation than TD, with lower classification accuracies observed in primarily the left frontoparietal network. The neural profiles of the ADHD and PDD differed specifically in the SN where the ADHD groups neural profile suggests significantly less specificity in neural representations of spatial and verbal working memory. We highlight within-group classification as an innovative tool for understanding the neural mechanisms of how cognitive processes may deviate in clinical disorders, an important intermediary step towards improving translational psychiatry.","link":"/opendata/vilgis-et-al-2022/"},{"title":"Visalli et al. (2022)","text":"Evidence is discordant regarding how emotional processing and cognitive control interact to shape behavior. This study sought to examine this interaction by looking at the distinction between proactive and reactive modes of control and how they relate with emotional processing. Seventy-four healthy participants performed an emotional priming Stroop task. On each trial, target stimuli of a spatial Stroop task were preceded by sad or neutral facial expressions, providing two emotional conditions. To manipulate the requirement of both proactive and reactive control, the proportion of congruent trials (PC) was varied at the list-wide (LWPC) and item-specific (ISPC) levels, respectively. We found that sad priming led to behavioral costs only in trials with low proactive and reactive cognitive control exertion. Our findings suggest that emotional processing affects processing stages other than cognitive control in the Stroop task. Moreover, both proactive and reactive control modes seem effective in overcoming emotional interference of priming stimuli.","link":"/opendata/visalli-et-al-2022/"},{"title":"von Clarenau et al. (2022)","text":"People routinely make decisions based on samples of numerical values. A common conclusion from the literature in psychophysics and behavioral economics is that observers subjectively compress magnitudes, such that extreme values have less sway over choice than prescribed by a normative model (underweighting). However, recent studies have reported evidence for anti-compression, that is, the relative overweighting of extreme values. Here, we investigate potential reasons for this discrepancy in findings and examine the possibility that it reflects adaptive responses to different task requirements. We performed a large-scale study (N = 607) of sequential numerical integration, manipulating (i) the task requirement (averaging a single stream or comparing two streams of numbers), (ii) the distribution of sample values (uniform or Gaussian), and (iii) their range (1 to 9 or 100 to 900). The data showed compression of subjective values in the averaging task, but anti-compression in the comparison task. This pattern held for both distribution types and for both ranges. The findings are consistent with model simulations showing that either compression or anti-compression can be beneficial for noisy observers, depending on the sample-level processing demands imposed by the task.","link":"/opendata/von-clarenau-et-al-2022/"},{"title":"Voulgaropoulou et al. (2022)","text":"Humans are continuously exposed to stressful challenges in everyday life. Such stressful events trigger a complex physiological reaction - the fight-or-flight response - that can hamper flexible decision-making and learning. Inspired by key neural and peripheral characteristics of the fight-or-flight response, here, we ask whether acute stress changes how humans learn about costs and benefits. Healthy adults were randomly exposed to an acute stress (age mean=23.48, 21/40 female) or no-stress control (age mean=23.80, 22/40 female) condition, after which they completed a reinforcement learning task in which they minimize cost (physical effort) and maximize benefits (monetary rewards). During the task pupillometry data were collected. A computational model of cost-benefit reinforcement learning was employed to investigate the effect of acute stress on cost and benefit learning and decision-making. Acute stress improved learning to maximize rewards relative to minimizing physical effort (Condition-by-Trial Type interaction: F(1,78)= 6.53, p = 0.01, n2G= 0.04; reward &gt; effort in stress condition: t(39) = 5.40, p αR in control condition: t(39) = -4.75, p &lt; 0.001]. This process was associated with distinct alterations in pupil size fluctuations. Data and scripts are available (https://osf.io/ydv2q/). Here we demonstrate that acute stress is associated with asymmetric learning about reward value versus action cost, thereby providing new insights into learning strategies under acute stress, which, depending on the context, may be maladaptive or beneficial. Our pupillometry and physiological results tentatively link asymmetric cost and benefit learning to stress-related changes in catecholamine activity.","link":"/opendata/voulgaropoulou-et-al-2022/"},{"title":"Vuletich & Payne (2019)","text":"Can implicit bias be changed? In a recent longitudinal study, Lai and colleagues (2016, Study 2) compared nine interventions intended to reduce racial bias across 18 university campuses. Although all interventions changed participants’ bias on an immediate test, none were effective after a delay. This study has been interpreted as strong evidence that implicit biases are difficult to change. We revisited Lai et al.’s study to test whether the stability observed reflected persistent individual attitudes or stable environments. Our reanalysis (N = 4,842) indicates that individual biases did not return to preexisting levels. Instead, campus means returned to preexisting campus means, whereas individual scores fluctuated mostly randomly. Campus means were predicted by markers of structural inequality. Our results are consistent with the theory that implicit bias reflects biases in the environment rather than individual dispositions. This conclusion is nearly the opposite of the original interpretation: Although social environments are stable, individual implicit biases are ephemeral.","link":"/opendata/vuletich-payne-2019/"},{"title":"Wall et al. (2023)","text":"Predictive inference is an important cognitive function and there are many tasks which measure it, and the error driven learning that underpins it. Context is a key contribution to this learning, with different contexts requiring different learning strategies. A factor not often considered however, is the conditions and time-frame over which a model of that context is developed. This study required participants to learn under two changing, unsignalled contexts with opposing optimal responses to large errors - change-points and oddballs. The changes in context occurred under two task structures: 1) a fixed task structure, with consecutive, short blocks of each context, and 2) a random task structure, with the context randomly selected for each new block. Through this design we examined the conditions under which learning contexts can be differentiated from each other, and the time-frame over which that learning occurs. We found that participants responded in accordance with the optimal strategy for each contexts, and did so within a short period of time, over very few meaningful errors. We further found that the responses became more optimal throughout the experiment, but only for periods of context consistency (the fixed task structure), and if the first experienced context involved meaningful errors. These results show that people will continue to refine their model of the environment across multiple trials and blocks, leading to more context-appropriate responding - but only in certain conditions. This highlights the importance of considering the task structure, and the time-frames of model development those patterns may encourage. This has implications for interpreting differences in learning across different contexts","link":"/opendata/wall-et-al-2023/"},{"title":"Waltmann et al. (2022a)","text":"Task-based measures that capture neurocognitive processes can help bridge the gap between brain and behavior. To transfer tasks to clinical application, reliability is a crucial benchmark because it imposes an upper bound to potential correlations with other variables (e.g., symptom or brain data). However, the reliability of many task readouts is low. In this study, we scrutinized the retest reliability of a probabilistic reversal learning task (PRLT) that is frequently used to characterize cognitive flexibility in psychiatric populations. We analyzed data from N = 40 healthy subjects, who completed the PRLT twice. We focused on how individual metrics are derived, i.e., whether data were partially pooled across participants and whether priors were used to inform estimates. We compared the reliability of the resulting indices across sessions, as well as the internal consistency of a selection of indices. We found good to excellent reliability for behavioral indices as derived from mixed-effects models that included data from both sessions. The internal consistency was good to excellent. For indices derived from computational modeling, we found excellent reliability when using hierarchical estimation with empirical priors and including data from both sessions. Our results indicate that the PRLT is well equipped to measure individual differences in cognitive flexibility in reinforcement learning. However, this depends heavily on hierarchical modeling of the longitudinal data (whether sessions are modeled separately or jointly), on estimation methods, and on the combination of parameters included in computational models. We discuss implications for the applicability of PRLT indices in psychiatric research and as diagnostic tools.","link":"/opendata/waltmann-et-al-2022a/"},{"title":"Waltmann et al. (2022b)","text":"Precisely charting the maturation of core neurocognitive functions such as reinforcement learning (RL) and flexible adaptation to changing action-outcome contingencies is key for developmental neuroscience and adjacent fields like developmental psychiatry. However, research in this area is both sparse and conflicted, especially regarding potentially asymmetric development of learning for different motives (obtain wins vs avoid losses) and learning from valenced feedback (positive vs negative). In the current study, we investigated the development of RL from adolescence to adulthood, using a probabilistic reversal learning task modified to experimentally separate motivational context and feedback valence, in a sample of 95 healthy participants between 12 and 45. We show that adolescence is characterized by enhanced novelty seeking and response shifting especially after negative feedback, which leads to poorer returns when reward contingencies are stable. Computationally, this is accounted for by reduced impact of positive feedback on behavior. We also show, using fMRI, that activity of the medial frontopolar cortex reflecting choice probability is attenuated in adolescence. We argue that this can be interpreted as reflecting diminished confidence in upcoming choices. Interestingly, we find no age- related differences between learning in win and loss contexts.","link":"/opendata/waltmann-et-al-2022b/"},{"title":"Warren et al. (2017)","text":"The adaptive regulation of the trade-off between pursuing a known reward (exploitation) and sampling lesser-known options in search of something better (exploration) is critical for optimal performance. Theory and recent empirical work suggest that humans use at least two strategies for solving this dilemma: a directed strategy in which choices are explicitly biased toward information seeking, and a random strategy in which decision noise leads to exploration by chance. Here we examined the hypothesis that random exploration is governed by the neuromodulatory locus coeruleus-norepinephrine system. We administered atomoxetine, a norepinephrine transporter blocker that increases extracellular levels of norepinephrine throughout the cortex, to 22 healthy human participants in a double-blind crossover design. We examined the effect of treatment on performance in a gambling task designed to produce distinct measures of directed exploration and random exploration. In line with our hypothesis we found an effect of atomoxetine on random, but not directed exploration. However, contrary to expectation, atomoxetine reduced rather than increased random exploration. We offer three potential explanations of our findings, involving the non-linear relationship between tonic NE and cognitive performance, the interaction of atomoxetine with other neuromodulators, and the possibility that atomoxetine affected phasic norepinephrine activity more so than tonic norepinephrine activity.","link":"/opendata/warren-et-al-2017/"},{"title":"Watson et al. (2019)","text":"Physically salient but task-irrelevant distractors can capture attention in visual search, but resource-dependent, executive-control processes can help reduce this distraction. However, it is not only physically salient stimuli that grab our attention: Recent research has shown that reward history also influences the likelihood that stimuli will capture attention. Here, we investigated whether resource-dependent control processes modulate the effect of reward on attentional capture, much as for the effect of physical salience. To this end, we used eye tracking with a rewarded visual search task and compared performance under conditions of high and low working memory load. In two experiments, we demonstrated that oculomotor capture by high-reward distractor stimuli is enhanced under high memory load. These results highlight the role of executive-control processes in modulating distraction by reward-related stimuli. Our findings have implications for understanding the neurocognitive processes involved in real-life conditions in which reward-related stimuli may influence behavior, such as addiction.","link":"/opendata/watson-et-al-2019/"},{"title":"Watson et al. (2022)","text":"The translation of the outcome-devaluation paradigm to study habit in humans has yielded interesting insights but proven to be challenging. We present a novel, outcome-revaluation task with a symmetrical design, in the sense that half of the available outcomes are always valuable and the other half not-valuable. In the present studies, during the instrumental learning phase, participants learned to respond (Go) to certain stimuli to collect valuable outcomes (and points) while refraining to respond (NoGo) to stimuli signaling not-valuable outcomes. Half of the stimuli were short-trained, while the other half were long-trained. Subsequently, in the test phase, the signaled outcomes were either value-congruent with training (still-valuable and still-not-valuable), or value-incongruent (devalued and upvalued). The change in outcome value on value-incongruent trials meant that participants had to flexibly adjust their behavior. At the end of the training phase, participants completed the self-report behavioral automaticity index - providing an automaticity score for each stimulus-response association. We conducted two experiments using this task, that both provided evidence for stimulus-driven habits as reflected in poorer performance on devalued and upvalued trials relative to still-not-valuable trials and still-valuable trials, respectively. While self-reported automaticity increased with longer training, behavioral flexibility was not affected. After extended training (Experiment 2), higher levels of self-reported automaticity when responding to stimuli signaling valuable outcomes were related to more slips of action when the associated outcome was subsequently devalued. We conclude that the symmetrical outcome-revaluation task provides a promising paradigm for the experimental investigation of habits in humans.","link":"/opendata/watson-et-al-2022/"},{"title":"Weber et al. (2022)","text":"Across species, animals have an intrinsic drive to approach appetitive stimuli and to withdraw from aversive stimuli. In affective science, influential theories of emotion link positive affect with strengthened behavioural approach and negative affect with avoidance. Based on these theories, we predicted that individuals positive and negative affect levels should particularly influence their behaviour when innate Pavlovian approach/avoidance tendencies conflict with learned instrumental behaviours. Here, across two experiments - exploratory Experiment 1 (N = 91) and a preregistered confirmatory Experiment 2 (N = 335) - we assessed how induced positive and negative affect influenced Pavlovian-instrumental interactions in a reward/punishment Go/No-Go task. Contrary to our hypotheses, we found no evidence for a main effect of positive/negative affect on either approach/avoidance behaviour or Pavlovian-instrumental interactions. However, we did find evidence that the effects of induced affect on behaviour were moderated by individual differences in self-reported behavioural inhibition and gender. Exploratory computational modelling analyses explained these demographic moderating effects as arising from positive correlations between demographic factors and individual differences in the strength of Pavlovian-instrumental interactions. These findings serve to sharpen our understanding of the effects of positive and negative affect on instrumental behaviour.","link":"/opendata/weber-et-al-2022/"},{"title":"Weilbacher et al. (2020)","text":"Previous research has indicated a bias in memory-based decision-making, with people preferring options that they remember better. However, the cognitive mechanisms underlying this memory bias remain elusive. Here, we propose that choosing poorly remembered options is conceptually similar to choosing options with uncertain outcomes. We predicted that the memory bias would be reduced when options had negative subjective value, analogous to the reflection effect, according to which uncertainty aversion is stronger in gains than in losses. In two preregistered experiments (N = 36 each), participants made memory-based decisions between appetitive and aversive stimuli. People preferred better-remembered options in the gain domain, but this behavioral pattern reversed in the loss domain. This effect was not related to participants’ ambiguity or risk attitudes, as measured in a separate task. Our results increase the understanding of memory-based decision-making and connect this emerging field to well-established research on decisions under uncertainty.","link":"/opendata/weilbacher-et-al-2020/"},{"title":"Weiss et al. (2021)","text":"Making accurate decisions in uncertain environments requires identifying the generative cause of sensory cues, but also the expected outcomes of possible actions. Although both cognitive processes can be formalized as Bayesian inference, they are commonly studied using different experimental frameworks, making their formal comparison difficult. Here, by framing a reversal learning task either as cue-based or outcome-based inference, we found that humans perceive the same volatile environment as more stable when inferring its hidden state by interaction with uncertain outcomes than by observation of equally uncertain cues. Multivariate patterns of magnetoencephalographic (MEG) activity reflected this behavioral difference in the neural interaction between inferred beliefs and incoming evidence, an effect originating from associative regions in the temporal lobe. Together, these findings indicate that the degree of control over the sampling of volatile environments shapes human learning and decision-making under uncertainty.","link":"/opendata/weiss-et-al-2021/"},{"title":"Wester et al. (2022)","text":"The expanded version of the Inventory of Depression and Anxiety Symptoms (IDAS-II) is a 99-item self-report measure containing 18 nonoverlapping dimensional scales assessing symptoms of depression, anxiety, and mania. The aim of this study was to develop and validate a German adaptation of the IDAS-II. Participants from a community sample (N = 1,054) completed the IDAS-II (German version). In addition, part of the sample (N = 550) completed a series of additional measures of depression (Patient Health Questionnaire-9, WHO-Five Well-Being Index, Symptom Checklist-90 Revised-Short Version) and anxiety disorders (Generalized Anxiety Disorder Scale-7, Fear of Negative Evaluation Scale-5, Dimensional Obsessive-Compulsive Scale, The International Trauma Questionnaire). We conducted item-level confirmatory factor analyses (CFA) separately for the 15 nonsaturated IDAS-II scales, which confirmed unidimensionality. McDonalds ω indicated good internal consistency (ω &gt; .8) of all symptom scales except Euphoria (ω = .751) and Ordering (ω = .728). A CFA of the IDAS-II scales, based on exploratory results by Watson et al. (2012), confirmed a three-factor model of Distress, Obsessions/Fear, and Positive Mood. Correlational analyses with additional symptom measures supported the convergent and discriminant validity of the IDAS-II scales. The IDAS-II (German version) allows for a reliable assessment of the severity of depression, anxiety, and bipolar symptoms and is one of the first clinical measures for German-speaking samples that is consistent with the Hierarchical Taxonomy of Psychopathology (HiTOP).","link":"/opendata/wester-et-al-2022/"},{"title":"Widge et al. (2019)","text":"Deep brain stimulation (DBS) is a circuit-oriented treatment for mental disorders. Unfortunately, even well-conducted psychiatric DBS clinical trials have yielded inconsistent symptom relief, in part because DBS mechanism(s) of action are unclear. One clue to those mechanisms may lie in the efficacy of ventral internal capsule/ventral striatum (VCVS) DBS in both major depression (MDD) and obsessive-compulsive disorder (OCD). MDD and OCD both involve deficits in cognitive control. Cognitive control depends on prefrontal cortex (PFC) regions that project into the VCVS. Here, we show that VCVS DBS effect is explained in part by enhancement of PFC-driven cognitive control. DBS improves human subjects performance on a cognitive control task and increases theta (5-8Hz) oscillations in both medial and lateral PFC. The theta increase predicts subjects clinical outcomes. Our results suggest a possible mechanistic approach to DBS therapy, based on tuning stimulation to optimize these neurophysiologic phenomena.","link":"/opendata/widge-et-al-2019/"},{"title":"Wiehler et al. (2021)","text":"Gambling disorder (GD) is a behavioral addiction associated with impairments in value-based decision-making and behavioral flexibility and might be linked to changes in the dopamine system. Maximizing long-term rewards requires a flexible trade-off between the exploitation of known options and the exploration of novel options for information gain. This exploration-exploitation trade-off is thought to depend on dopamine neurotransmission. We hypothesized that human gamblers would show a reduction in directed (uncertainty-based) exploration, accompanied by changes in brain activity in a fronto-parietal exploration-related network. Twenty-three frequent, non-treatment seeking gamblers and twenty-three healthy matched controls (all male) performed a four-armed bandit task during functional magnetic resonance imaging (fMRI). Computational modeling using hierarchical Bayesian parameter estimation revealed signatures of directed exploration, random exploration, and perseveration in both groups. Gamblers showed a reduction in directed exploration, whereas random exploration and perseveration were similar between groups. Neuroimaging revealed no evidence for group differences in neural representations of basic task variables (expected value, prediction errors). Our hypothesis of reduced frontal pole (FP) recruitment in gamblers was not supported. Exploratory analyses showed that during directed exploration, gamblers showed reduced parietal cortex and substantia-nigra/ventral-tegmental-area activity. Cross-validated classification analyses revealed that connectivity in an exploration-related network was predictive of group status, suggesting that connectivity patterns might be more predictive of problem gambling than univariate effects. Findings reveal specific reductions of strategic exploration in gamblers that might be linked to altered processing in a fronto-parietal network and/or changes in dopamine neurotransmission implicated in GD.","link":"/opendata/wiehler-et-al-2021/"},{"title":"Williams et al. (2022)","text":"Visual object recognition is not performed in isolation but depends on prior knowledge and context. Here, we found that auditory context plays a critical role in visual object perception. Using a psychophysical task in which naturalistic sounds were paired with noisy visual inputs, we demonstrated across two experiments (young adults; ns = 18-40 in Experiments 1 and 2, respectively) that the representations of ambiguous visual objects were shifted toward the visual features of an object that were related to the incidental sound. In a series of control experiments, we found that these effects were not driven by decision or response biases (ns = 40-85) nor were they due to top-down expectations (n = 40). Instead, these effects were driven by the continuous integration of audiovisual inputs during perception itself. Together, our results demonstrate that the perceptual experience of visual objects is directly shaped by naturalistic auditory context, which provides independent and diagnostic information about the visual world.","link":"/opendata/williams-et-al-2022/"},{"title":"Wimmer et al. (2018)","text":"Over the past few decades, neuroscience research has illuminated the neural mechanisms supporting learning from reward feedback. Learning paradigms are increasingly being extended to study mood and psychiatric disorders as well as addiction. However, one potentially critical characteristic that this research ignores is the effect of time on learning: human feedback learning paradigms are usually conducted in a single rapidly paced session, whereas learning experiences in ecologically relevant circumstances and in animal research are almost always separated by longer periods of time. In our experiments, we examined reward learning in short condensed sessions distributed across weeks versus learning completed in a single “massed” session in male and female participants. As expected, we found that after equal amounts of training, accuracy was matched between the spaced and massed conditions. However, in a 3-week follow-up, we found that participants exhibited significantly greater memory for the value of spaced-trained stimuli. Supporting a role for short-term memory in massed learning, we found a significant positive correlation between initial learning and working memory capacity. Neurally, we found that patterns of activity in the medial temporal lobe and prefrontal cortex showed stronger discrimination of spaced- versus massed-trained reward values. Further, patterns in the striatum discriminated between spaced- and massed-trained stimuli overall. Our results indicate that single-session learning tasks engage partially distinct learning mechanisms from distributed training. Our studies begin to address a large gap in our knowledge of human learning from reinforcement, with potential implications for our understanding of mood disorders and addiction.","link":"/opendata/wimmer-et-al-2018/"},{"title":"Wimmer & Poldrack (2022)","text":"Neuroscience research has illuminated the mechanisms supporting learning from reward feedback, demonstrating a critical role for the striatum and midbrain dopamine system. However, in humans, short-term working memory that is dependent on frontal and parietal cortices can also play an important role, particularly in commonly used paradigms in which learning is relatively condensed in time. Given the growing use of reward-based learning tasks in translational studies in computational psychiatry, it is important to understand the extent of the influence of working memory and also how core gradual learning mechanisms can be better isolated. In our experiments, we manipulated the spacing between repetitions along with a post-learning delay preceding a test phase. We found that learning was slower for stimuli repeated after a long delay (spaced-trained) compared to those repeated immediately (massed-trained), likely reflecting the remaining contribution of feedback learning mechanisms when working memory is not available. For massed learning, brief interruptions led to drops in subsequent performance, and individual differences in working memory capacity positively correlated with overall performance. Interestingly, when tested after a delay period but not immediately, relative preferences decayed in the massed condition and increased in the spaced condition. Our results provide additional support for a large role of working memory in reward-based learning in temporally condensed designs. We suggest that spacing training within or between sessions is a promising approach to better isolate and understand mechanisms supporting gradual reward-based learning, with particular importance for understanding potential learning dysfunctions in addiction and psychiatric disorders.","link":"/opendata/wimmer-poldrack-2022/"},{"title":"Wimmer et al. (2023)","text":"Theories of neural replay propose that it supports a range of functions, most prominently planning and memory consolidation. Here, we test the hypothesis that distinct signatures of replay in the same task are related to model-based decision-making (“planning”) and memory preservation. We designed a reward learning task wherein participants utilized structure knowledge for model-based evaluation, while at the same time had to maintain knowledge of two independent and randomly alternating task environments. Using magnetoencephalography and multivariate analysis, we first identified temporally compressed sequential reactivation, or replay, both prior to choice and following reward feedback. Before choice, prospective replay strength was enhanced for the current task-relevant environment when a model-based planning strategy was beneficial. Following reward receipt, and consistent with a memory preservation role, replay for the alternative distal task environment was enhanced as a function of decreasing recency of experience with that environment. Critically, these planning and memory preservation relationships were selective to pre-choice and post-feedback periods, respectively. Our results provide support for key theoretical proposals regarding the functional role of replay and demonstrate that the relative strength of planning and memory-related signals are modulated by ongoing computational and task demands.","link":"/opendata/wimmer-et-al-2023/"},{"title":"Wischnewski et al. (2021)","text":"In decision-making with uncertain outcomes people may rely on external cues, such as expert advice, even if this information has no predictive value. While the fronto-parietal event-related potential (ERP) components feedback-related negativity (FRN) and P3 are associated with both reward/punishment feedback processing, the relationship between ERP modulation and expert advice during decision making remains unclear. In this double-blind sham-controlled within-subject study transcranial alternating current stimulation (tACS) at an intensity of 1 mA was applied to the frontal cortex in twenty-four healthy volunteers. The aim was to decrease reliance on expert advice by targeting FRN, P3a and P3b components. Following administration of frontal delta (2.5 Hz), theta (5 Hz) and sham tACS, ERPs and advice-guided decision making were evaluated. Results showed a tentative behavioral effect of delta tACS in the response bias. In contrast, theta tACS significantly lowered P3b and P3a amplitudes, but no effects of tACS were observed for the FRN. Effects on electrophysiology and advice following behavior were uncorrelated. Our findings suggest that theta tACS may modulate electrocortical signals and delta tACS advice following, yet the relationship between both remains unresolved.","link":"/opendata/wischnewski-et-al-2021/"},{"title":"Wise et al. (2019)","text":"Visual selective attention acts as a filter on perceptual information, facilitating learning and inference about important events in an agents environment. A role for visual attention in reward-based decisions has previously been demonstrated, but it remains unclear how visual attention is recruited during aversive learning, particularly when learning about multiple stimuli concurrently. This question is of particular importance in psychopathology, where enhanced attention to threat is a putative feature of pathological anxiety. Using an aversive reversal learning task that required subjects to learn, and exploit, predictions about multiple stimuli, we show that the allocation of visual attention is influenced significantly by aversive value but not by uncertainty. Moreover, this relationship is bidirectional in that attention biases value updates for attended stimuli, resulting in heightened value estimates. Our findings have implications for understanding biased attention in psychopathology and support a role for learning in the expression of threat-related attentional biases in anxiety.","link":"/opendata/wise-et-al-2019/"},{"title":"Wise et al. (2020)","text":"Symptom expression in psychiatric conditions is often linked to altered threat perception, however how computational mechanisms that support aversive learning relate to specific psychiatric symptoms remains undetermined. We answer this question using an online game-based aversive learning task together with measures of common psychiatric symptoms in 400 subjects. We show that physiological symptoms of anxiety and a transdiagnostic compulsivity-related factor are associated with enhanced safety learning, as measured using a probabilistic computational model, while trait cognitive anxiety symptoms are associated with enhanced learning from danger. We use data-driven partial least squares regression to identify two separable components across behavioural and questionnaire data: one linking enhanced safety learning and lower estimated uncertainty to physiological anxiety, compulsivity, and impulsivity; the other linking enhanced threat learning and heightened uncertainty estimation to symptoms of depression and social anxiety. Our findings implicate aversive learning processes in the expression of psychiatric symptoms that transcend diagnostic boundaries.","link":"/opendata/wise-et-al-2020/"},{"title":"Wise et al. (2022)","text":"Successful avoidance of recurrent threats depends on inferring threatening agents’ preferences and predicting their movement patterns accordingly. However, it remains largely unknown how the human brain achieves this, despite the fact that many natural threats are posed by complex, dynamic agents that act according to their own goals. Here, we propose that humans exploit an interactive cognitive map of the social environment to infer threatening agents’ preferences and also to simulate their future behavior, providing for flexible, generalizable avoidance strategies. We tested this proposal across three preregistered experiments (total n=510) using a task in which participants collected rewards while avoiding one of several possible virtual threatening agents. A novel, model-based, hypothesis-testing inverse reinforcement learning computational model best explained participants’ inferences about threatening agents’ latent preferences, with participants using this inferred knowledge to enact generalizable, model-based avoidance strategies across different environments. Using tree-search planning models, we found that participants’ behavior was best explained by a planning algorithm that incorporated simulations of the threat’s goal-directed behavior, and that prior expectations about the threat’s predictability were linked to individual differences in avoidance. Together, our results indicate that humans use a cognitive map to determine threatening agents’ preferences, in turn facilitating generalized predictions of the threatening agent’s behavior and enabling flexible and effective avoidance.","link":"/opendata/wise-et-al-2022/"},{"title":"Woelk et al. (2022)","text":"Anxiety disorders are effectively treated with exposure therapy, but relapse remains high. Fear may reinstate after reoccurrence of the negative event because the expectancy of the aversive outcome (unconditioned stimulus [US]) is adjusted but not its evaluation. Imagery rescripting (ImRs) is an intervention that is proposed to work through revaluation of the US. The aim of our preregistered study was to test the effects of ImRs and extinction on US expectancy and US revaluation. Day 1 (n = 106) consisted of acquisition with an aversive film clip as US. The manipulation (ImRs + extinction, extinction-only, or ImRs-only) took place on Day 2. Reinstatement of fear was tested on Day 3. Results showed expectancy learning in both extinction conditions but not in the ImRs-only condition and no enhanced revaluation learning in ImRs. The combination of ImRs and extinction slowed down extinction but did not protect against reinstatement, which pleads in favor of stand-alone interventions in clinical practice.","link":"/opendata/woelk-et-al-2022/"},{"title":"Wu et al. (2018)","text":"From foraging for food to learning complex games, many aspects of human behaviour can be framed as a search problem with a vast space of possible actions. Under finite search horizons, optimal solutions are generally unobtainable. Yet, how do humans navigate vast problem spaces, which require intelligent exploration of unobserved actions? Using various bandit tasks with up to 121 arms, we study how humans search for rewards under limited search horizons, in which the spatial correlation of rewards (in both generated and natural environments) provides traction for generalization. Across various different probabilistic and heuristic models, we find evidence that Gaussian process function learning-combined with an optimistic upper confidence bound sampling strategy-provides a robust account of how people use generalization to guide search. Our modelling results and parameter estimates are recoverable and can be used to simulate human-like performance, providing insights about human behaviour in complex environments.","link":"/opendata/wu-et-al-2018/"},{"title":"Wu et al. (2022)","text":"How does time pressure influence exploration and decision-making? We investigated this question with several four-armed bandit tasks manipulating (within subjects) expected reward, uncertainty, and time pressure (limited vs. unlimited). With limited time, people have less opportunity to perform costly computations, thus shifting the cost-benefit balance of different exploration strategies. Through behavioral, reinforcement learning (RL), reaction time (RT), and evidence accumulation analyses, we show that time pressure changes how people explore and respond to uncertainty. Specifically, participants reduced their uncertainty-directed exploration under time pressure, were less value-directed, and repeated choices more often.Since our analyses relate uncertainty to slower responses and dampened evidence accumulation (i.e., drift rates), this demonstrates a resource-rational shift towards simpler, lower-cost strategies under time pressure. These results shed light on how people adapt their exploration and decision-making strategies to externally imposed cognitive constraints.","link":"/opendata/wu-et-al-2022/"},{"title":"Wulff et al. (2018)","text":"People can learn about the probabilistic consequences of their actions in two ways: One is by consulting descriptions of an action’s consequences and probabilities (e.g., reading up on a medication’s side effects). The other is by personally experiencing the probabilistic consequences of an action (e.g., beta testing software). In principle, people taking each route can reach analogous states of knowledge and consequently make analogous decisions. In the last dozen years, however, research has demonstrated systematic discrepancies between description- and experienced-based choices. This description-experience gap has been attributed to factors including reliance on a small set of experience, the impact of recency, and different weighting of probability information in the two decision types. In this meta-analysis focusing on studies using the sampling paradigm of decisions from experience, we evaluated these and other determinants of the decision–experience gap by reference to more than 70,000 choices made by more than 6,000 participants. We found, first, a robust description-experience gap but also a key moderator, namely, problem structure. Second, the largest determinant of the gap was reliance on small samples and the associated sampling error: free to terminate search, individuals explored too little to experience all possible outcomes. Third, the gap persisted when sampling error was basically eliminated, suggesting other determinants. Fourth, the occurrence of recency was contingent on decision makers’ autonomy to terminate search, consistent with the notion of optional stopping. Finally, we found indications of different probability weighting in decisions from experience versus decisions from description when the problem structure involved a risky and a safe option.","link":"/opendata/wulff-et-al-2018/"},{"title":"Xia et al. (2022)","text":"Fear conditioning is a laboratory paradigm commonly used to investigate aversive learning and memory. In context fear conditioning, a configuration of elemental cues (conditioned stimulus, CS) predicts an aversive event (unconditioned stimulus, US). To quantify context fear acquisition in humans, previous work has used startle eye-blink responses (SEBR), skin conductance responses (SCR) and verbal reports, but different quantification methods have rarely been compared. Moreover, it is unclear how to induce, and measure context fear memory retention over several days. First, we used a semi-immersive virtual reality paradigm. In two experiments, we found successful declarative learning and memory retention over seven days, but no evidence of conditioned responses. Next, we used a configural fear conditioning paradigm with five static room images as CSs in two experiments. Besides successful declarative learning and memory retention after seven days, SCR and pupil dilation to CS onset differentiated CS+/CS- during acquisition training, and SEBR and pupil dilation differentiated CS+/CS- during the recall test, with medium to large effect sizes for the most sensitive indices (SEBR: Hedge’s g = 0.56 and 0.69; pupil dilation: Hedge’s g = 0.99 and g = 0.88). Our results demonstrate that with a suitable experimental paradigm, context fear memory retention can be demonstrated over seven days, and we provide robust and replicable measurement methods.","link":"/opendata/xia-et-al-2022/"},{"title":"Xu & Stocco (2021)","text":"Behavioral data, despite being a common index of cognitive activity, is under scrutiny for having poor reliability as a result of noise or lacking replications of reliable effects. Here, we argue that cognitive modeling can be used to enhance the test-retest reliability of the behavioral measures by recovering individual-level parameters from behavioral data. We tested this empirically with the Probabilistic Stimulus Selection (PSS) task, which is used to measure a participants sensitivity to positive or negative reinforcement. An analysis of 400,000 simulations from an Adaptive Control of Thought-Rational (ACT-R) model of this task showed that the poor reliability of the task is due to the instability of the end-estimates: because of the way the task works, the same participants might sometimes end up having apparently opposite scores. To recover the underlying interpretable parameters and enhance reliability, we used a Bayesian Maximum A Posteriori (MAP) procedure. We were able to obtain reliable parameters across sessions (intraclass correlation coefficient ≈ 0.5). A follow-up study on a modified version of the task also found the same pattern of results, with very poor test-retest reliability in behavior but moderate reliability in recovered parameters (intraclass correlation coefficient ≈ 0.4). Collectively, these results imply that this approach can further be used to provide superior measures in terms of reliability, and bring greater insights into individual differences.","link":"/opendata/xu-stocco-2021/"},{"title":"Yoo et al. (2022)","text":"How does the nature of a stimulus affect our ability to learn appropriate response associations? In typical laboratory experiments learning is investigated under somewhat ideal circumstances, where stimuli are easily discriminable visually and linguistically. This is not representative of most real-life learning, where visually or linguistically overlapping stimuli can result in different rewards (e.g., you may learn over time that you can pet one specific dog that is friendly, but that you should avoid a very similar looking one that isn’t). With two experiments, we test how humans learn in three stimulus conditions: stimuli with distinct visual representations but overlapping linguistic representations, stimuli with distinct linguistic representations but overlapping visual representations, and stimuli with distinct visual and linguistic representations. We find that decreasing linguistic and visual distinctness both decrease performance, substantially more for the lowered linguistic distinctness condition. We develop computational models to test different hypotheses about how reinforcement learning (RL) and working memory (WM) processes are affected by different stimulus conditions. Interestingly, we find that only RL, and not WM, is affected by stimulus condition: people learn slower and have higher across-stimulus value confusion at decision when linguistic information overlaps relative to when it is distinct. These results demonstrate strong effects of stimulus type on learning, and highlight the importance of considering the parallel contributions of different cognitive processes when studying behavior.","link":"/opendata/yoo-et-al-2022/"},{"title":"Zaatri et al. (2022)","text":"Although living in social groups provides many benefits for group members, such groups also serve as a setting for social competition over rank and influence. Evolutionary accounts suggest that social anxiety plays a role in regulating in-group conflict, as individuals who are concerned about social threat may choose to defer to others to maintain the hierarchical status quo. Here, we examine how social anxiety levels are related to the advice-giving style an individual adopts: a competitive influence-seeking strategy or a defensive blend-in strategy. We begin by demonstrating that similarity to others drives activity in the brains valuation system, even during a competitive advice-taking task. Then, in three behavioural experiments, we show that social anxiety levels are related to the tendency to give advice resembling the advice given by rival advisers and to refrain from status-seeking behaviour. Social anxiety was also associated with negative social comparisons with rival advisers. Our findings highlight the role of competing social goals in shaping information sharing.","link":"/opendata/zaatri-et-al-2022/"},{"title":"Zajkowski et al. (2017)","text":"The explore-exploit dilemma occurs anytime we must choose between exploring unknown options for information and exploiting known resources for reward. Previous work suggests that people use two different strategies to solve the explore-exploit dilemma: directed exploration, driven by information seeking, and random exploration, driven by decision noise. Here, we show that these two strategies rely on different neural systems. Using transcranial magnetic stimulation to inhibit the right frontopolar cortex, we were able to selectively inhibit directed exploration while leaving random exploration intact. This suggests a causal role for right frontopolar cortex in directed, but not random, exploration and that directed and random exploration rely on (at least partially) dissociable neural systems.","link":"/opendata/zajkowski-et-al-2017/"},{"title":"Zaller et al. (2021)","text":"Excessive information seeking, or exploratory behavior to minimize the uncertainty of unknown options, is a feature of anxiety disorders. The horizons task (Wilson et al. 2014) is a popular task for measuring information-seeking behavior, recently used to identify under-exploration in psychosis (Waltz et al. 2020). The horizons task has not yet been evaluated as a tool for measuring information seeking behavior in anxious individuals. We recruited 100 participants to complete an online version of the horizons task. Anxiety was measured with the Penn State Worry Questionnaire (PSWQ), and attitudes related to information seeking were measured with the Intolerance of Uncertainty scale (IUS) and the Need for Closure scale (NCS). Information seeking behavior on the horizons task was measured per participant using hierarchical Bayesian modeling. We confirmed that behavior on the online version of the horizons task is similar to previous in-person studies. Contrary to our hypotheses, we found no evidence of a relationship between information seeking behavior on the task and anxiety symptoms or the information seeking scales. Our results suggest behavior on the horizons task does not predict beliefs and attitudes towards anxious information seeking. We suspect this may reflect design features of the task that reduce the value of information seeking behaviors. We conclude by proposing modifications to the task that may improve its utility as a measure of information seeking behavior in anxiety.","link":"/opendata/zaller-et-al-2021/"},{"title":"Zech et al. (2022)","text":"The approach-avoidance task (AAT) is an implicit task that measures peoples behavioral tendencies to approach or avoid stimuli in the environment. In recent years, it has been used successfully to help explain a variety of health problems (e.g., addictions and phobias). Unfortunately, more recent AAT studies have failed to replicate earlier promising findings. One explanation for these replication failures could be that the AAT does not reliably measure approach-avoidance tendencies. Here, we first review existing literature on the reliability of various versions of the AAT. Next, we examine the AATs reliability in a large and diverse sample (N = 1077; 248 of whom completed all sessions). Using a smartphone-based, mobile AAT, we measured participants approach-avoidance tendencies eight times over a period of seven months (one measurement per month) in two distinct stimulus sets (happy/sad expressions and disgusting/neutral stimuli). The mobile AATs split-half reliability was adequate for face stimuli (r = .85), but low for disgust stimuli (r = .72). Its test-retest reliability based on a single measurement was poor for either stimulus set (all ICC1s &lt; .3). Its test-retest reliability based on the average of all eight measurements was moderately good for face stimuli (ICCk = .73), but low for disgust stimuli (ICCk = .5). Results suggest that single-measurement AATs could be influenced by unexplained temporal fluctuations of approach-avoidance tendencies. These fluctuations could be examined in future studies. Until then, this work suggests that future research using the AAT should rely on multiple rather than single measurements.","link":"/opendata/zech-et-al-2022/"},{"title":"Zhu et al. (2019)","text":"Both basal ganglia (BG) and orbitofrontal cortex (OFC) have been widely implicated in social and non-social decision-making. However, unlike OFC damage, BG pathology is not typically associated with disturbances in social functioning. Here we studied the behavior of patients with focal lesions to either BG or OFC in a multi-strategy competitive game known to engage these regions. We find that whereas OFC patients are significantly impaired, BG patients show intact learning in the economic game. By contrast, when information about the strategic context is absent, both cohorts are significantly impaired. Computational modeling further shows a preserved ability in BG patients to learn by anticipating and responding to the behavior of others using the strategic context. These results suggest that apparently divergent findings on BG contribution to social decision-making may instead reflect a model where higher-order learning processes are dissociable from trial-and-error learning, and can be preserved despite BG damage.","link":"/opendata/zhu-et-al-2019/"},{"title":"Ziaka & Protopapas (2022)","text":"Cognitive control has been typically examined using single-item tasks. This has implications for the generalizability of theories of control implementation. Previous studies have revealed that different control demands are posed by tasks depending on whether they present stimuli individually (i.e., single-item) or simultaneously in array format (i.e., multi-item). In the present study we tracked within-task performance in single-item and multi-item Stroop tasks using simultaneous pupillometry, gaze, and behavioral response measures, aiming to explore the implications of format differences for cognitive control. The results indicated within-task performance decline in the multi-item version of the Stroop task, accompanied by pupil constriction and dwell time increase, in both the incongruent and the neutral condition. In contrast, no performance decline or dwell time increase was observed in the course of the single-item version of the task. These findings point to capacity constraints beyond the explanatory range of current theories of cognitive control, with implications for cognitive control research, and highlight the need for better understanding the cognitive demands of multi-item tasks.","link":"/opendata/ziaka-protopapas-2022/"},{"title":"Zilker et al. (2020)","text":"The canonical conclusion from research on age differences in risky choice is that older adults are more risk averse than younger adults, at least in choices involving gains. Most of the evidence for this conclusion derives from studies that used a specific type of choice problem: choices between a safe and a risky option. However, safe and risky options differ not only in the degree of risk but also in the amount of information to be processed-that is, in their complexity. In both an online and a lab experiment, we demonstrate that differences in option complexity can be a key driver of age differences in risk attitude. When the complexity of the safe option is increased, older adults no longer seem more risk averse than younger adults (in gains). Using computational modeling, we test mechanisms that potentially underlie the effect of option complexity. The results show that participants are not simply averse to complexity, and that increasing the complexity of safe options does more than simply make responses more noisy. Rather, differences in option complexity affect the processing of attribute information: whereas the availability of a simple safe option is associated with the distortion of probability weighting and lower outcome sensitivity, these effects are attenuated when both options are more similar in complexity. We also dissociate these effects of option complexity from an effect of certainty. Our findings may also have implications for age differences in other decision phenomena (e.g., framing effect, loss aversion, immediacy effect).","link":"/opendata/zilker-et-al-2020/"},{"title":"Zorowitz et al. (2021)","text":"A common research design in the field of computational psychiatry involves leveraging the power of online participant recruitment to assess correlations between behavior in cognitive tasks and the self-reported severity of psychiatric symptoms in large, diverse samples. Although large online samples have many advantages for psychiatric research, some potential pitfalls of this research design are not widely understood. Here we detail circumstances in which entirely spurious correlations may arise between task behavior and symptom severity as a result of inadequate screening of careless or low-effort responding on psychiatric symptom surveys. Specifically, since many psychiatric symptom surveys have asymmetric ground-truth score distributions in the general population, participants who respond carelessly on these surveys will show apparently elevated symptom levels. If these participants are similarly careless in their task performance, and are not excluded from analysis, this may result in a spurious association between greater symptom scores and worse behavioral task performance. Here, we demonstrate exactly this pattern of results in two independent samples of participants (total N = 779) recruited online to complete a self-report symptom battery and one of two common cognitive tasks. We show that many behavior-symptom correlations are entirely abolished when participants flagged for careless responding on surveys are excluded from analysis. We also show that exclusion based on task performance alone is often insufficient to prevent these spurious correlations. Of note, we demonstrate that false-positive rates for these spurious correlations increase with sample size, contrary to common assumptions. We offer guidance on how researchers using this general experimental design can guard against this issue in future research; in particular, we recommend the adoption of screening methods for self-report measures that are currently uncommon in this field.","link":"/opendata/zorowitz-et-al-2021/"},{"title":"Zorowitz et al. (2022)","text":"Matrix reasoning tasks are among the most widely used measures of cognitive ability in the behavioral sciences, but the lack of matrix reasoning tests in the public domain complicates their use. Here we present an extensive investigation and psychometric validation of the matrix reasoning item bank (MaRs-IB), an open-access set of matrix reasoning items. In a first study, we calibrate the psychometric functioning of the items in the MaRs-IB in a large sample adults participants (N=1501). Using additive multilevel item structure models, we establish that the MaRs-IB has many desirable psychometric properties: its items span a wide range of difficulty, possess medium- to-large levels of discrimination, and exhibit robust associations between item complexity and difficulty. However, we also find that item clones are not always psychometrically equivalent and cannot assumed to be exchangeable. In a second study, we demonstrate how experimenters can use the estimated item parameters to design new matrix reasoning tests using optimal item assembly. Specifically, we design and validate two new sets of test forms in an independent sample of adults (N=600). We find these new tests possess good reliability and convergent validity with an established measure of matrix reasoning. We hope that the materials and results made available here will encourage experimenters to use the MaRs-IB in their research.","link":"/opendata/zorowitz-et-al-2022/"},{"title":"Zorowitz & Niv (2023)","text":"Data from N=149 participants who completed a gamified version of the two-step task under one of three conditions: (1) stimuli from both first- and second-state choices were randomly assigned to right/left positions on the screen on every trial; (2) stimuli from both first- and second-state choices were assigned fixed right/left positions on the screen (i.e., unchanging across trials); or (3) stimuli from first-state choices were randomly assigned to right/left positions on the screen on every trial. Second-state stimuli were assigned fixed right/left positions on the screen (i.e., unchanging across trials).","link":"/opendata/zorowitz-niv-2023/"}],"tags":[{"name":"memory","slug":"memory","link":"/opendata/tags/memory/"},{"name":"explore/exploit","slug":"explore-exploit","link":"/opendata/tags/explore-exploit/"},{"name":"2-arm bandit","slug":"2-arm-bandit","link":"/opendata/tags/2-arm-bandit/"},{"name":"pavlovian go/no-go task","slug":"pavlovian-go-no-go-task","link":"/opendata/tags/pavlovian-go-no-go-task/"},{"name":"schizotypy","slug":"schizotypy","link":"/opendata/tags/schizotypy/"},{"name":"m/eeg","slug":"m-eeg","link":"/opendata/tags/m-eeg/"},{"name":"social decision making","slug":"social-decision-making","link":"/opendata/tags/social-decision-making/"},{"name":"cognitive control","slug":"cognitive-control","link":"/opendata/tags/cognitive-control/"},{"name":"planning","slug":"planning","link":"/opendata/tags/planning/"},{"name":"sequential sampling","slug":"sequential-sampling","link":"/opendata/tags/sequential-sampling/"},{"name":"probability estimation","slug":"probability-estimation","link":"/opendata/tags/probability-estimation/"},{"name":"metacognition","slug":"metacognition","link":"/opendata/tags/metacognition/"},{"name":"confidence","slug":"confidence","link":"/opendata/tags/confidence/"},{"name":"perceptual decision making","slug":"perceptual-decision-making","link":"/opendata/tags/perceptual-decision-making/"},{"name":"pavlovian conditioning","slug":"pavlovian-conditioning","link":"/opendata/tags/pavlovian-conditioning/"},{"name":"eye-tracking","slug":"eye-tracking","link":"/opendata/tags/eye-tracking/"},{"name":"information seeking","slug":"information-seeking","link":"/opendata/tags/information-seeking/"},{"name":"paranoia","slug":"paranoia","link":"/opendata/tags/paranoia/"},{"name":"interval timing","slug":"interval-timing","link":"/opendata/tags/interval-timing/"},{"name":"database","slug":"database","link":"/opendata/tags/database/"},{"name":"multi-arm bandit","slug":"multi-arm-bandit","link":"/opendata/tags/multi-arm-bandit/"},{"name":"restless bandit","slug":"restless-bandit","link":"/opendata/tags/restless-bandit/"},{"name":"punishment","slug":"punishment","link":"/opendata/tags/punishment/"},{"name":"anxiety","slug":"anxiety","link":"/opendata/tags/anxiety/"},{"name":"depression","slug":"depression","link":"/opendata/tags/depression/"},{"name":"sequential decision making","slug":"sequential-decision-making","link":"/opendata/tags/sequential-decision-making/"},{"name":"approach/avoidance","slug":"approach-avoidance","link":"/opendata/tags/approach-avoidance/"},{"name":"foraging","slug":"foraging","link":"/opendata/tags/foraging/"},{"name":"risk sensitivity","slug":"risk-sensitivity","link":"/opendata/tags/risk-sensitivity/"},{"name":"development","slug":"development","link":"/opendata/tags/development/"},{"name":"adolescence","slug":"adolescence","link":"/opendata/tags/adolescence/"},{"name":"working memory","slug":"working-memory","link":"/opendata/tags/working-memory/"},{"name":"configural learning","slug":"configural-learning","link":"/opendata/tags/configural-learning/"},{"name":"compulsivity","slug":"compulsivity","link":"/opendata/tags/compulsivity/"},{"name":"tdcs","slug":"tdcs","link":"/opendata/tags/tdcs/"},{"name":"agency","slug":"agency","link":"/opendata/tags/agency/"},{"name":"reversal learning","slug":"reversal-learning","link":"/opendata/tags/reversal-learning/"},{"name":"economic game","slug":"economic-game","link":"/opendata/tags/economic-game/"},{"name":"range adaptation","slug":"range-adaptation","link":"/opendata/tags/range-adaptation/"},{"name":"counterfactual feedback","slug":"counterfactual-feedback","link":"/opendata/tags/counterfactual-feedback/"},{"name":"free association","slug":"free-association","link":"/opendata/tags/free-association/"},{"name":"narrative","slug":"narrative","link":"/opendata/tags/narrative/"},{"name":"test-retest","slug":"test-retest","link":"/opendata/tags/test-retest/"},{"name":"volatility","slug":"volatility","link":"/opendata/tags/volatility/"},{"name":"compound generalization","slug":"compound-generalization","link":"/opendata/tags/compound-generalization/"},{"name":"mood","slug":"mood","link":"/opendata/tags/mood/"},{"name":"decisions from description","slug":"decisions-from-description","link":"/opendata/tags/decisions-from-description/"},{"name":"effort","slug":"effort","link":"/opendata/tags/effort/"},{"name":"continuous outcomes","slug":"continuous-outcomes","link":"/opendata/tags/continuous-outcomes/"},{"name":"stress","slug":"stress","link":"/opendata/tags/stress/"},{"name":"two-step","slug":"two-step","link":"/opendata/tags/two-step/"},{"name":"mouse-tracking","slug":"mouse-tracking","link":"/opendata/tags/mouse-tracking/"},{"name":"iowa gambling task","slug":"iowa-gambling-task","link":"/opendata/tags/iowa-gambling-task/"},{"name":"temporal discounting","slug":"temporal-discounting","link":"/opendata/tags/temporal-discounting/"},{"name":"pathological gambling","slug":"pathological-gambling","link":"/opendata/tags/pathological-gambling/"},{"name":"mental imagery","slug":"mental-imagery","link":"/opendata/tags/mental-imagery/"},{"name":"time pressure","slug":"time-pressure","link":"/opendata/tags/time-pressure/"},{"name":"value construction","slug":"value-construction","link":"/opendata/tags/value-construction/"},{"name":"stroop","slug":"stroop","link":"/opendata/tags/stroop/"},{"name":"probabilistic selection task","slug":"probabilistic-selection-task","link":"/opendata/tags/probabilistic-selection-task/"},{"name":"parkinson's","slug":"parkinson-s","link":"/opendata/tags/parkinson-s/"},{"name":"latent cause inference","slug":"latent-cause-inference","link":"/opendata/tags/latent-cause-inference/"},{"name":"self-report only","slug":"self-report-only","link":"/opendata/tags/self-report-only/"},{"name":"reward visibility","slug":"reward-visibility","link":"/opendata/tags/reward-visibility/"},{"name":"generalization","slug":"generalization","link":"/opendata/tags/generalization/"},{"name":"ecological momentary assessment","slug":"ecological-momentary-assessment","link":"/opendata/tags/ecological-momentary-assessment/"},{"name":"mania","slug":"mania","link":"/opendata/tags/mania/"},{"name":"horizons task","slug":"horizons-task","link":"/opendata/tags/horizons-task/"},{"name":"impulsivity","slug":"impulsivity","link":"/opendata/tags/impulsivity/"},{"name":"psychosis","slug":"psychosis","link":"/opendata/tags/psychosis/"},{"name":"sequence learning","slug":"sequence-learning","link":"/opendata/tags/sequence-learning/"},{"name":"serial reaction time","slug":"serial-reaction-time","link":"/opendata/tags/serial-reaction-time/"},{"name":"inverse RL","slug":"inverse-RL","link":"/opendata/tags/inverse-RL/"},{"name":"avoidance","slug":"avoidance","link":"/opendata/tags/avoidance/"},{"name":"clinical trial","slug":"clinical-trial","link":"/opendata/tags/clinical-trial/"},{"name":"balloon analog risk task","slug":"balloon-analog-risk-task","link":"/opendata/tags/balloon-analog-risk-task/"},{"name":"habits","slug":"habits","link":"/opendata/tags/habits/"},{"name":"outcome devaluation","slug":"outcome-devaluation","link":"/opendata/tags/outcome-devaluation/"},{"name":"autism","slug":"autism","link":"/opendata/tags/autism/"},{"name":"attention","slug":"attention","link":"/opendata/tags/attention/"},{"name":"spatial navigation","slug":"spatial-navigation","link":"/opendata/tags/spatial-navigation/"},{"name":"mindfulness","slug":"mindfulness","link":"/opendata/tags/mindfulness/"},{"name":"self-judgment","slug":"self-judgment","link":"/opendata/tags/self-judgment/"},{"name":"ptsd","slug":"ptsd","link":"/opendata/tags/ptsd/"},{"name":"adhd","slug":"adhd","link":"/opendata/tags/adhd/"},{"name":"mind wandering","slug":"mind-wandering","link":"/opendata/tags/mind-wandering/"},{"name":"stop signal","slug":"stop-signal","link":"/opendata/tags/stop-signal/"},{"name":"monetary incentive delay task","slug":"monetary-incentive-delay-task","link":"/opendata/tags/monetary-incentive-delay-task/"},{"name":"go/no-go task","slug":"go-no-go-task","link":"/opendata/tags/go-no-go-task/"},{"name":"aging","slug":"aging","link":"/opendata/tags/aging/"},{"name":"trauma","slug":"trauma","link":"/opendata/tags/trauma/"},{"name":"visual perception","slug":"visual-perception","link":"/opendata/tags/visual-perception/"},{"name":"auditory perception","slug":"auditory-perception","link":"/opendata/tags/auditory-perception/"},{"name":"causal reasoning","slug":"causal-reasoning","link":"/opendata/tags/causal-reasoning/"},{"name":"longitudinal","slug":"longitudinal","link":"/opendata/tags/longitudinal/"},{"name":"pavlovian instrumental transfer","slug":"pavlovian-instrumental-transfer","link":"/opendata/tags/pavlovian-instrumental-transfer/"},{"name":"curiosity","slug":"curiosity","link":"/opendata/tags/curiosity/"},{"name":"abstract reasoning","slug":"abstract-reasoning","link":"/opendata/tags/abstract-reasoning/"},{"name":"executive functioning","slug":"executive-functioning","link":"/opendata/tags/executive-functioning/"},{"name":"anchoring","slug":"anchoring","link":"/opendata/tags/anchoring/"},{"name":"substance use","slug":"substance-use","link":"/opendata/tags/substance-use/"},{"name":"categorization","slug":"categorization","link":"/opendata/tags/categorization/"},{"name":"implicit association test","slug":"implicit-association-test","link":"/opendata/tags/implicit-association-test/"},{"name":"multisensory integration","slug":"multisensory-integration","link":"/opendata/tags/multisensory-integration/"}],"categories":[]}